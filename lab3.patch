diff -Naur lab2/src/java/simpledb/BTreeEntry.java lab3/src/java/simpledb/BTreeEntry.java
--- lab2/src/java/simpledb/BTreeEntry.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeEntry.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,137 @@
+package simpledb;
+
+import java.io.Serializable;
+
+/**
+ * Each instance of BTreeEntry stores one key and two child page ids. It is used
+ * by BTreeInternalPage as an abstraction to iterate through the entries stored inside. 
+ * All of the entries or tuples in the left child page should be less than or equal to 
+ * the key, and all of the entries or tuples in the right child page should be greater 
+ * than or equal to the key.
+ * 
+ * Note that updating a BTreeEntry does not actually change the data stored on the page 
+ * identified by its recordId. After updating a BTreeEntry object, you must call 
+ * BTreeInternalPage.updateEntry() in order for the changes to take effect.
+ *
+ * @see BTreeInternalPage
+ * @see BTreeInternalPage#updateEntry(BTreeEntry)
+ *
+ */
+public class BTreeEntry implements Serializable {
+
+	private static final long serialVersionUID = 1L;
+	
+	/**
+	 * The key of this entry
+	 * */
+	private Field key;
+
+	/**
+	 * The left child page id
+	 * */
+	private BTreePageId leftChild;
+
+	/**
+	 * The right child page id
+	 * */
+	private BTreePageId rightChild;
+
+	/**
+	 * The record id of this entry
+	 * */
+	private RecordId rid; // null if not stored on any page
+
+	/**
+	 * Constructor to create a new BTreeEntry
+	 * @param key - the key
+	 * @param leftChild - page id of the left child
+	 * @param rightChild - page id of the right child
+	 */
+	public BTreeEntry(Field key, BTreePageId leftChild, BTreePageId rightChild) {
+		this.key = key;
+		this.leftChild = leftChild;
+		this.rightChild = rightChild;
+	}
+	
+	/**
+	 * @return the key
+	 */
+	public Field getKey() {
+		return key;
+	}
+	
+	/**
+	 * @return the left child page id
+	 */
+	public BTreePageId getLeftChild() {
+		return leftChild;
+	}
+	
+	/**
+	 * @return the right child page id
+	 */
+	public BTreePageId getRightChild() {
+		return rightChild;
+	}
+	
+	/**
+	 * @return the record id of this entry, representing the location of this entry
+	 * in a BTreeFile. May be null if this entry is not stored on any page in the file
+	 */
+	public RecordId getRecordId() {
+		return rid;
+	}
+	
+	/**
+	 * Set the key for this entry. Note that updating a BTreeEntry does not 
+	 * actually change the data stored on the page identified by its recordId.  After
+	 * calling this method, you must call BTreeInternalPage.updateEntry() in order for
+	 * it to take effect.
+	 * @param key - the new key
+	 * @see BTreeInternalPage#updateEntry(BTreeEntry)
+	 */
+	public void setKey(Field key) {
+		this.key = key;
+	}
+	
+	/**
+	 * Set the left child id for this entry.  Note that updating a BTreeEntry does not 
+	 * actually change the data stored on the page identified by its recordId.  After
+	 * calling this method, you must call BTreeInternalPage.updateEntry() in order for
+	 * it to take effect.
+	 * @param leftChild - the new left child
+	 * @see BTreeInternalPage#updateEntry(BTreeEntry)
+	 */
+	public void setLeftChild(BTreePageId leftChild) {
+		this.leftChild = leftChild;
+	}
+	
+	/**
+	 * Set the right child id for this entry.  Note that updating a BTreeEntry does not 
+	 * actually change the data stored on the page identified by its recordId.  After
+	 * calling this method, you must call BTreeInternalPage.updateEntry() in order for
+	 * it to take effect.
+	 * @param rightChild - the new right child
+	 * @see BTreeInternalPage#updateEntry(BTreeEntry)
+	 */
+	public void setRightChild(BTreePageId rightChild) {
+		this.rightChild = rightChild;
+	}
+	
+	/**
+	 * set the record id for this entry
+	 * @param rid - the new record id
+	 */
+	public void setRecordId(RecordId rid) {
+		this.rid = rid;
+	}
+	
+	/**
+	 * Prints a representation of this BTreeEntry
+	 */
+	public String toString() {
+		return "[" + leftChild.pageNumber() + "|" + key + "|" + rightChild.pageNumber() + "]";
+	}
+	
+}
+
diff -Naur lab2/src/java/simpledb/BTreeFile.java lab3/src/java/simpledb/BTreeFile.java
--- lab2/src/java/simpledb/BTreeFile.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeFile.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,1255 @@
+package simpledb;
+
+import java.io.*;
+import java.util.*;
+import java.nio.channels.FileChannel;
+
+import simpledb.Predicate.Op;
+
+/**
+ * BTreeFile is an implementation of a DbFile that stores a B+ tree.
+ * Specifically, it stores a pointer to a root page,
+ * a set of internal pages, and a set of leaf pages, which contain a collection of tuples
+ * in sorted order. BTreeFile works closely with BTreeLeafPage, BTreeInternalPage,
+ * and BTreeRootPtrPage. The format of these pages is described in their constructors.
+ * 
+ * @see simpledb.BTreeLeafPage#BTreeLeafPage
+ * @see simpledb.BTreeInternalPage#BTreeInternalPage
+ * @see simpledb.BTreeHeaderPage#BTreeHeaderPage
+ * @see simpledb.BTreeRootPtrPage#BTreeRootPtrPage
+ * @author Becca Taft
+ */
+public class BTreeFile implements DbFile {
+
+	private final File f;
+	private final TupleDesc td;
+	private final int tableid ;
+	private int keyField;
+
+	/**
+	 * Constructs a B+ tree file backed by the specified file.
+	 * 
+	 * @param f - the file that stores the on-disk backing store for this B+ tree
+	 *            file.
+	 * @param key - the field which index is keyed on
+	 * @param td - the tuple descriptor of tuples in the file
+	 */
+	public BTreeFile(File f, int key, TupleDesc td) {
+		this.f = f;
+		this.tableid = f.getAbsoluteFile().hashCode();
+		this.keyField = key;
+		this.td = td;
+	}
+
+	/**
+	 * Returns the File backing this BTreeFile on disk.
+	 */
+	public File getFile() {
+		return f;
+	}
+
+	/**
+	 * Returns an ID uniquely identifying this BTreeFile. Implementation note:
+	 * you will need to generate this tableid somewhere and ensure that each
+	 * BTreeFile has a "unique id," and that you always return the same value for
+	 * a particular BTreeFile. We suggest hashing the absolute file name of the
+	 * file underlying the BTreeFile, i.e. f.getAbsoluteFile().hashCode().
+	 * 
+	 * @return an ID uniquely identifying this BTreeFile.
+	 */
+	public int getId() {
+		return tableid;
+	}
+
+	/**
+	 * Returns the TupleDesc of the table stored in this DbFile.
+	 * 
+	 * @return TupleDesc of this DbFile.
+	 */
+	public TupleDesc getTupleDesc() {
+		return td;
+	}
+
+	/**
+	 * Read a page from the file on disk. This should not be called directly
+	 * but should be called from the BufferPool via getPage()
+	 * 
+	 * @param pid - the id of the page to read from disk
+	 * @return the page constructed from the contents on disk
+	 */
+	public Page readPage(PageId pid) {
+		BTreePageId id = (BTreePageId) pid;
+		BufferedInputStream bis = null;
+
+		try {
+			bis = new BufferedInputStream(new FileInputStream(f));
+			if(id.pgcateg() == BTreePageId.ROOT_PTR) {
+				byte pageBuf[] = new byte[BTreeRootPtrPage.getPageSize()];
+				int retval = bis.read(pageBuf, 0, BTreeRootPtrPage.getPageSize());
+				if (retval == -1) {
+					throw new IllegalArgumentException("Read past end of table");
+				}
+				if (retval < BTreeRootPtrPage.getPageSize()) {
+					throw new IllegalArgumentException("Unable to read "
+							+ BTreeRootPtrPage.getPageSize() + " bytes from BTreeFile");
+				}
+				Debug.log(1, "BTreeFile.readPage: read page %d", id.pageNumber());
+				BTreeRootPtrPage p = new BTreeRootPtrPage(id, pageBuf);
+				return p;
+			}
+			else {
+				byte pageBuf[] = new byte[BufferPool.getPageSize()];
+				if (bis.skip(BTreeRootPtrPage.getPageSize() + (id.pageNumber()-1) * BufferPool.getPageSize()) != 
+						BTreeRootPtrPage.getPageSize() + (id.pageNumber()-1) * BufferPool.getPageSize()) {
+					throw new IllegalArgumentException(
+							"Unable to seek to correct place in BTreeFile");
+				}
+				int retval = bis.read(pageBuf, 0, BufferPool.getPageSize());
+				if (retval == -1) {
+					throw new IllegalArgumentException("Read past end of table");
+				}
+				if (retval < BufferPool.getPageSize()) {
+					throw new IllegalArgumentException("Unable to read "
+							+ BufferPool.getPageSize() + " bytes from BTreeFile");
+				}
+				Debug.log(1, "BTreeFile.readPage: read page %d", id.pageNumber());
+				if(id.pgcateg() == BTreePageId.INTERNAL) {
+					BTreeInternalPage p = new BTreeInternalPage(id, pageBuf, keyField);
+					return p;
+				}
+				else if(id.pgcateg() == BTreePageId.LEAF) {
+					BTreeLeafPage p = new BTreeLeafPage(id, pageBuf, keyField);
+					return p;
+				}
+				else { // id.pgcateg() == BTreePageId.HEADER
+					BTreeHeaderPage p = new BTreeHeaderPage(id, pageBuf);
+					return p;
+				}
+			}
+		} catch (IOException e) {
+			throw new RuntimeException(e);
+		} finally {
+			// Close the file on success or error
+			try {
+				if (bis != null)
+					bis.close();
+			} catch (IOException ioe) {
+				// Ignore failures closing the file
+			}
+		}
+	}
+
+	/**
+	 * Write a page to disk.  This should not be called directly but should 
+	 * be called from the BufferPool when pages are flushed to disk
+	 * 
+	 * @param page - the page to write to disk
+	 */
+	public void writePage(Page page) throws IOException {
+		BTreePageId id = (BTreePageId) page.getId();
+		
+		byte[] data = page.getPageData();
+		RandomAccessFile rf = new RandomAccessFile(f, "rw");
+		if(id.pgcateg() == BTreePageId.ROOT_PTR) {
+			rf.write(data);
+			rf.close();
+		}
+		else {
+			rf.seek(BTreeRootPtrPage.getPageSize() + (page.getId().pageNumber()-1) * BufferPool.getPageSize());
+			rf.write(data);
+			rf.close();
+		}
+	}
+	
+	/**
+	 * Returns the number of pages in this BTreeFile.
+	 */
+	public int numPages() {
+		// we only ever write full pages
+		return (int) ((f.length() - BTreeRootPtrPage.getPageSize())/ BufferPool.getPageSize());
+	}
+
+	/**
+	 * Returns the index of the field that this B+ tree is keyed on
+	 */
+	public int keyField() {
+		return keyField;
+	}
+
+	/**
+	 * Recursive function which finds and locks the leaf page in the B+ tree corresponding to
+	 * the left-most page possibly containing the key field f. It locks all internal
+	 * nodes along the path to the leaf node with READ_ONLY permission, and locks the 
+	 * leaf node with permission perm.
+	 * 
+	 * If f is null, it finds the left-most leaf page -- used for the iterator
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param pid - the current page being searched
+	 * @param perm - the permissions with which to lock the leaf page
+	 * @param f - the field to search for
+	 * @return the left-most leaf page possibly containing the key field f
+	 * 
+	 */
+	private BTreeLeafPage findLeafPage(TransactionId tid, HashMap<PageId, Page> dirtypages, BTreePageId pid, Permissions perm,
+			Field f) 
+					throws DbException, TransactionAbortedException {
+		// some code goes here
+        return null;
+	}
+	
+	/**
+	 * Convenience method to find a leaf page when there is no dirtypages HashMap.
+	 * Used by the BTreeFile iterator.
+	 * @see #findLeafPage(TransactionId, HashMap, BTreePageId, Permissions, Field)
+	 * 
+	 * @param tid - the transaction id
+	 * @param pid - the current page being searched
+	 * @param perm - the permissions with which to lock the leaf page
+	 * @param f - the field to search for
+	 * @return the left-most leaf page possibly containing the key field f
+	 * 
+	 */
+	BTreeLeafPage findLeafPage(TransactionId tid, BTreePageId pid, Permissions perm,
+			Field f) 
+					throws DbException, TransactionAbortedException {
+		return findLeafPage(tid, new HashMap<PageId, Page>(), pid, perm, f);
+	}
+
+	/**
+	 * Split a leaf page to make room for new tuples and recursively split the parent node
+	 * as needed to accommodate a new entry. The new entry should have a key matching the key field
+	 * of the first tuple in the right-hand page (the key is "copied up"), and child pointers 
+	 * pointing to the two leaf pages resulting from the split.  Update sibling pointers and parent 
+	 * pointers as needed.  
+	 * 
+	 * Return the leaf page into which a new tuple with key field "field" should be inserted.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the leaf page to split
+	 * @param field - the key field of the tuple to be inserted after the split is complete. Necessary to know
+	 * which of the two pages to return.
+	 * @see #getParentWithEmptySlots(TransactionId, HashMap, BTreePageId, Field)
+	 * 
+	 * @return the leaf page into which the new tuple should be inserted
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected BTreeLeafPage splitLeafPage(TransactionId tid, HashMap<PageId, Page> dirtypages, BTreeLeafPage page, Field field) 
+			throws DbException, IOException, TransactionAbortedException {
+		// some code goes here
+        // YOUR CODE HERE:
+        // Split the leaf page by adding a new page on the right of the existing
+		// page and moving half of the tuples to the new page.  Copy the middle key up
+		// into the parent page, and recursively split the parent as needed to accommodate
+		// the new entry.  getParentWithEmtpySlots() will be useful here.  Don't forget to update
+		// the sibling pointers of all the affected leaf pages.  Return the page into which a 
+		// tuple with the given key field should be inserted.
+        return null;
+		
+	}
+	
+	/**
+	 * Split an internal page to make room for new entries and recursively split its parent page
+	 * as needed to accommodate a new entry. The new entry for the parent should have a key matching 
+	 * the middle key in the original internal page being split (this key is "pushed up" to the parent). 
+	 * The child pointers of the new parent entry should point to the two internal pages resulting 
+	 * from the split. Update parent pointers as needed.
+	 * 
+	 * Return the internal page into which an entry with key field "field" should be inserted
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the internal page to split
+	 * @param field - the key field of the entry to be inserted after the split is complete. Necessary to know
+	 * which of the two pages to return.
+	 * @see #getParentWithEmptySlots(TransactionId, HashMap, BTreePageId, Field)
+	 * @see #updateParentPointers(TransactionId, HashMap, BTreeInternalPage)
+	 * 
+	 * @return the internal page into which the new entry should be inserted
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected BTreeInternalPage splitInternalPage(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreeInternalPage page, Field field) 
+					throws DbException, IOException, TransactionAbortedException {
+		// some code goes here
+        // YOUR CODE HERE:
+        // Split the internal page by adding a new page on the right of the existing
+		// page and moving half of the entries to the new page.  Push the middle key up
+		// into the parent page, and recursively split the parent as needed to accommodate
+		// the new entry.  getParentWithEmtpySlots() will be useful here.  Don't forget to update
+		// the parent pointers of all the children moving to the new page.  updateParentPointers()
+		// will be useful here.  Return the page into which an entry with the given key field
+		// should be inserted.
+		return null;
+	}
+	
+	/**
+	 * Method to encapsulate the process of getting a parent page ready to accept new entries.
+	 * This may mean creating a page to become the new root of the tree, splitting the existing 
+	 * parent page if there are no empty slots, or simply locking and returning the existing parent page.
+	 *
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param parentId - the id of the parent. May be an internal page or the RootPtr page
+	 * @param field - the key of the entry which will be inserted. Needed in case the parent must be split
+	 * to accommodate the new entry
+	 * @return the parent page, guaranteed to have at least one empty slot
+	 * @see #splitInternalPage(TransactionId, HashMap, BTreeInternalPage, Field)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private BTreeInternalPage getParentWithEmptySlots(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreePageId parentId, Field field) throws DbException, IOException, TransactionAbortedException {
+		
+		BTreeInternalPage parent = null;
+		
+		// create a parent node if necessary
+		// this will be the new root of the tree
+		if(parentId.pgcateg() == BTreePageId.ROOT_PTR) {
+			parent = (BTreeInternalPage) getEmptyPage(tid, dirtypages, BTreePageId.INTERNAL);
+			
+			// update the root pointer
+			BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) getPage(tid, dirtypages, 
+					BTreeRootPtrPage.getId(tableid), Permissions.READ_WRITE);
+			rootPtr.setRootId(parent.getId());		
+		}
+		else { 
+			// lock the parent page
+			parent = (BTreeInternalPage) getPage(tid, dirtypages, parentId, 
+					Permissions.READ_WRITE);
+		}
+
+		// split the parent if needed
+		if(parent.getNumEmptySlots() == 0) {
+			parent = splitInternalPage(tid, dirtypages, parent, field);
+		}
+
+		return parent;
+
+	}
+
+	/**
+	 * Helper function to update the parent pointer of a node.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param pid - id of the parent node
+	 * @param child - id of the child node to be updated with the parent pointer
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private void updateParentPointer(TransactionId tid, HashMap<PageId, Page> dirtypages, BTreePageId pid, BTreePageId child) 
+			throws DbException, IOException, TransactionAbortedException {
+
+		BTreePage p = (BTreePage) getPage(tid, dirtypages, child, Permissions.READ_ONLY);
+
+		if(!p.getParentId().equals(pid)) {
+			p = (BTreePage) getPage(tid, dirtypages, child, Permissions.READ_WRITE);
+			p.setParentId(pid);
+		}
+
+	}
+	
+	/**
+	 * Update the parent pointer of every child of the given page so that it correctly points to
+	 * the parent
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the parent page
+	 * @see #updateParentPointer(TransactionId, HashMap, BTreePageId, BTreePageId)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private void updateParentPointers(TransactionId tid, HashMap<PageId, Page> dirtypages, BTreeInternalPage page) 
+			throws DbException, IOException, TransactionAbortedException{
+		Iterator<BTreeEntry> it = page.iterator();
+		BTreePageId pid = page.getId();
+		BTreeEntry e = null;
+		while(it.hasNext()) {
+			e = it.next();
+			updateParentPointer(tid, dirtypages, pid, e.getLeftChild());
+		}
+		if(e != null) {
+			updateParentPointer(tid, dirtypages, pid, e.getRightChild());
+		}
+	}
+	
+	/**
+	 * Method to encapsulate the process of locking/fetching a page.  First the method checks the local 
+	 * cache ("dirtypages"), and if it can't find the requested page there, it fetches it from the buffer pool.  
+	 * It also adds pages to the dirtypages cache if they are fetched with read-write permission, since 
+	 * presumably they will soon be dirtied by this transaction.
+	 * 
+	 * This method is needed to ensure that page updates are not lost if the same pages are
+	 * accessed multiple times.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param pid - the id of the requested page
+	 * @param perm - the requested permissions on the page
+	 * @return the requested page
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private Page getPage(TransactionId tid, HashMap<PageId, Page> dirtypages, BTreePageId pid, Permissions perm) 
+			throws DbException, TransactionAbortedException {
+		if(dirtypages.containsKey(pid)) {
+			return dirtypages.get(pid);
+		}
+		else {
+			Page p = Database.getBufferPool().getPage(tid, pid, perm);
+			if(perm == Permissions.READ_WRITE) {
+				dirtypages.put(pid, p);
+			}
+			return p;
+		}
+	}
+
+	/**
+	 * Insert a tuple into this BTreeFile, keeping the tuples in sorted order. 
+	 * May cause pages to split if the page where tuple t belongs is full.
+	 * 
+	 * @param tid - the transaction id
+	 * @param t - the tuple to insert
+	 * @return a list of all pages that were dirtied by this operation. Could include
+	 * many pages since parent pointers will need to be updated when an internal node splits.
+	 * @see #splitLeafPage(TransactionId, HashMap, BTreeLeafPage, Field)
+	 */
+	public ArrayList<Page> insertTuple(TransactionId tid, Tuple t)
+			throws DbException, IOException, TransactionAbortedException {
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+
+		// get a read lock on the root pointer page and use it to locate the root page
+		BTreeRootPtrPage rootPtr = getRootPtrPage(tid, dirtypages);
+		BTreePageId rootId = rootPtr.getRootId();
+
+		if(rootId == null) { // the root has just been created, so set the root pointer to point to it		
+			rootId = new BTreePageId(tableid, numPages(), BTreePageId.LEAF);
+			rootPtr = (BTreeRootPtrPage) getPage(tid, dirtypages, BTreeRootPtrPage.getId(tableid), Permissions.READ_WRITE);
+			rootPtr.setRootId(rootId);
+		}
+
+		// find and lock the left-most leaf page corresponding to the key field,
+		// and split the leaf page if there are no more slots available
+		BTreeLeafPage leafPage = findLeafPage(tid, dirtypages, rootId, Permissions.READ_WRITE, t.getField(keyField));
+		if(leafPage.getNumEmptySlots() == 0) {
+			leafPage = splitLeafPage(tid, dirtypages, leafPage, t.getField(keyField));	
+		}
+
+		// insert the tuple into the leaf page
+		leafPage.insertTuple(t);
+
+		ArrayList<Page> dirtyPagesArr = new ArrayList<Page>();
+		dirtyPagesArr.addAll(dirtypages.values());
+		return dirtyPagesArr;
+	}
+	
+	/**
+	 * Handle the case when a B+ tree page becomes less than half full due to deletions.
+	 * If one of its siblings has extra tuples/entries, redistribute those tuples/entries.
+	 * Otherwise merge with one of the siblings. Update pointers as needed.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the page which is less than half full
+	 * @see #handleMinOccupancyLeafPage(TransactionId, HashMap, BTreeLeafPage, BTreeInternalPage, BTreeEntry, BTreeEntry)
+	 * @see #handleMinOccupancyInternalPage(TransactionId, HashMap, BTreeInternalPage, BTreeInternalPage, BTreeEntry, BTreeEntry)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private void handleMinOccupancyPage(TransactionId tid, HashMap<PageId, Page> dirtypages, BTreePage page) 
+			throws DbException, IOException, TransactionAbortedException {
+		BTreePageId parentId = page.getParentId();
+		BTreeEntry leftEntry = null;
+		BTreeEntry rightEntry = null;
+		BTreeInternalPage parent = null;
+
+		// find the left and right siblings through the parent so we make sure they have
+		// the same parent as the page. Find the entries in the parent corresponding to 
+		// the page and siblings
+		if(parentId.pgcateg() != BTreePageId.ROOT_PTR) {
+			parent = (BTreeInternalPage) getPage(tid, dirtypages, parentId, Permissions.READ_WRITE);
+			Iterator<BTreeEntry> ite = parent.iterator();
+			while(ite.hasNext()) {
+				BTreeEntry e = ite.next();
+				if(e.getLeftChild().equals(page.getId())) {
+					rightEntry = e;
+					break;
+				}
+				else if(e.getRightChild().equals(page.getId())) {
+					leftEntry = e;
+				}
+			}
+		}
+		
+		if(page.getId().pgcateg() == BTreePageId.LEAF) {
+			handleMinOccupancyLeafPage(tid, dirtypages, (BTreeLeafPage) page, parent, leftEntry, rightEntry);
+		}
+		else { // BTreePageId.INTERNAL
+			handleMinOccupancyInternalPage(tid, dirtypages, (BTreeInternalPage) page, parent, leftEntry, rightEntry);
+		}
+	}
+	
+	/**
+	 * Handle the case when a leaf page becomes less than half full due to deletions.
+	 * If one of its siblings has extra tuples, redistribute those tuples.
+	 * Otherwise merge with one of the siblings. Update pointers as needed.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the leaf page which is less than half full
+	 * @param parent - the parent of the leaf page
+	 * @param leftEntry - the entry in the parent pointing to the given page and its left-sibling
+	 * @param rightEntry - the entry in the parent pointing to the given page and its right-sibling
+	 * @see #mergeLeafPages(TransactionId, HashMap, BTreeLeafPage, BTreeLeafPage, BTreeInternalPage, BTreeEntry)
+	 * @see #stealFromLeafPage(BTreeLeafPage, BTreeLeafPage, Iterator, BTreeInternalPage, BTreeEntry)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private void handleMinOccupancyLeafPage(TransactionId tid, HashMap<PageId, Page> dirtypages, BTreeLeafPage page, 
+			BTreeInternalPage parent, BTreeEntry leftEntry, BTreeEntry rightEntry) 
+			throws DbException, IOException, TransactionAbortedException {
+		BTreePageId leftSiblingId = null;
+		BTreePageId rightSiblingId = null;
+		if(leftEntry != null) leftSiblingId = leftEntry.getLeftChild();
+		if(rightEntry != null) rightSiblingId = rightEntry.getRightChild();
+		
+		int maxEmptySlots = page.getMaxTuples() - page.getMaxTuples()/2; // ceiling
+		if(leftSiblingId != null) {
+			BTreeLeafPage leftSibling = (BTreeLeafPage) getPage(tid, dirtypages, leftSiblingId, Permissions.READ_WRITE);
+			// if the left sibling is at minimum occupancy, merge with it. Otherwise
+			// steal some tuples from it
+			if(leftSibling.getNumEmptySlots() >= maxEmptySlots) {
+				mergeLeafPages(tid, dirtypages, leftSibling, page, parent, leftEntry);
+			}
+			else {
+				stealFromLeafPage(page, leftSibling, parent, leftEntry, false);				
+			}
+		}
+		else if(rightSiblingId != null) {	
+			BTreeLeafPage rightSibling = (BTreeLeafPage) getPage(tid, dirtypages, rightSiblingId, Permissions.READ_WRITE);
+			// if the right sibling is at minimum occupancy, merge with it. Otherwise
+			// steal some tuples from it
+			if(rightSibling.getNumEmptySlots() >= maxEmptySlots) {
+				mergeLeafPages(tid, dirtypages, page, rightSibling, parent, rightEntry);
+			}
+			else {
+				stealFromLeafPage(page, rightSibling, parent, rightEntry, true);				
+			}
+		}
+	}
+	
+	/**
+	 * Steal tuples from a sibling and copy them to the given page so that both pages are at least
+	 * half full.  Update the parent's entry so that the key matches the key field of the first
+	 * tuple in the right-hand page.
+	 * 
+	 * @param page - the leaf page which is less than half full
+	 * @param sibling - the sibling which has tuples to spare
+	 * @param parent - the parent of the two leaf pages
+	 * @param entry - the entry in the parent pointing to the two leaf pages
+	 * @param isRightSibling - whether the sibling is a right-sibling
+	 * 
+	 * @throws DbException
+	 */
+	protected void stealFromLeafPage(BTreeLeafPage page, BTreeLeafPage sibling,
+			BTreeInternalPage parent, BTreeEntry entry, boolean isRightSibling) throws DbException {
+		// some code goes here
+        // YOUR CODE HERE:
+        // Move some of the tuples from the sibling to the page so
+		// that the tuples are evenly distributed. Be sure to update
+		// the corresponding parent entry.
+	}
+
+	/**
+	 * Handle the case when an internal page becomes less than half full due to deletions.
+	 * If one of its siblings has extra entries, redistribute those entries.
+	 * Otherwise merge with one of the siblings. Update pointers as needed.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the internal page which is less than half full
+	 * @param parent - the parent of the internal page
+	 * @param leftEntry - the entry in the parent pointing to the given page and its left-sibling
+	 * @param rightEntry - the entry in the parent pointing to the given page and its right-sibling
+	 * @see #mergeInternalPages(TransactionId, HashMap, BTreeInternalPage, BTreeInternalPage, BTreeInternalPage, BTreeEntry)
+	 * @see #stealFromLeftInternalPage(TransactionId, HashMap, BTreeInternalPage, BTreeInternalPage, BTreeInternalPage, BTreeEntry)
+	 * @see #stealFromRightInternalPage(TransactionId, HashMap, BTreeInternalPage, BTreeInternalPage, BTreeInternalPage, BTreeEntry)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private void handleMinOccupancyInternalPage(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreeInternalPage page, BTreeInternalPage parent, BTreeEntry leftEntry, BTreeEntry rightEntry) 
+					throws DbException, IOException, TransactionAbortedException {
+		BTreePageId leftSiblingId = null;
+		BTreePageId rightSiblingId = null;
+		if(leftEntry != null) leftSiblingId = leftEntry.getLeftChild();
+		if(rightEntry != null) rightSiblingId = rightEntry.getRightChild();
+		
+		int maxEmptySlots = page.getMaxEntries() - page.getMaxEntries()/2; // ceiling
+		if(leftSiblingId != null) {
+			BTreeInternalPage leftSibling = (BTreeInternalPage) getPage(tid, dirtypages, leftSiblingId, Permissions.READ_WRITE);
+			// if the left sibling is at minimum occupancy, merge with it. Otherwise
+			// steal some entries from it
+			if(leftSibling.getNumEmptySlots() >= maxEmptySlots) {
+				mergeInternalPages(tid, dirtypages, leftSibling, page, parent, leftEntry);
+			}
+			else {
+				stealFromLeftInternalPage(tid, dirtypages, page, leftSibling, parent, leftEntry);
+			}
+		}
+		else if(rightSiblingId != null) {
+			BTreeInternalPage rightSibling = (BTreeInternalPage) getPage(tid, dirtypages, rightSiblingId, Permissions.READ_WRITE);
+			// if the right sibling is at minimum occupancy, merge with it. Otherwise
+			// steal some entries from it
+			if(rightSibling.getNumEmptySlots() >= maxEmptySlots) {
+				mergeInternalPages(tid, dirtypages, page, rightSibling, parent, rightEntry);
+			}
+			else {
+				stealFromRightInternalPage(tid, dirtypages, page, rightSibling, parent, rightEntry);
+			}
+		}
+	}
+	
+	/**
+	 * Steal entries from the left sibling and copy them to the given page so that both pages are at least
+	 * half full. Keys can be thought of as rotating through the parent entry, so the original key in the 
+	 * parent is "pulled down" to the right-hand page, and the last key in the left-hand page is "pushed up"
+	 * to the parent.  Update parent pointers as needed.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the internal page which is less than half full
+	 * @param leftSibling - the left sibling which has entries to spare
+	 * @param parent - the parent of the two internal pages
+	 * @param leftEntry - the entry in the parent pointing to the two internal pages
+	 * @see #updateParentPointers(TransactionId, HashMap, BTreeInternalPage)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected void stealFromLeftInternalPage(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreeInternalPage page, BTreeInternalPage leftSibling, BTreeInternalPage parent, 
+			BTreeEntry leftEntry) throws DbException, IOException, TransactionAbortedException {
+		// some code goes here
+        // YOUR CODE HERE:
+        // Move some of the entries from the left sibling to the page so
+		// that the entries are evenly distributed. Be sure to update
+		// the corresponding parent entry. Be sure to update the parent
+		// pointers of all children in the entries that were moved.
+		
+	}
+	
+	/**
+	 * Steal entries from the right sibling and copy them to the given page so that both pages are at least
+	 * half full. Keys can be thought of as rotating through the parent entry, so the original key in the 
+	 * parent is "pulled down" to the left-hand page, and the last key in the right-hand page is "pushed up"
+	 * to the parent.  Update parent pointers as needed.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param page - the internal page which is less than half full
+	 * @param rightSibling - the right sibling which has entries to spare
+	 * @param parent - the parent of the two internal pages
+	 * @param rightEntry - the entry in the parent pointing to the two internal pages
+	 * @see #updateParentPointers(TransactionId, HashMap, BTreeInternalPage)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected void stealFromRightInternalPage(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreeInternalPage page, BTreeInternalPage rightSibling, BTreeInternalPage parent, 
+			BTreeEntry rightEntry) throws DbException, IOException, TransactionAbortedException {
+		// some code goes here
+        // YOUR CODE HERE:
+        // Move some of the entries from the right sibling to the page so
+		// that the entries are evenly distributed. Be sure to update
+		// the corresponding parent entry. Be sure to update the parent
+		// pointers of all children in the entries that were moved.
+	}
+	
+	/**
+	 * Merge two leaf pages by moving all tuples from the right page to the left page. 
+	 * Delete the corresponding key and right child pointer from the parent, and recursively 
+	 * handle the case when the parent gets below minimum occupancy.
+	 * Update sibling pointers as needed, and make the right page available for reuse.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param leftPage - the left leaf page
+	 * @param rightPage - the right leaf page
+	 * @param parent - the parent of the two pages
+	 * @param parentEntry - the entry in the parent corresponding to the leftPage and rightPage
+	 * @see #deleteParentEntry(TransactionId, HashMap, BTreePage, BTreeInternalPage, BTreeEntry)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected void mergeLeafPages(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreeLeafPage leftPage, BTreeLeafPage rightPage, BTreeInternalPage parent, BTreeEntry parentEntry) 
+					throws DbException, IOException, TransactionAbortedException {
+
+		// some code goes here
+        // YOUR CODE HERE: 
+		// Move all the tuples from the right page to the left page, update
+		// the sibling pointers, and make the right page available for reuse.
+		// Delete the entry in the parent corresponding to the two pages that are merging -
+		// deleteParentEntry() will be useful here
+	}
+
+	/**
+	 * Merge two internal pages by moving all entries from the right page to the left page 
+	 * and "pulling down" the corresponding key from the parent entry. 
+	 * Delete the corresponding key and right child pointer from the parent, and recursively 
+	 * handle the case when the parent gets below minimum occupancy.
+	 * Update parent pointers as needed, and make the right page available for reuse.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param leftPage - the left internal page
+	 * @param rightPage - the right internal page
+	 * @param parent - the parent of the two pages
+	 * @param parentEntry - the entry in the parent corresponding to the leftPage and rightPage
+	 * @see #deleteParentEntry(TransactionId, HashMap, BTreePage, BTreeInternalPage, BTreeEntry)
+	 * @see #updateParentPointers(TransactionId, HashMap, BTreeInternalPage)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected void mergeInternalPages(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreeInternalPage leftPage, BTreeInternalPage rightPage, BTreeInternalPage parent, BTreeEntry parentEntry) 
+					throws DbException, IOException, TransactionAbortedException {
+		
+		// some code goes here
+        // YOUR CODE HERE:
+        // Move all the entries from the right page to the left page, update
+		// the parent pointers of the children in the entries that were moved, 
+		// and make the right page available for reuse
+		// Delete the entry in the parent corresponding to the two pages that are merging -
+		// deleteParentEntry() will be useful here
+	}
+	
+	/**
+	 * Method to encapsulate the process of deleting an entry (specifically the key and right child) 
+	 * from a parent node.  If the parent becomes empty (no keys remaining), that indicates that it 
+	 * was the root node and should be replaced by its one remaining child.  Otherwise, if it gets 
+	 * below minimum occupancy for non-root internal nodes, it should steal from one of its siblings or 
+	 * merge with a sibling.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param leftPage - the child remaining after the key and right child are deleted
+	 * @param parent - the parent containing the entry to be deleted
+	 * @param parentEntry - the entry to be deleted
+	 * @see #handleMinOccupancyPage(TransactionId, HashMap, BTreePage)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private void deleteParentEntry(TransactionId tid, HashMap<PageId, Page> dirtypages, 
+			BTreePage leftPage, BTreeInternalPage parent, BTreeEntry parentEntry) 
+					throws DbException, IOException, TransactionAbortedException {		
+		
+		// delete the entry in the parent.  If
+		// the parent is below minimum occupancy, get some tuples from its siblings
+		// or merge with one of the siblings
+		parent.deleteKeyAndRightChild(parentEntry);
+		int maxEmptySlots = parent.getMaxEntries() - parent.getMaxEntries()/2; // ceiling
+		if(parent.getNumEmptySlots() == parent.getMaxEntries()) {
+			// This was the last entry in the parent.
+			// In this case, the parent (root node) should be deleted, and the merged 
+			// page will become the new root
+			BTreePageId rootPtrId = parent.getParentId();
+			if(rootPtrId.pgcateg() != BTreePageId.ROOT_PTR) {
+				throw new DbException("attempting to delete a non-root node");
+			}
+			BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) getPage(tid, dirtypages, rootPtrId, Permissions.READ_WRITE);
+			leftPage.setParentId(rootPtrId);
+			rootPtr.setRootId(leftPage.getId());
+
+			// release the parent page for reuse
+			setEmptyPage(tid, dirtypages, parent.getId().pageNumber());
+		}
+		else if(parent.getNumEmptySlots() > maxEmptySlots) { 
+			handleMinOccupancyPage(tid, dirtypages, parent);
+		}
+	}
+
+	/**
+	 * Delete a tuple from this BTreeFile. 
+	 * May cause pages to merge or redistribute entries/tuples if the pages 
+	 * become less than half full.
+	 * 
+	 * @param tid - the transaction id
+	 * @param t - the tuple to delete
+	 * @return a list of all pages that were dirtied by this operation. Could include
+	 * many pages since parent pointers will need to be updated when an internal node merges.
+	 * @see #handleMinOccupancyPage(TransactionId, HashMap, BTreePage)
+	 */
+	public ArrayList<Page> deleteTuple(TransactionId tid, Tuple t) 
+			throws DbException, IOException, TransactionAbortedException {
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+
+		BTreePageId pageId = new BTreePageId(tableid, t.getRecordId().getPageId().pageNumber(), 
+				BTreePageId.LEAF);
+		BTreeLeafPage page = (BTreeLeafPage) getPage(tid, dirtypages, pageId, Permissions.READ_WRITE);
+		page.deleteTuple(t);
+
+		// if the page is below minimum occupancy, get some tuples from its siblings
+		// or merge with one of the siblings
+		int maxEmptySlots = page.getMaxTuples() - page.getMaxTuples()/2; // ceiling
+		if(page.getNumEmptySlots() > maxEmptySlots) { 
+			handleMinOccupancyPage(tid, dirtypages, page);
+		}
+
+		ArrayList<Page> dirtyPagesArr = new ArrayList<Page>();
+		dirtyPagesArr.addAll(dirtypages.values());
+		return dirtyPagesArr;
+	}
+
+	/**
+	 * Get a read lock on the root pointer page. Create the root pointer page and root page
+	 * if necessary.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages 
+	 * @return the root pointer page
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private BTreeRootPtrPage getRootPtrPage(TransactionId tid, HashMap<PageId, Page> dirtypages) throws DbException, IOException, TransactionAbortedException {
+		synchronized(this) {
+			if(f.length() == 0) {
+				// create the root pointer page and the root page
+				BufferedOutputStream bw = new BufferedOutputStream(
+						new FileOutputStream(f, true));
+				byte[] emptyRootPtrData = BTreeRootPtrPage.createEmptyPageData();
+				byte[] emptyLeafData = BTreeLeafPage.createEmptyPageData();
+				bw.write(emptyRootPtrData);
+				bw.write(emptyLeafData);
+				bw.close();
+			}
+		}
+
+		// get a read lock on the root pointer page
+		return (BTreeRootPtrPage) getPage(tid, dirtypages, BTreeRootPtrPage.getId(tableid), Permissions.READ_ONLY);
+	}
+
+	/**
+	 * Get the page number of the first empty page in this BTreeFile.
+	 * Creates a new page if none of the existing pages are empty.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @return the page number of the first empty page
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected int getEmptyPageNo(TransactionId tid, HashMap<PageId, Page> dirtypages) 
+			throws DbException, IOException, TransactionAbortedException {
+		// get a read lock on the root pointer page and use it to locate the first header page
+		BTreeRootPtrPage rootPtr = getRootPtrPage(tid, dirtypages);
+		BTreePageId headerId = rootPtr.getHeaderId();
+		int emptyPageNo = 0;
+
+		if(headerId != null) {
+			BTreeHeaderPage headerPage = (BTreeHeaderPage) getPage(tid, dirtypages, headerId, Permissions.READ_ONLY);
+			int headerPageCount = 0;
+			// try to find a header page with an empty slot
+			while(headerPage != null && headerPage.getEmptySlot() == -1) {
+				headerId = headerPage.getNextPageId();
+				if(headerId != null) {
+					headerPage = (BTreeHeaderPage) getPage(tid, dirtypages, headerId, Permissions.READ_ONLY);
+					headerPageCount++;
+				}
+				else {
+					headerPage = null;
+				}
+			}
+
+			// if headerPage is not null, it must have an empty slot
+			if(headerPage != null) {
+				headerPage = (BTreeHeaderPage) getPage(tid, dirtypages, headerId, Permissions.READ_WRITE);
+				int emptySlot = headerPage.getEmptySlot();
+				headerPage.markSlotUsed(emptySlot, true);
+				emptyPageNo = headerPageCount * BTreeHeaderPage.getNumSlots() + emptySlot;
+			}
+		}
+
+		// at this point if headerId is null, either there are no header pages 
+		// or there are no free slots
+		if(headerId == null) {		
+			synchronized(this) {
+				// create the new page
+				BufferedOutputStream bw = new BufferedOutputStream(
+						new FileOutputStream(f, true));
+				byte[] emptyData = BTreeInternalPage.createEmptyPageData();
+				bw.write(emptyData);
+				bw.close();
+				emptyPageNo = numPages();
+			}
+		}
+
+		return emptyPageNo; 
+	}
+	
+	/**
+	 * Method to encapsulate the process of creating a new page.  It reuses old pages if possible,
+	 * and creates a new page if none are available.  It wipes the page on disk and in the cache and 
+	 * returns a clean copy locked with read-write permission
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param pgcateg - the BTreePageId category of the new page.  Either LEAF, INTERNAL, or HEADER
+	 * @return the new empty page
+	 * @see #getEmptyPageNo(TransactionId, HashMap)
+	 * @see #setEmptyPage(TransactionId, HashMap, int)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	private Page getEmptyPage(TransactionId tid, HashMap<PageId, Page> dirtypages, int pgcateg)
+			throws DbException, IOException, TransactionAbortedException {
+		// create the new page
+		int emptyPageNo = getEmptyPageNo(tid, dirtypages);
+		BTreePageId newPageId = new BTreePageId(tableid, emptyPageNo, pgcateg);
+		
+		// write empty page to disk
+		RandomAccessFile rf = new RandomAccessFile(f, "rw");
+		rf.seek(BTreeRootPtrPage.getPageSize() + (emptyPageNo-1) * BufferPool.getPageSize());
+		rf.write(BTreePage.createEmptyPageData());
+		rf.close();
+		
+		// make sure the page is not in the buffer pool	or in the local cache		
+		Database.getBufferPool().discardPage(newPageId);
+		dirtypages.remove(newPageId);
+		
+		return getPage(tid, dirtypages, newPageId, Permissions.READ_WRITE);
+	}
+
+	/**
+	 * Mark a page in this BTreeFile as empty. Find the corresponding header page 
+	 * (create it if needed), and mark the corresponding slot in the header page as empty.
+	 * 
+	 * @param tid - the transaction id
+	 * @param dirtypages - the list of dirty pages which should be updated with all new dirty pages
+	 * @param emptyPageNo - the page number of the empty page
+	 * @see #getEmptyPage(TransactionId, HashMap, int)
+	 * 
+	 * @throws DbException
+	 * @throws IOException
+	 * @throws TransactionAbortedException
+	 */
+	protected void setEmptyPage(TransactionId tid, HashMap<PageId, Page> dirtypages, int emptyPageNo) 
+			throws DbException, IOException, TransactionAbortedException {
+
+		// if this is the last page in the file (and not the only page), just 
+		// truncate the file
+		// @TODO: Commented out because we should probably do this somewhere else in case the transaction aborts....
+//		synchronized(this) {
+//			if(emptyPageNo == numPages()) {
+//				if(emptyPageNo <= 1) {
+//					// if this is the only page in the file, just return.
+//					// It just means we have an empty root page
+//					return;
+//				}
+//				long newSize = f.length() - BufferPool.getPageSize();
+//				FileOutputStream fos = new FileOutputStream(f, true);
+//				FileChannel fc = fos.getChannel();
+//				fc.truncate(newSize);
+//				fc.close();
+//				fos.close();
+//				return;
+//			}
+//		}
+
+		// otherwise, get a read lock on the root pointer page and use it to locate 
+		// the first header page
+		BTreeRootPtrPage rootPtr = getRootPtrPage(tid, dirtypages);
+		BTreePageId headerId = rootPtr.getHeaderId();
+		BTreePageId prevId = null;
+		int headerPageCount = 0;
+
+		// if there are no header pages, create the first header page and update
+		// the header pointer in the BTreeRootPtrPage
+		if(headerId == null) {
+			rootPtr = (BTreeRootPtrPage) getPage(tid, dirtypages, BTreeRootPtrPage.getId(tableid), Permissions.READ_WRITE);
+			
+			BTreeHeaderPage headerPage = (BTreeHeaderPage) getEmptyPage(tid, dirtypages, BTreePageId.HEADER);
+			headerId = headerPage.getId();
+			headerPage.init();
+			rootPtr.setHeaderId(headerId);
+		}
+
+		// iterate through all the existing header pages to find the one containing the slot
+		// corresponding to emptyPageNo
+		while(headerId != null && (headerPageCount + 1) * BTreeHeaderPage.getNumSlots() < emptyPageNo) {
+			BTreeHeaderPage headerPage = (BTreeHeaderPage) getPage(tid, dirtypages, headerId, Permissions.READ_ONLY);
+			prevId = headerId;
+			headerId = headerPage.getNextPageId();
+			headerPageCount++;
+		}
+
+		// at this point headerId should either be null or set with 
+		// the headerPage containing the slot corresponding to emptyPageNo.
+		// Add header pages until we have one with a slot corresponding to emptyPageNo
+		while((headerPageCount + 1) * BTreeHeaderPage.getNumSlots() < emptyPageNo) {
+			BTreeHeaderPage prevPage = (BTreeHeaderPage) getPage(tid, dirtypages, prevId, Permissions.READ_WRITE);
+			
+			BTreeHeaderPage headerPage = (BTreeHeaderPage) getEmptyPage(tid, dirtypages, BTreePageId.HEADER);
+			headerId = headerPage.getId();
+			headerPage.init();
+			headerPage.setPrevPageId(prevId);
+			prevPage.setNextPageId(headerId);
+			
+			headerPageCount++;
+			prevId = headerId;
+		}
+
+		// now headerId should be set with the headerPage containing the slot corresponding to 
+		// emptyPageNo
+		BTreeHeaderPage headerPage = (BTreeHeaderPage) getPage(tid, dirtypages, headerId, Permissions.READ_WRITE);
+		int emptySlot = emptyPageNo - headerPageCount * BTreeHeaderPage.getNumSlots();
+		headerPage.markSlotUsed(emptySlot, false);
+	}
+
+	/**
+	 * get the specified tuples from the file based on its IndexPredicate value on
+	 * behalf of the specified transaction. This method will acquire a read lock on
+	 * the affected pages of the file, and may block until the lock can be
+	 * acquired.
+	 * 
+	 * @param tid - the transaction id
+	 * @param ipred - the index predicate value to filter on
+	 * @return an iterator for the filtered tuples
+	 */
+	public DbFileIterator indexIterator(TransactionId tid, IndexPredicate ipred) {
+		return new BTreeSearchIterator(this, tid, ipred);
+	}
+
+	/**
+	 * Get an iterator for all tuples in this B+ tree file in sorted order. This method 
+	 * will acquire a read lock on the affected pages of the file, and may block until 
+	 * the lock can be acquired.
+	 * 
+	 * @param tid - the transaction id
+	 * @return an iterator for all the tuples in this file
+	 */
+	public DbFileIterator iterator(TransactionId tid) {
+		return new BTreeFileIterator(this, tid);
+	}
+
+}
+
+/**
+ * Helper class that implements the Java Iterator for tuples on a BTreeFile
+ */
+class BTreeFileIterator extends AbstractDbFileIterator {
+
+	Iterator<Tuple> it = null;
+	BTreeLeafPage curp = null;
+
+	TransactionId tid;
+	BTreeFile f;
+
+	/**
+	 * Constructor for this iterator
+	 * @param f - the BTreeFile containing the tuples
+	 * @param tid - the transaction id
+	 */
+	public BTreeFileIterator(BTreeFile f, TransactionId tid) {
+		this.f = f;
+		this.tid = tid;
+	}
+
+	/**
+	 * Open this iterator by getting an iterator on the first leaf page
+	 */
+	public void open() throws DbException, TransactionAbortedException {
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(
+				tid, BTreeRootPtrPage.getId(f.getId()), Permissions.READ_ONLY);
+		BTreePageId root = rootPtr.getRootId();
+		curp = f.findLeafPage(tid, root, Permissions.READ_ONLY, null);
+		it = curp.iterator();
+	}
+
+	/**
+	 * Read the next tuple either from the current page if it has more tuples or
+	 * from the next page by following the right sibling pointer.
+	 * 
+	 * @return the next tuple, or null if none exists
+	 */
+	@Override
+	protected Tuple readNext() throws TransactionAbortedException, DbException {
+		if (it != null && !it.hasNext())
+			it = null;
+
+		while (it == null && curp != null) {
+			BTreePageId nextp = curp.getRightSiblingId();
+			if(nextp == null) {
+				curp = null;
+			}
+			else {
+				curp = (BTreeLeafPage) Database.getBufferPool().getPage(tid,
+						nextp, Permissions.READ_ONLY);
+				it = curp.iterator();
+				if (!it.hasNext())
+					it = null;
+			}
+		}
+
+		if (it == null)
+			return null;
+		return it.next();
+	}
+
+	/**
+	 * rewind this iterator back to the beginning of the tuples
+	 */
+	public void rewind() throws DbException, TransactionAbortedException {
+		close();
+		open();
+	}
+
+	/**
+	 * close the iterator
+	 */
+	public void close() {
+		super.close();
+		it = null;
+		curp = null;
+	}
+}
+
+/**
+ * Helper class that implements the DbFileIterator for search tuples on a
+ * B+ Tree File
+ */
+class BTreeSearchIterator extends AbstractDbFileIterator {
+
+	Iterator<Tuple> it = null;
+	BTreeLeafPage curp = null;
+
+	TransactionId tid;
+	BTreeFile f;
+	IndexPredicate ipred;
+
+	/**
+	 * Constructor for this iterator
+	 * @param f - the BTreeFile containing the tuples
+	 * @param tid - the transaction id
+	 * @param ipred - the predicate to filter on
+	 */
+	public BTreeSearchIterator(BTreeFile f, TransactionId tid, IndexPredicate ipred) {
+		this.f = f;
+		this.tid = tid;
+		this.ipred = ipred;
+	}
+
+	/**
+	 * Open this iterator by getting an iterator on the first leaf page applicable
+	 * for the given predicate operation
+	 */
+	public void open() throws DbException, TransactionAbortedException {
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(
+				tid, BTreeRootPtrPage.getId(f.getId()), Permissions.READ_ONLY);
+		BTreePageId root = rootPtr.getRootId();
+		if(ipred.getOp() == Op.EQUALS || ipred.getOp() == Op.GREATER_THAN 
+				|| ipred.getOp() == Op.GREATER_THAN_OR_EQ) {
+			curp = f.findLeafPage(tid, root, Permissions.READ_ONLY, ipred.getField());
+		}
+		else {
+			curp = f.findLeafPage(tid, root, Permissions.READ_ONLY, null);
+		}
+		it = curp.iterator();
+	}
+
+	/**
+	 * Read the next tuple either from the current page if it has more tuples matching
+	 * the predicate or from the next page by following the right sibling pointer.
+	 * 
+	 * @return the next tuple matching the predicate, or null if none exists
+	 */
+	@Override
+	protected Tuple readNext() throws TransactionAbortedException, DbException,
+	NoSuchElementException {
+		while (it != null) {
+
+			while (it.hasNext()) {
+				Tuple t = it.next();
+				if (t.getField(f.keyField()).compare(ipred.getOp(), ipred.getField())) {
+					return t;
+				}
+				else if(ipred.getOp() == Op.LESS_THAN || ipred.getOp() == Op.LESS_THAN_OR_EQ) {
+					// if the predicate was not satisfied and the operation is less than, we have
+					// hit the end
+					return null;
+				}
+				else if(ipred.getOp() == Op.EQUALS && 
+						t.getField(f.keyField()).compare(Op.GREATER_THAN, ipred.getField())) {
+					// if the tuple is now greater than the field passed in and the operation
+					// is equals, we have reached the end
+					return null;
+				}
+			}
+
+			BTreePageId nextp = curp.getRightSiblingId();
+			// if there are no more pages to the right, end the iteration
+			if(nextp == null) {
+				return null;
+			}
+			else {
+				curp = (BTreeLeafPage) Database.getBufferPool().getPage(tid,
+						nextp, Permissions.READ_ONLY);
+				it = curp.iterator();
+			}
+		}
+
+		return null;
+	}
+
+	/**
+	 * rewind this iterator back to the beginning of the tuples
+	 */
+	public void rewind() throws DbException, TransactionAbortedException {
+		close();
+		open();
+	}
+
+	/**
+	 * close the iterator
+	 */
+	public void close() {
+		super.close();
+		it = null;
+	}
+}
diff -Naur lab2/src/java/simpledb/BTreeFileEncoder.java lab3/src/java/simpledb/BTreeFileEncoder.java
--- lab2/src/java/simpledb/BTreeFileEncoder.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeFileEncoder.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,723 @@
+package simpledb;
+
+import java.io.*;
+import java.util.*;
+
+import simpledb.Predicate.Op;
+
+/**
+ * BTreeFileEncoder reads a comma delimited text file and converts it to
+ * pages of binary data in the appropriate format for simpledb B+ tree
+ * pages.
+ */
+
+public class BTreeFileEncoder {
+
+	/**
+	 * Encode the file using the BTreeFile's Insert method.
+	 * 
+	 * @param tuples - list of tuples to add to the file
+	 * @param hFile - the file to temporarily store the data as a heap file on disk
+	 * @param bFile - the file on disk to back the resulting BTreeFile
+	 * @param keyField - the index of the key field for this B+ tree
+	 * @param numFields - the number of fields in each tuple
+	 * @return the BTreeFile
+	 */
+	public static BTreeFile convert(ArrayList<ArrayList<Integer>> tuples, File hFile, 
+			File bFile, int keyField, int numFields) throws IOException {
+		File tempInput = File.createTempFile("tempTable", ".txt");
+		tempInput.deleteOnExit();
+		BufferedWriter bw = new BufferedWriter(new FileWriter(tempInput));
+		for (ArrayList<Integer> tuple : tuples) {
+			int writtenFields = 0;
+			for (Integer field : tuple) {
+				writtenFields++;
+				if (writtenFields > numFields) {
+					bw.close();
+					throw new RuntimeException("Tuple has more than " + numFields + " fields: (" +
+							Utility.listToString(tuple) + ")");
+				}
+				bw.write(String.valueOf(field));
+				if (writtenFields < numFields) {
+					bw.write(',');
+				}
+			}
+			bw.write('\n');
+		}
+		bw.close();
+		return convert(tempInput, hFile, bFile, keyField, numFields);
+	}
+
+	/**
+	 * Encode the file using the BTreeFile's Insert method.
+	 * 
+	 * @param inFile - the raw text file containing the tuples
+	 * @param hFile - the file to temporarily store the data as a heap file on disk
+	 * @param bFile - the file on disk to back the resulting BTreeFile
+	 * @param keyField - the index of the key field for this B+ tree
+	 * @param numFields - the number of fields in each tuple
+	 * @return the BTreeFile
+	 */
+	public static BTreeFile convert(File inFile, File hFile, File bFile,
+			int keyField, int numFields)
+					throws IOException {
+		// convert the inFile to HeapFile first.
+		HeapFileEncoder.convert(inFile, hFile, BufferPool.getPageSize(), numFields);
+		HeapFile heapf = Utility.openHeapFile(numFields, hFile);
+
+		// add the heap file to B+ tree file
+		BTreeFile bf = BTreeUtility.openBTreeFile(numFields, bFile, keyField);
+
+		try {
+			TransactionId tid = new TransactionId();
+			DbFileIterator it = Database.getCatalog().getDatabaseFile(heapf.getId()).iterator(tid);
+			it.open();
+			int count = 0;
+			Transaction t = new Transaction();
+			while (it.hasNext()) {
+				Tuple tup = it.next();
+				Database.getBufferPool().insertTuple(t.getId(), bf.getId(), tup);
+				count++;
+				if(count >= 40) {
+					Database.getBufferPool().flushAllPages();
+					count = 0;
+				}
+				t.commit();
+				t = new Transaction();
+			}
+			it.close();
+		} catch(TransactionAbortedException te){
+			te.printStackTrace();
+			return bf;
+		} catch(DbException e) {
+			e.printStackTrace();
+			return bf;
+		} catch(IOException e) {
+			e.printStackTrace();
+			return bf;
+		}
+
+		try {
+			Database.getBufferPool().flushAllPages();
+		} catch(Exception e) {
+			e.printStackTrace();
+		}
+
+		return bf;
+
+	}
+
+	/** 
+	 * comparator to sort Tuples by key field
+	 */
+	public static class TupleComparator implements Comparator<Tuple> {
+		private int keyField;
+
+		/** 
+		 * Construct a TupleComparator
+		 * 
+		 * @param keyField - the index of the field the tuples are keyed on
+		 */
+		public TupleComparator(int keyField) {
+			this.keyField = keyField;
+		}
+
+		/**
+		 * Compare two tuples based on their key field
+		 * 
+		 * @return -1 if t1 < t2, 1 if t1 > t2, 0 if t1 == t2
+		 */
+		public int compare(Tuple t1, Tuple t2) {
+			int cmp = 0;
+			if(t1.getField(keyField).compare(Op.LESS_THAN, t2.getField(keyField))) {
+				cmp = -1;
+			}
+			else if(t1.getField(keyField).compare(Op.GREATER_THAN, t2.getField(keyField))) {
+				cmp = 1;
+			}
+			return cmp;
+		}
+	}
+
+	/**
+	 * Faster method to encode the B+ tree file
+	 * 
+	 * @param tuples - list of tuples to add to the file
+	 * @param hFile - the file to temporarily store the data as a heap file on disk
+	 * @param bFile - the file on disk to back the resulting BTreeFile
+	 * @param npagebytes - number of bytes per page
+	 * @param numFields - number of fields per tuple
+	 * @param typeAr - array containing the types of the tuples
+	 * @param fieldSeparator - character separating fields in the raw data file
+	 * @param keyField - the field of the tuples the B+ tree will be keyed on
+	 * @return the BTreeFile
+	 */
+	public static BTreeFile convert(ArrayList<ArrayList<Integer>> tuples, File hFile, 
+			File bFile, int npagebytes,
+			int numFields, Type[] typeAr, char fieldSeparator, int keyField) 
+					throws IOException, DbException, TransactionAbortedException {
+		File tempInput = File.createTempFile("tempTable", ".txt");
+		tempInput.deleteOnExit();
+		BufferedWriter bw = new BufferedWriter(new FileWriter(tempInput));
+		for (ArrayList<Integer> tuple : tuples) {
+			int writtenFields = 0;
+			for (Integer field : tuple) {
+				writtenFields++;
+				if (writtenFields > numFields) {
+					bw.close();
+					throw new RuntimeException("Tuple has more than " + numFields + " fields: (" +
+							Utility.listToString(tuple) + ")");
+				}
+				bw.write(String.valueOf(field));
+				if (writtenFields < numFields) {
+					bw.write(',');
+				}
+			}
+			bw.write('\n');
+		}
+		bw.close();
+		return convert(tempInput, hFile, bFile, npagebytes,
+				numFields, typeAr, fieldSeparator, keyField);
+	}
+
+	/** 
+	 * Faster method to encode the B+ tree file
+	 * 
+	 * @param inFile - the file containing the raw data
+	 * @param hFile - the data file for the HeapFile to be used as an intermediate conversion step
+	 * @param bFile - the data file for the BTreeFile
+	 * @param npagebytes - number of bytes per page
+	 * @param numFields - number of fields per tuple
+	 * @param typeAr - array containing the types of the tuples
+	 * @param fieldSeparator - character separating fields in the raw data file
+	 * @param keyField - the field of the tuples the B+ tree will be keyed on
+	 * @return the B+ tree file
+	 * @throws IOException
+	 * @throws DbException
+	 * @throws TransactionAbortedException
+	 */
+	public static BTreeFile convert(File inFile, File hFile, File bFile, int npagebytes,
+			int numFields, Type[] typeAr, char fieldSeparator, int keyField) 
+					throws IOException, DbException, TransactionAbortedException {
+		// convert the inFile to HeapFile first.
+		HeapFileEncoder.convert(inFile, hFile, BufferPool.getPageSize(), numFields);
+		HeapFile heapf = Utility.openHeapFile(numFields, hFile);
+
+		// read all the tuples from the heap file and sort them on the keyField
+		ArrayList<Tuple> tuples = new ArrayList<Tuple>();
+		TransactionId tid = new TransactionId();
+		DbFileIterator it = Database.getCatalog().getDatabaseFile(heapf.getId()).iterator(tid);
+		it.open();
+		while (it.hasNext()) {
+			Tuple tup = it.next();
+			tuples.add(tup);
+		}
+		it.close();
+		Collections.sort(tuples, new TupleComparator(keyField));
+
+		// add the tuples to B+ tree file
+		BTreeFile bf = BTreeUtility.openBTreeFile(numFields, bFile, keyField);
+		Type keyType = typeAr[keyField];
+		int tableid = bf.getId();
+
+		int nrecbytes = 0;
+		for (int i = 0; i < numFields ; i++) {
+			nrecbytes += typeAr[i].getLen();
+		}
+		// pointerbytes: left sibling pointer, right sibling pointer, parent pointer
+		int leafpointerbytes = 3 * BTreeLeafPage.INDEX_SIZE; 
+		int nrecords = (npagebytes * 8 - leafpointerbytes * 8) /  (nrecbytes * 8 + 1);  //floor comes for free
+
+		int nentrybytes = keyType.getLen() + BTreeInternalPage.INDEX_SIZE;
+		// pointerbytes: one extra child pointer, parent pointer, child page category
+		int internalpointerbytes = 2 * BTreeLeafPage.INDEX_SIZE + 1; 
+		int nentries = (npagebytes * 8 - internalpointerbytes * 8 - 1) /  (nentrybytes * 8 + 1);  //floor comes for free
+
+		ArrayList<ArrayList<BTreeEntry>> entries = new ArrayList<ArrayList<BTreeEntry>>();
+
+		// first add some bytes for the root pointer page
+		bf.writePage(new BTreeRootPtrPage(BTreeRootPtrPage.getId(tableid), 
+				BTreeRootPtrPage.createEmptyPageData()));
+
+		// next iterate through all the tuples and write out leaf pages
+		// and internal pages as they fill up.
+		// We wait until we have two full pages of tuples before writing out the first page
+		// so that we will not end up with any pages containing less than nrecords/2 tuples
+		// (unless it's the only page)
+		ArrayList<Tuple> page1 = new ArrayList<Tuple>();
+		ArrayList<Tuple> page2 = new ArrayList<Tuple>();
+		BTreePageId leftSiblingId = null;
+		for(Tuple tup : tuples) {
+			if(page1.size() < nrecords) {
+				page1.add(tup);
+			}
+			else if(page2.size() < nrecords) {
+				page2.add(tup);
+			}
+			else {
+				// write out a page of records
+				byte[] leafPageBytes = convertToLeafPage(page1, npagebytes, numFields, typeAr, keyField);
+				BTreePageId leafPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.LEAF);
+				BTreeLeafPage leafPage = new BTreeLeafPage(leafPid, leafPageBytes, keyField);
+				leafPage.setLeftSiblingId(leftSiblingId);
+				bf.writePage(leafPage);
+				leftSiblingId = leafPid;
+
+				// update the parent by "copying up" the next key
+				BTreeEntry copyUpEntry = new BTreeEntry(page2.get(0).getField(keyField), leafPid, null);
+				updateEntries(entries, bf, copyUpEntry, 0, nentries, npagebytes, 
+						keyType, tableid, keyField);
+
+				page1 = page2;
+				page2 = new ArrayList<Tuple>();
+				page2.add(tup);
+			}
+		}
+
+		// now we need to deal with the end cases. There are two options:
+		// 1. We have less than or equal to a full page of records. Because of the way the code
+		//    was written above, we know this must be the only page
+		// 2. We have somewhere between one and two pages of records remaining.
+		// For case (1), we write out the page 
+		// For case (2), we divide the remaining records equally between the last two pages,
+		// write them out, and update the parent's child pointers.
+		BTreePageId lastPid = null;
+		if(page2.size() == 0) {
+			// write out a page of records - this is the root page
+			byte[] lastPageBytes = convertToLeafPage(page1, npagebytes, numFields, typeAr, keyField);
+			lastPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.LEAF);
+			BTreeLeafPage lastPage = new BTreeLeafPage(lastPid, lastPageBytes, keyField);
+			lastPage.setLeftSiblingId(leftSiblingId);
+			bf.writePage(lastPage);
+		}
+		else {
+			// split the remaining tuples in half
+			int remainingTuples = page1.size() + page2.size();
+			ArrayList<Tuple> secondToLastPg = new ArrayList<Tuple>();
+			ArrayList<Tuple> lastPg = new ArrayList<Tuple>();
+			secondToLastPg.addAll(page1.subList(0, remainingTuples/2));
+			lastPg.addAll(page1.subList(remainingTuples/2, page1.size()));
+			lastPg.addAll(page2);
+
+			// write out the last two pages of records
+			byte[] secondToLastPageBytes = convertToLeafPage(secondToLastPg, npagebytes, numFields, typeAr, keyField);
+			BTreePageId secondToLastPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.LEAF);
+			BTreeLeafPage secondToLastPage = new BTreeLeafPage(secondToLastPid, secondToLastPageBytes, keyField);
+			secondToLastPage.setLeftSiblingId(leftSiblingId);
+			bf.writePage(secondToLastPage);
+
+			byte[] lastPageBytes = convertToLeafPage(lastPg, npagebytes, numFields, typeAr, keyField);
+			lastPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.LEAF);
+			BTreeLeafPage lastPage = new BTreeLeafPage(lastPid, lastPageBytes, keyField);
+			lastPage.setLeftSiblingId(secondToLastPid);
+			bf.writePage(lastPage);
+
+			// update the parent by "copying up" the next key
+			BTreeEntry copyUpEntry = new BTreeEntry(lastPg.get(0).getField(keyField), secondToLastPid, lastPid);
+			updateEntries(entries, bf, copyUpEntry, 0, nentries, npagebytes, 
+					keyType, tableid, keyField);
+		}
+
+		// Write out the remaining internal pages
+		cleanUpEntries(entries, bf, nentries, npagebytes, keyType, tableid, keyField);
+
+		// update the root pointer to point to the last page of the file
+		int root = bf.numPages();
+		int rootCategory = (root > 1 ? BTreePageId.INTERNAL : BTreePageId.LEAF);
+		byte[] rootPtrBytes = convertToRootPtrPage(root, rootCategory, 0);
+		bf.writePage(new BTreeRootPtrPage(BTreeRootPtrPage.getId(tableid), rootPtrBytes));
+
+		// set all the parent and sibling pointers
+		setParents(bf, new BTreePageId(tableid, root, rootCategory), BTreeRootPtrPage.getId(tableid));
+		setRightSiblingPtrs(bf, lastPid, null);
+
+		Database.resetBufferPool(BufferPool.DEFAULT_PAGES);
+		return bf;
+	}
+
+	/**
+	 * Set all the right sibling pointers by following the left sibling pointers
+	 * 
+	 * @param bf - the BTreeFile
+	 * @param pid - the id of the page to update with the right sibling pointer
+	 * @param rightSiblingId - the id of the page's right sibling
+	 * @throws IOException
+	 * @throws DbException
+	 */
+	private static void setRightSiblingPtrs(BTreeFile bf, BTreePageId pid, BTreePageId rightSiblingId) 
+			throws IOException, DbException {
+		BTreeLeafPage page = (BTreeLeafPage) bf.readPage(pid);
+		page.setRightSiblingId(rightSiblingId);
+		BTreePageId leftSiblingId = page.getLeftSiblingId();
+		bf.writePage(page);
+		if(leftSiblingId != null) {
+			setRightSiblingPtrs(bf, leftSiblingId, page.getId());
+		}
+	}
+
+	/**
+	 * Recursive function to set all the parent pointers
+	 * 
+	 * @param bf - the BTreeFile
+	 * @param pid - id of the page to update with the parent pointer
+	 * @param parent - the id of the page's parent
+	 * @throws IOException
+	 * @throws DbException
+	 */
+	private static void setParents(BTreeFile bf, BTreePageId pid, BTreePageId parent) 
+			throws IOException, DbException {
+		if(pid.pgcateg() == BTreePageId.INTERNAL) {
+			BTreeInternalPage page = (BTreeInternalPage) bf.readPage(pid);
+			page.setParentId(parent);
+
+			Iterator<BTreeEntry> it = page.iterator();
+			BTreeEntry e = null;
+			while(it.hasNext()) {
+				e = it.next();
+				setParents(bf, e.getLeftChild(), pid);
+			}
+			if(e != null) {
+				setParents(bf, e.getRightChild(), pid);
+			}
+			bf.writePage(page);
+		}
+		else { // pid.pgcateg() == BTreePageId.LEAF
+			BTreeLeafPage page = (BTreeLeafPage) bf.readPage(pid);
+			page.setParentId(parent);
+			bf.writePage(page);
+		}
+	}
+
+	/**
+	 * Write out any remaining entries and update the parent pointers.
+	 * 
+	 * @param entries - the list of remaining entries
+	 * @param bf - the BTreeFile
+	 * @param nentries - number of entries per page
+	 * @param npagebytes - number of bytes per page
+	 * @param keyType - the type of the key field
+	 * @param tableid - the table id of this BTreeFile
+	 * @param keyField - the index of the key field
+	 * @throws IOException
+	 */
+	private static void cleanUpEntries(ArrayList<ArrayList<BTreeEntry>> entries,
+			BTreeFile bf, int nentries, int npagebytes, Type keyType, int tableid, 
+			int keyField) throws IOException {
+		// As with the leaf pages, there are two options:
+		// 1. We have less than or equal to a full page of entries. Because of the way the code
+		//    was written, we know this must be the root page
+		// 2. We have somewhere between one and two pages of entries remaining.
+		// For case (1), we write out the page 
+		// For case (2), we divide the remaining entries equally between the last two pages,
+		// write them out, and update the parent's child pointers.
+		for(int i = 0; i < entries.size(); i++) {
+			int childPageCategory = (i == 0 ? BTreePageId.LEAF : BTreePageId.INTERNAL);
+			int size = entries.get(i).size();
+			if(size <= nentries) {
+				// write out a page of entries
+				byte[] internalPageBytes = convertToInternalPage(entries.get(i), npagebytes, keyType, childPageCategory);
+				BTreePageId internalPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.INTERNAL);
+				bf.writePage(new BTreeInternalPage(internalPid, internalPageBytes, keyField));
+			}
+			else {
+				// split the remaining entries in half
+				ArrayList<BTreeEntry> secondToLastPg = new ArrayList<BTreeEntry>();
+				ArrayList<BTreeEntry> lastPg = new ArrayList<BTreeEntry>();
+				secondToLastPg.addAll(entries.get(i).subList(0, size/2));
+				lastPg.addAll(entries.get(i).subList(size/2 + 1, size));
+
+				// write out the last two pages of entries
+				byte[] secondToLastPageBytes = convertToInternalPage(secondToLastPg, npagebytes, keyType, childPageCategory);
+				BTreePageId secondToLastPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.INTERNAL);
+				bf.writePage(new BTreeInternalPage(secondToLastPid, secondToLastPageBytes, keyField));
+
+				byte[] lastPageBytes = convertToInternalPage(lastPg, npagebytes, keyType, childPageCategory);
+				BTreePageId lastPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.INTERNAL);
+				bf.writePage(new BTreeInternalPage(lastPid, lastPageBytes, keyField));
+
+				// update the parent by "pushing up" the next key
+				BTreeEntry pushUpEntry = new BTreeEntry(entries.get(i).get(size/2).getKey(), secondToLastPid, lastPid);
+				updateEntries(entries, bf, pushUpEntry, i+1, nentries, npagebytes, 
+						keyType, tableid, keyField);
+			}
+
+		}
+	}
+
+	/**
+	 * Recursive function to update the entries by adding a new Entry at a particular level
+	 * 
+	 * @param entries - the list of entries
+	 * @param bf - the BTreefile
+	 * @param e - the new entry 
+	 * @param level - the level of the new entry (0 is closest to the leaf pages)
+	 * @param nentries - number of entries per page
+	 * @param npagebytes - number of bytes per page
+	 * @param keyType - the type of the key field
+	 * @param tableid - the table id of this BTreeFile
+	 * @param keyField - the index of the key field
+	 * @throws IOException
+	 */
+	private static void updateEntries(ArrayList<ArrayList<BTreeEntry>> entries, 
+			BTreeFile bf, BTreeEntry e, int level, int nentries, int npagebytes, Type keyType, 
+			int tableid, int keyField) throws IOException {
+		while(entries.size() <= level) {
+			entries.add(new ArrayList<BTreeEntry>());
+		}
+
+		int childPageCategory = (level == 0 ? BTreePageId.LEAF : BTreePageId.INTERNAL);
+		int size = entries.get(level).size();
+
+		if(size > 0) {
+			BTreeEntry prev = entries.get(level).get(size-1);
+			entries.get(level).set(size-1, new BTreeEntry(prev.getKey(), prev.getLeftChild(), e.getLeftChild()));
+			if(size == nentries * 2 + 1) {
+				// write out a page of entries
+				ArrayList<BTreeEntry> pageEntries = new ArrayList<BTreeEntry>();
+				pageEntries.addAll(entries.get(level).subList(0, nentries));
+				byte[] internalPageBytes = convertToInternalPage(pageEntries, npagebytes, keyType, childPageCategory);
+				BTreePageId internalPid = new BTreePageId(tableid, bf.numPages() + 1, BTreePageId.INTERNAL);
+				bf.writePage(new BTreeInternalPage(internalPid, internalPageBytes, keyField));
+
+				// update the parent by "pushing up" the next key
+				BTreeEntry pushUpEntry = new BTreeEntry(entries.get(level).get(nentries).getKey(), internalPid, null);
+				updateEntries(entries, bf, pushUpEntry, level + 1, nentries, npagebytes, 
+						keyType, tableid, keyField);
+				ArrayList<BTreeEntry> remainingEntries = new ArrayList<BTreeEntry>();
+				remainingEntries.addAll(entries.get(level).subList(nentries+1, size));
+				entries.get(level).clear();
+				entries.get(level).addAll(remainingEntries);
+			}
+		}
+		entries.get(level).add(e);
+	}
+
+	/**
+	 * Convert a set of tuples to a byte array in the format of a BTreeLeafPage
+	 * 
+	 * @param tuples - the set of tuples
+	 * @param npagebytes - number of bytes per page
+	 * @param numFields - number of fields in each tuple
+	 * @param typeAr - array containing the types of the tuples
+	 * @param keyField - the field of the tuples the B+ tree will be keyed on
+	 * @return a byte array which can be passed to the BTreeLeafPage constructor
+	 * @throws IOException
+	 */
+	public static byte[] convertToLeafPage(ArrayList<Tuple> tuples, int npagebytes,
+			int numFields, Type[] typeAr, int keyField)
+					throws IOException {
+		int nrecbytes = 0;
+		for (int i = 0; i < numFields ; i++) {
+			nrecbytes += typeAr[i].getLen();
+		}
+		// pointerbytes: left sibling pointer, right sibling pointer, parent pointer
+		int pointerbytes = 3 * BTreeLeafPage.INDEX_SIZE; 
+		int nrecords = (npagebytes * 8 - pointerbytes * 8) /  (nrecbytes * 8 + 1);  //floor comes for free
+
+		//  per record, we need one bit; there are nrecords per page, so we need
+		// nrecords bits, i.e., ((nrecords/32)+1) integers.
+		int nheaderbytes = (nrecords / 8);
+		if (nheaderbytes * 8 < nrecords)
+			nheaderbytes++;  //ceiling
+		int nheaderbits = nheaderbytes * 8;
+
+		ByteArrayOutputStream baos = new ByteArrayOutputStream(npagebytes);
+		DataOutputStream dos = new DataOutputStream(baos);
+
+		// write out the pointers and the header of the page,
+		// then sort the tuples on the keyField and write out the tuples.
+		//
+		// in the header, write a 1 for bits that correspond to records we've
+		// written and 0 for empty slots.
+
+		int recordcount = tuples.size();
+		if (recordcount > nrecords)
+			recordcount = nrecords;
+
+		dos.writeInt(0); // parent pointer
+		dos.writeInt(0); // left sibling pointer
+		dos.writeInt(0); // right sibling pointer
+
+		int i = 0;
+		byte headerbyte = 0;
+
+		for (i=0; i<nheaderbits; i++) {
+			if (i < recordcount)
+				headerbyte |= (1 << (i % 8));
+
+			if (((i+1) % 8) == 0) {
+				dos.writeByte(headerbyte);
+				headerbyte = 0;
+			}
+		}
+
+		if (i % 8 > 0)
+			dos.writeByte(headerbyte);
+
+		Collections.sort(tuples, new TupleComparator(keyField));
+		for(int t = 0; t < recordcount; t++) {
+			TupleDesc td = tuples.get(t).getTupleDesc();
+			for(int j = 0; j < td.numFields(); j++) {
+				tuples.get(t).getField(j).serialize(dos);
+			}
+		}
+
+		// pad the rest of the page with zeroes
+		for (i=0; i<(npagebytes - (recordcount * nrecbytes + nheaderbytes + pointerbytes)); i++)
+			dos.writeByte(0);
+
+		return baos.toByteArray();
+	}
+
+	/**
+	 *  Comparator to sort BTreeEntry objects by key
+	 */
+	public static class EntryComparator implements Comparator<BTreeEntry> {
+		/**
+		 * Compare two entries based on their key field
+		 * 
+		 * @return -1 if e1 < e2, 1 if e1 > e2, 0 if e1 == e2
+		 */
+		public int compare(BTreeEntry e1, BTreeEntry e2) {
+			int cmp = 0;
+			if(e1.getKey().compare(Op.LESS_THAN, e2.getKey())) {
+				cmp = -1;
+			}
+			else if(e1.getKey().compare(Op.GREATER_THAN, e2.getKey())) {
+				cmp = 1;
+			}
+			return cmp;
+		}
+	}
+
+	/**
+	 *  Comparator to sort BTreeEntry objects by key in descending order
+	 */
+	public static class ReverseEntryComparator implements Comparator<BTreeEntry> {
+		/**
+		 * Compare two entries based on their key field
+		 * 
+		 * @return -1 if e1 > e2, 1 if e1 < e2, 0 if e1 == e2
+		 */
+		public int compare(BTreeEntry e1, BTreeEntry e2) {
+			int cmp = 0;
+			if(e1.getKey().compare(Op.GREATER_THAN, e2.getKey())) {
+				cmp = -1;
+			}
+			else if(e1.getKey().compare(Op.LESS_THAN, e2.getKey())) {
+				cmp = 1;
+			}
+			return cmp;
+		}
+	}
+
+	/**
+	 * Convert a set of entries to a byte array in the format of a BTreeInternalPage
+	 * 
+	 * @param entries - the set of entries
+	 * @param npagebytes - number of bytes per page
+	 * @param keyType - the type of the key field
+	 * @param childPageCategory - the category of the child pages (either internal or leaf)
+	 * @return a byte array which can be passed to the BTreeInternalPage constructor
+	 * @throws IOException
+	 */
+	public static byte[] convertToInternalPage(ArrayList<BTreeEntry> entries, int npagebytes,
+			Type keyType, int childPageCategory)
+					throws IOException {
+		int nentrybytes = keyType.getLen() + BTreeInternalPage.INDEX_SIZE;
+		// pointerbytes: one extra child pointer, parent pointer, child page category
+		int pointerbytes = 2 * BTreeLeafPage.INDEX_SIZE + 1; 
+		int nentries = (npagebytes * 8 - pointerbytes * 8 - 1) /  (nentrybytes * 8 + 1);  //floor comes for free
+
+		//  per entry, we need one bit; there are nentries per page, so we need
+		// nentries bits, plus 1 for the extra child pointer.
+		int nheaderbytes = (nentries + 1) / 8;
+		if (nheaderbytes * 8 < nentries + 1)
+			nheaderbytes++;  //ceiling
+		int nheaderbits = nheaderbytes * 8;
+
+		ByteArrayOutputStream baos = new ByteArrayOutputStream(npagebytes);
+		DataOutputStream dos = new DataOutputStream(baos);
+
+		// write out the pointers and the header of the page,
+		// then sort the entries and write them out.
+		//
+		// in the header, write a 1 for bits that correspond to entries we've
+		// written and 0 for empty slots.
+		int entrycount = entries.size();
+		if (entrycount > nentries)
+			entrycount = nentries;
+
+		dos.writeInt(0); // parent pointer
+		dos.writeByte((byte) childPageCategory);
+
+		int i = 0;
+		byte headerbyte = 0;
+
+		for (i=0; i<nheaderbits; i++) {
+			if (i < entrycount + 1)
+				headerbyte |= (1 << (i % 8));
+
+			if (((i+1) % 8) == 0) {
+				dos.writeByte(headerbyte);
+				headerbyte = 0;
+			}
+		}
+
+		if (i % 8 > 0)
+			dos.writeByte(headerbyte);
+
+		Collections.sort(entries, new EntryComparator());
+		for(int e = 0; e < entrycount; e++) {
+			entries.get(e).getKey().serialize(dos);
+		}
+
+		for(int e = entrycount; e < nentries; e++) {
+			for (int j=0; j<keyType.getLen(); j++) {
+				dos.writeByte(0);
+			}
+		}
+
+		dos.writeInt(entries.get(0).getLeftChild().pageNumber());
+		for(int e = 0; e < entrycount; e++) {
+			dos.writeInt(entries.get(e).getRightChild().pageNumber());
+		}
+
+		for(int e = entrycount; e < nentries; e++) {
+			for (int j=0; j<BTreeInternalPage.INDEX_SIZE; j++) {
+				dos.writeByte(0);
+			}
+		}
+
+		// pad the rest of the page with zeroes
+		for (i=0; i<(npagebytes - (nentries * nentrybytes + nheaderbytes + pointerbytes)); i++)
+			dos.writeByte(0);
+
+		return baos.toByteArray();
+
+	}
+
+	/**
+	 * Create a byte array in the format of a BTreeRootPtrPage
+	 * 
+	 * @param root - the page number of the root page
+	 * @param rootCategory - the category of the root page (leaf or internal)
+	 * @param header - the page number of the first header page
+	 * @return a byte array which can be passed to the BTreeRootPtrPage constructor
+	 * @throws IOException
+	 */
+	public static byte[] convertToRootPtrPage(int root, int rootCategory, int header)
+			throws IOException {
+
+		ByteArrayOutputStream baos = new ByteArrayOutputStream(BTreeRootPtrPage.getPageSize());
+		DataOutputStream dos = new DataOutputStream(baos);
+
+		dos.writeInt(root); // root pointer
+		dos.writeByte((byte) rootCategory); // root page category
+
+		dos.writeInt(header); // header pointer
+
+		return baos.toByteArray();
+	}
+
+}
diff -Naur lab2/src/java/simpledb/BTreeHeaderPage.java lab3/src/java/simpledb/BTreeHeaderPage.java
--- lab2/src/java/simpledb/BTreeHeaderPage.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeHeaderPage.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,306 @@
+package simpledb;
+
+import java.io.*;
+
+/**
+ * Each instance of BTreeHeaderPage stores data for one page of a BTreeFile and 
+ * implements the Page interface that is used by BufferPool.
+ *
+ * @see BTreeFile
+ * @see BufferPool
+ *
+ */
+public class BTreeHeaderPage implements Page {
+	private volatile boolean dirty = false;
+	private volatile TransactionId dirtier = null;
+	
+	final static int INDEX_SIZE = Type.INT_TYPE.getLen();
+
+	final BTreePageId pid;
+	final byte header[];
+	final int numSlots;
+
+	private int nextPage; // next header page or 0
+	private int prevPage; // previous header page or 0
+
+	byte[] oldData;
+	private final Byte oldDataLock=new Byte((byte)0);
+
+	/**
+	 * Create a BTreeHeaderPage from a set of bytes of data read from disk.
+	 * The format of a BTreeHeaderPage is two pointers to the next and previous
+	 * header pages, followed by a set of bytes indicating which pages in the file
+	 * are used or available
+	 * @see BufferPool#getPageSize()
+	 * 
+	 */
+	public BTreeHeaderPage(BTreePageId id, byte[] data) throws IOException {
+		this.pid = id;
+		this.numSlots = getNumSlots();
+		DataInputStream dis = new DataInputStream(new ByteArrayInputStream(data));
+
+		// Read the next and prev pointers
+		try {
+			Field f = Type.INT_TYPE.parse(dis);
+			this.nextPage = ((IntField) f).getValue();
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+		}
+
+		try {
+			Field f = Type.INT_TYPE.parse(dis);
+			this.prevPage = ((IntField) f).getValue();
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+		}
+
+		// allocate and read the header slots of this page
+		header = new byte[getHeaderSize()];
+		for (int i=0; i<header.length; i++)
+			header[i] = dis.readByte();
+
+		dis.close();
+
+		setBeforeImage();
+	}
+
+	/**
+	 * Initially mark all slots in the header used.
+	 */
+	public void init() {
+		for (int i=0; i<header.length; i++)
+			header[i] = (byte) 0xFF;
+	}
+
+	/**
+	 * Computes the number of bytes in the header while saving room for pointers
+	 */
+	private static int getHeaderSize() {        
+		// pointerBytes: nextPage and prevPage pointers
+		int pointerBytes = 2 * INDEX_SIZE; 
+		return BufferPool.getPageSize() - pointerBytes;
+	}
+
+	/**
+	 * Computes the number of slots in the header
+	 */
+	public static int getNumSlots() {        
+		return getHeaderSize() * 8;
+	}
+
+	/** Return a view of this page before it was modified
+        -- used by recovery */
+	public BTreeHeaderPage getBeforeImage(){
+		try {
+			byte[] oldDataRef = null;
+			synchronized(oldDataLock)
+			{
+				oldDataRef = oldData;
+			}
+			return new BTreeHeaderPage(pid,oldDataRef);
+		} catch (IOException e) {
+			e.printStackTrace();
+			//should never happen -- we parsed it OK before!
+			System.exit(1);
+		}
+		return null;
+	}
+
+	public void setBeforeImage() {
+		synchronized(oldDataLock)
+		{
+			oldData = getPageData().clone();
+		}
+	}
+
+	/**
+	 * @return the PageId associated with this page.
+	 */
+	public BTreePageId getId() {
+		return pid;
+	}
+
+	/**
+	 * Generates a byte array representing the contents of this page.
+	 * Used to serialize this page to disk.
+	 * <p>
+	 * The invariant here is that it should be possible to pass the byte
+	 * array generated by getPageData to the BTreeHeaderPage constructor and
+	 * have it produce an identical BTreeHeaderPage object.
+	 *
+	 * @see #BTreeHeaderPage
+	 * @return A byte array correspond to the bytes of this page.
+	 */
+	public byte[] getPageData() {
+		int len = BufferPool.getPageSize();
+		ByteArrayOutputStream baos = new ByteArrayOutputStream(len);
+		DataOutputStream dos = new DataOutputStream(baos);
+
+		// write out the next and prev pointers
+		try {
+			dos.writeInt(nextPage);
+
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+		try {
+			dos.writeInt(prevPage);
+
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		// create the header of the page
+		for (int i=0; i<header.length; i++) {
+			try {
+				dos.writeByte(header[i]);
+			} catch (IOException e) {
+				// this really shouldn't happen
+				e.printStackTrace();
+			}
+		}
+
+		try {
+			dos.flush();
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		return baos.toByteArray();
+	}
+
+	/**
+	 * Static method to generate a byte array corresponding to an empty
+	 * BTreeHeaderPage.
+	 * Used to add new, empty pages to the file. Passing the results of
+	 * this method to the BTreeHeaderPage constructor will create a BTreeHeaderPage with
+	 * no valid data in it.
+	 *
+	 * @return The returned ByteArray.
+	 */
+	public static byte[] createEmptyPageData() {
+		int len = BufferPool.getPageSize();
+		return new byte[len]; //all 0
+	}
+
+	/**
+	 * Get the page id of the previous header page
+	 * @return the page id of the previous header page
+	 */
+	public BTreePageId getPrevPageId() {
+		if(prevPage == 0) {
+			return null;
+		}
+		return new BTreePageId(pid.getTableId(), prevPage, BTreePageId.HEADER);
+	}
+
+	/**
+	 * Get the page id of the next header page
+	 * @return the page id of the next header page
+	 */
+	public BTreePageId getNextPageId() {
+		if(nextPage == 0) {
+			return null;
+		}
+		return new BTreePageId(pid.getTableId(), nextPage, BTreePageId.HEADER);
+	}
+
+	/**
+	 * Set the page id of the previous header page
+	 * @param id - the page id of the previous header page
+	 * @throws DbException
+	 */
+	public void setPrevPageId(BTreePageId id) throws DbException {
+		if(id == null) {
+			prevPage = 0;
+		}
+		else {
+			if(id.getTableId() != pid.getTableId()) {
+				throw new DbException("table id mismatch in setPrevPageId");
+			}
+			if(id.pgcateg() != BTreePageId.HEADER) {
+				throw new DbException("prevPage must be a header page");
+			}
+			prevPage = id.pageNumber();
+		}
+	}
+
+	/**
+	 * Set the page id of the next header page
+	 * @param id - the page id of the next header page
+	 * @throws DbException
+	 */
+	public void setNextPageId(BTreePageId id) throws DbException {
+		if(id == null) {
+			nextPage = 0;
+		}
+		else {
+			if(id.getTableId() != pid.getTableId()) {
+				throw new DbException("table id mismatch in setNextPageId");
+			}
+			if(id.pgcateg() != BTreePageId.HEADER) {
+				throw new DbException("nextPage must be a header page");
+			}
+			nextPage = id.pageNumber();
+		}
+	}
+
+	/**
+	 * Marks this page as dirty/not dirty and record that transaction
+	 * that did the dirtying
+	 */
+	public void markDirty(boolean dirty, TransactionId tid) {
+		this.dirty = dirty;
+		if (dirty) this.dirtier = tid;
+	}
+
+	/**
+	 * Returns the tid of the transaction that last dirtied this page, or null if the page is not dirty
+	 */
+	public TransactionId isDirty() {
+		if (this.dirty)
+			return this.dirtier;
+		else
+			return null;
+	}
+
+	/**
+	 * Returns true if the page of the BTreeFile associated with slot i is used
+	 */
+	public boolean isSlotUsed(int i) {
+		int headerbit = i % 8;
+		int headerbyte = (i - headerbit) / 8;
+		return (header[headerbyte] & (1 << headerbit)) != 0;
+	}
+
+	/**
+	 * Abstraction to mark a page of the BTreeFile used or unused
+	 */
+	public void markSlotUsed(int i, boolean value) {
+		int headerbit = i % 8;
+		int headerbyte = (i - headerbit) / 8;
+
+		Debug.log(1, "BTreeHeaderPage.setSlot: setting slot %d to %b", i, value);
+		if(value)
+			header[headerbyte] |= 1 << headerbit;
+		else
+			header[headerbyte] &= (0xFF ^ (1 << headerbit));
+	}
+
+	/**
+	 * get the index of the first empty slot
+	 * @return the index of the first empty slot or -1 if none exists
+	 */
+	public int getEmptySlot() {
+		for (int i=0; i<header.length; i++) {
+			if((int) header[i] != 0xFF) {
+				for(int j = 0; j < 8; j++) {
+					if(!isSlotUsed(i*8 + j)) {
+						return i*8 + j;
+					}
+				}
+			}
+		}
+		return -1;
+	}
+}
diff -Naur lab2/src/java/simpledb/BTreeInternalPage.java lab3/src/java/simpledb/BTreeInternalPage.java
--- lab2/src/java/simpledb/BTreeInternalPage.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeInternalPage.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,783 @@
+package simpledb;
+
+import java.util.*;
+import java.io.*;
+
+import simpledb.Predicate.Op;
+
+/**
+ * Each instance of BTreeInternalPage stores data for one page of a BTreeFile and 
+ * implements the Page interface that is used by BufferPool.
+ *
+ * @see BTreeFile
+ * @see BufferPool
+ *
+ */
+public class BTreeInternalPage extends BTreePage {
+	private final byte header[];
+	private final Field keys[];
+	private final int children[];
+	private final int numSlots;
+	
+	private int childCategory; // either leaf or internal
+	
+	/**
+	 * Create a BTreeInternalPage from a set of bytes of data read from disk.
+	 * The format of a BTreeInternalPage is a set of header bytes indicating
+	 * the slots of the page that are in use, some number of entry slots, and extra
+	 * bytes for the parent pointer, one extra child pointer (a node with m entries 
+	 * has m+1 pointers to children), and the category of all child pages (either 
+	 * leaf or internal).
+	 *  Specifically, the number of entries is equal to: <p>
+	 *          floor((BufferPool.getPageSize()*8 - extra bytes*8) / (entry size * 8 + 1))
+	 * <p> where entry size is the size of entries in this index node
+	 * (key + child pointer), which can be determined via the key field and 
+	 * {@link Catalog#getTupleDesc}.
+	 * The number of 8-bit header words is equal to:
+	 * <p>
+	 *      ceiling((no. entry slots + 1) / 8)
+	 * <p>
+	 * @see Database#getCatalog
+	 * @see Catalog#getTupleDesc
+	 * @see BufferPool#getPageSize()
+	 * 
+	 * @param id - the id of this page
+	 * @param data - the raw data of this page
+	 * @param key - the field which the index is keyed on
+	 */
+	public BTreeInternalPage(BTreePageId id, byte[] data, int key) throws IOException {
+		super(id, key);
+		this.numSlots = getMaxEntries() + 1;
+		DataInputStream dis = new DataInputStream(new ByteArrayInputStream(data));
+
+		// Read the parent pointer
+		try {
+			Field f = Type.INT_TYPE.parse(dis);
+			this.parent = ((IntField) f).getValue();
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+		}
+
+		// read the child page category
+		childCategory = (int) dis.readByte();
+
+		// allocate and read the header slots of this page
+		header = new byte[getHeaderSize()];
+		for (int i=0; i<header.length; i++)
+			header[i] = dis.readByte();
+
+		keys = new Field[numSlots];
+		try{
+			// allocate and read the keys of this page
+			// start from 1 because the first key slot is not used
+			// since a node with m keys has m+1 pointers
+			keys[0] = null;
+			for (int i=1; i<keys.length; i++)
+				keys[i] = readNextKey(dis,i);
+		}catch(NoSuchElementException e){
+			e.printStackTrace();
+		}
+
+		children = new int[numSlots];
+		try{
+			// allocate and read the child pointers of this page
+			for (int i=0; i<children.length; i++)
+				children[i] = readNextChild(dis,i);
+		}catch(NoSuchElementException e){
+			e.printStackTrace();
+		}
+		dis.close();
+
+		setBeforeImage();
+	}
+
+	/** 
+	 * Retrieve the maximum number of entries this page can hold. (The number of keys)
+ 	 */
+	public int getMaxEntries() {        
+		int keySize = td.getFieldType(keyField).getLen();
+		int bitsPerEntryIncludingHeader = keySize * 8 + INDEX_SIZE * 8 + 1;
+		// extraBits are: one parent pointer, 1 byte for child page category, 
+		// one extra child pointer (node with m entries has m+1 pointers to children), 1 bit for extra header
+		int extraBits = 2 * INDEX_SIZE * 8 + 8 + 1; 
+		int entriesPerPage = (BufferPool.getPageSize()*8 - extraBits) / bitsPerEntryIncludingHeader; //round down
+		return entriesPerPage;
+	}
+
+	/**
+	 * Computes the number of bytes in the header of a B+ internal page with each entry occupying entrySize bytes
+	 * @return the number of bytes in the header
+	 */
+	private int getHeaderSize() {        
+		int slotsPerPage = getMaxEntries() + 1;
+		int hb = (slotsPerPage / 8);
+		if (hb * 8 < slotsPerPage) hb++;
+
+		return hb;
+	}
+
+	/** Return a view of this page before it was modified
+        -- used by recovery */
+	public BTreeInternalPage getBeforeImage(){
+		try {
+			byte[] oldDataRef = null;
+			synchronized(oldDataLock)
+			{
+				oldDataRef = oldData;
+			}
+			return new BTreeInternalPage(pid,oldDataRef,keyField);
+		} catch (IOException e) {
+			e.printStackTrace();
+			//should never happen -- we parsed it OK before!
+			System.exit(1);
+		}
+		return null;
+	}
+
+	public void setBeforeImage() {
+		synchronized(oldDataLock)
+		{
+			oldData = getPageData().clone();
+		}
+	}
+
+	/**
+	 * Read keys from the source file.
+	 */
+	private Field readNextKey(DataInputStream dis, int slotId) throws NoSuchElementException {
+		// if associated bit is not set, read forward to the next key, and
+		// return null.
+		if (!isSlotUsed(slotId)) {
+			for (int i=0; i<td.getFieldType(keyField).getLen(); i++) {
+				try {
+					dis.readByte();
+				} catch (IOException e) {
+					throw new NoSuchElementException("error reading empty key");
+				}
+			}
+			return null;
+		}
+
+		// read the key field
+		Field f = null;
+		try {
+			f = td.getFieldType(keyField).parse(dis);
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+			throw new NoSuchElementException("parsing error!");
+		}
+
+		return f;
+	}
+
+	/**
+	 * Read child pointers from the source file.
+	 */
+	private int readNextChild(DataInputStream dis, int slotId) throws NoSuchElementException {
+		// if associated bit is not set, read forward to the next child pointer, and
+		// return -1.
+		if (!isSlotUsed(slotId)) {
+			for (int i=0; i<INDEX_SIZE; i++) {
+				try {
+					dis.readByte();
+				} catch (IOException e) {
+					throw new NoSuchElementException("error reading empty child pointer");
+				}
+			}
+			return -1;
+		}
+
+		// read child pointer
+		int child = -1;
+		try {
+			Field f = Type.INT_TYPE.parse(dis);
+			child = ((IntField) f).getValue();
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+			throw new NoSuchElementException("parsing error!");
+		}
+
+		return child;
+	}
+
+	/**
+	 * Generates a byte array representing the contents of this page.
+	 * Used to serialize this page to disk.
+	 * <p>
+	 * The invariant here is that it should be possible to pass the byte
+	 * array generated by getPageData to the BTreeInternalPage constructor and
+	 * have it produce an identical BTreeInternalPage object.
+	 *
+	 * @see #BTreeInternalPage
+	 * @return A byte array correspond to the bytes of this page.
+	 */
+	public byte[] getPageData() {
+		int len = BufferPool.getPageSize();
+		ByteArrayOutputStream baos = new ByteArrayOutputStream(len);
+		DataOutputStream dos = new DataOutputStream(baos);
+
+		// write out the parent pointer
+		try {
+			dos.writeInt(parent);
+
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		// write out the child page category
+		try {
+			dos.writeByte((byte) childCategory);
+
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		// create the header of the page
+		for (int i=0; i<header.length; i++) {
+			try {
+				dos.writeByte(header[i]);
+			} catch (IOException e) {
+				// this really shouldn't happen
+				e.printStackTrace();
+			}
+		}
+
+		// create the keys
+		// start from 1 because the first key slot is not used
+		// since a node with m keys has m+1 pointers
+		for (int i=1; i<keys.length; i++) {
+
+			// empty slot
+			if (!isSlotUsed(i)) {
+				for (int j=0; j<td.getFieldType(keyField).getLen(); j++) {
+					try {
+						dos.writeByte(0);
+					} catch (IOException e) {
+						e.printStackTrace();
+					}
+
+				}
+				continue;
+			}
+
+			// non-empty slot
+			try {
+				keys[i].serialize(dos);
+			} catch (IOException e) {
+				e.printStackTrace();
+			}
+
+		}
+
+		// create the child pointers
+		for (int i=0; i<children.length; i++) {
+
+			// empty slot
+			if (!isSlotUsed(i)) {
+				for (int j=0; j<INDEX_SIZE; j++) {
+					try {
+						dos.writeByte(0);
+					} catch (IOException e) {
+						e.printStackTrace();
+					}
+
+				}
+				continue;
+			}
+
+			// non-empty slot
+			try {
+				dos.writeInt(children[i]);
+
+			} catch (IOException e) {
+				e.printStackTrace();
+			}
+		}
+
+		// padding
+		int zerolen = BufferPool.getPageSize() - (INDEX_SIZE + 1 + header.length + 
+				td.getFieldType(keyField).getLen() * (keys.length - 1) + INDEX_SIZE * children.length); 
+		byte[] zeroes = new byte[zerolen];
+		try {
+			dos.write(zeroes, 0, zerolen);
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		try {
+			dos.flush();
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		return baos.toByteArray();
+	}
+
+	/**
+	 * Delete the specified entry (key + 1 child pointer) from the page. The recordId
+	 * is used to find the specified entry, so it must not be null. After deletion, the 
+	 * entry's recordId should be set to null to reflect that it is no longer stored on 
+	 * any page.
+	 * @throws DbException if this entry is not on this page, or entry slot is
+	 *         already empty.
+	 * @param e The entry to delete
+	 * @param deleteRightChild - if true, delete the right child. Otherwise
+	 *        delete the left child
+	 */
+	private void deleteEntry(BTreeEntry e, boolean deleteRightChild) throws DbException {
+		RecordId rid = e.getRecordId();
+		if(rid == null)
+			throw new DbException("tried to delete entry with null rid");
+		if((rid.getPageId().pageNumber() != pid.pageNumber()) || (rid.getPageId().getTableId() != pid.getTableId()))
+			throw new DbException("tried to delete entry on invalid page or table");
+		if (!isSlotUsed(rid.tupleno()))
+			throw new DbException("tried to delete null entry.");
+		if(deleteRightChild) {
+			markSlotUsed(rid.tupleno(), false); 
+		}
+		else {
+			for(int i = rid.tupleno() - 1; i >= 0; i--) {
+				if(isSlotUsed(i)) {
+					children[i] = children[rid.tupleno()];
+					markSlotUsed(rid.tupleno(), false); 
+					break;
+				}	
+			}
+		}
+		e.setRecordId(null);
+	}
+
+	/**
+	 * Delete the specified entry (key + right child pointer) from the page. The recordId
+	 * is used to find the specified entry, so it must not be null. After deletion, the 
+	 * entry's recordId should be set to null to reflect that it is no longer stored on 
+	 * any page.
+	 * @throws DbException if this entry is not on this page, or entry slot is
+	 *         already empty.
+	 * @param e The entry to delete
+	 */
+	public void deleteKeyAndRightChild(BTreeEntry e) throws DbException {
+		deleteEntry(e, true);
+	}
+	
+	/**
+	 * Delete the specified entry (key + left child pointer) from the page. The recordId
+	 * is used to find the specified entry, so it must not be null. After deletion, the 
+	 * entry's recordId should be set to null to reflect that it is no longer stored on 
+	 * any page.
+	 * @throws DbException if this entry is not on this page, or entry slot is
+	 *         already empty.
+	 * @param e The entry to delete
+	 */
+	public void deleteKeyAndLeftChild(BTreeEntry e) throws DbException {
+		deleteEntry(e, false);
+	}
+	
+	/**
+	 * Update the key and/or child pointers of an entry at the location specified by its 
+	 * record id.
+	 * @param e - the entry with updated key and/or child pointers
+	 * @throws DbException if this entry is not on this page, entry slot is
+	 *         already empty, or updating this key would put the entry out of 
+	 *         order on the page
+	 */
+	public void updateEntry(BTreeEntry e) throws DbException {
+		RecordId rid = e.getRecordId();
+		if(rid == null)
+			throw new DbException("tried to update entry with null rid");
+		if((rid.getPageId().pageNumber() != pid.pageNumber()) || (rid.getPageId().getTableId() != pid.getTableId()))
+			throw new DbException("tried to update entry on invalid page or table");
+		if (!isSlotUsed(rid.tupleno()))
+			throw new DbException("tried to update null entry.");
+		
+		for(int i = rid.tupleno() + 1; i < numSlots; i++) {
+			if(isSlotUsed(i)) {
+				if(keys[i].compare(Op.LESS_THAN, e.getKey())) {
+					throw new DbException("attempt to update entry with invalid key " + e.getKey() +
+							" HINT: updated key must be less than or equal to keys on the right");
+				}
+				break;
+			}	
+		}
+		for(int i = rid.tupleno() - 1; i >= 0; i--) {
+			if(isSlotUsed(i)) {
+				if(i > 0 && keys[i].compare(Op.GREATER_THAN, e.getKey())) {
+					throw new DbException("attempt to update entry with invalid key " + e.getKey() +
+							" HINT: updated key must be greater than or equal to keys on the left");
+				}
+				children[i] = e.getLeftChild().pageNumber();
+				break;
+			}	
+		}
+		children[rid.tupleno()] = e.getRightChild().pageNumber(); 
+		keys[rid.tupleno()] = e.getKey();
+	}
+
+	/**
+	 * Adds the specified entry to the page; the entry's recordId should be updated to 
+	 * reflect that it is now stored on this page.
+	 * @throws DbException if the page is full (no empty slots) or key field type,
+	 *         table id, or child page category is a mismatch, or the entry is invalid
+	 * @param e The entry to add.
+	 */
+	public void insertEntry(BTreeEntry e) throws DbException {
+		if (!e.getKey().getType().equals(td.getFieldType(keyField)))
+			throw new DbException("key field type mismatch, in insertEntry");
+
+		if(e.getLeftChild().getTableId() != pid.getTableId() || e.getRightChild().getTableId() != pid.getTableId())
+			throw new DbException("table id mismatch in insertEntry");
+
+		if(childCategory == 0) {
+			if(e.getLeftChild().pgcateg() != e.getRightChild().pgcateg())
+				throw new DbException("child page category mismatch in insertEntry");
+
+			childCategory = e.getLeftChild().pgcateg();
+		}
+		else if(e.getLeftChild().pgcateg() != childCategory || e.getRightChild().pgcateg() != childCategory)
+			throw new DbException("child page category mismatch in insertEntry");
+
+		// if this is the first entry, add it and return
+		if(getNumEmptySlots() == getMaxEntries()) {
+			children[0] = e.getLeftChild().pageNumber();
+			children[1] = e.getRightChild().pageNumber();
+			keys[1] = e.getKey();
+			markSlotUsed(0, true);
+			markSlotUsed(1, true);
+			e.setRecordId(new RecordId(pid, 1));
+			return;
+		}
+
+		// find the first empty slot, starting from 1
+		int emptySlot = -1;
+		for (int i=1; i<numSlots; i++) {
+			if (!isSlotUsed(i)) {
+				emptySlot = i;
+				break;
+			}
+		}
+
+		if (emptySlot == -1)
+			throw new DbException("called insertEntry on page with no empty slots.");        
+
+		// find the child pointer matching the left or right child in this entry
+		int lessOrEqKey = -1;
+		for (int i=0; i<numSlots; i++) {
+			if(isSlotUsed(i)) {
+				if(children[i] == e.getLeftChild().pageNumber() || children[i] == e.getRightChild().pageNumber()) {
+					if(i > 0 && keys[i].compare(Op.GREATER_THAN, e.getKey())) {
+						throw new DbException("attempt to insert invalid entry with left child " + 
+								e.getLeftChild().pageNumber() + ", right child " + 
+								e.getRightChild().pageNumber() + " and key " + e.getKey() +
+								" HINT: one of these children must match an existing child on the page" +
+								" and this key must be correctly ordered in between that child's" +
+								" left and right keys");
+					}
+					lessOrEqKey = i;
+					if(children[i] == e.getRightChild().pageNumber()) {
+						children[i] = e.getLeftChild().pageNumber();
+					}
+				}
+				else if(lessOrEqKey != -1) {
+					// validate that the next key is greater than or equal to the one we are inserting
+					if(keys[i].compare(Op.LESS_THAN, e.getKey())) {
+						throw new DbException("attempt to insert invalid entry with left child " + 
+								e.getLeftChild().pageNumber() + ", right child " + 
+								e.getRightChild().pageNumber() + " and key " + e.getKey() +
+								" HINT: one of these children must match an existing child on the page" +
+								" and this key must be correctly ordered in between that child's" +
+								" left and right keys");
+					}
+					break;
+				}
+			}
+		}
+
+		if(lessOrEqKey == -1) {
+			throw new DbException("attempt to insert invalid entry with left child " + 
+					e.getLeftChild().pageNumber() + ", right child " + 
+					e.getRightChild().pageNumber() + " and key " + e.getKey() +
+					" HINT: one of these children must match an existing child on the page" +
+					" and this key must be correctly ordered in between that child's" +
+					" left and right keys");
+		}
+
+		// shift entries back or forward to fill empty slot and make room for new entry
+		// while keeping entries in sorted order
+		int goodSlot = -1;
+		if(emptySlot < lessOrEqKey) {
+			for(int i = emptySlot; i < lessOrEqKey; i++) {
+				moveEntry(i+1, i);
+			}
+			goodSlot = lessOrEqKey;
+		}
+		else {
+			for(int i = emptySlot; i > lessOrEqKey + 1; i--) {
+				moveEntry(i-1, i);
+			}
+			goodSlot = lessOrEqKey + 1;
+		}
+
+		// insert new entry into the correct spot in sorted order
+		markSlotUsed(goodSlot, true);
+		Debug.log(1, "BTreeLeafPage.insertEntry: new entry, tableId = %d pageId = %d slotId = %d", pid.getTableId(), pid.pageNumber(), goodSlot);
+		keys[goodSlot] = e.getKey();
+		children[goodSlot] = e.getRightChild().pageNumber();
+		e.setRecordId(new RecordId(pid, goodSlot));
+	}
+
+	/**
+	 * Move an entry from one slot to another slot, and update the corresponding
+	 * headers
+	 */
+	private void moveEntry(int from, int to) {
+		if(!isSlotUsed(to) && isSlotUsed(from)) {
+			markSlotUsed(to, true);
+			keys[to] = keys[from];
+			children[to] = children[from];
+			markSlotUsed(from, false);
+		}
+	}
+
+	/**
+	 * Returns the number of entries (keys) currently stored on this page
+	 */
+	public int getNumEntries() {
+		return numSlots - getNumEmptySlots() - 1;
+	}
+	
+	/**
+	 * Returns the number of empty slots on this page.
+	 */
+	public int getNumEmptySlots() {
+		int cnt = 0;
+		// start from 1 because the first key slot is not used
+		// since a node with m keys has m+1 pointers
+		for(int i=1; i<numSlots; i++)
+			if(!isSlotUsed(i))
+				cnt++;
+		return cnt;
+	}
+
+	/**
+	 * Returns true if associated slot on this page is filled.
+	 */
+	public boolean isSlotUsed(int i) {
+		int headerbit = i % 8;
+		int headerbyte = (i - headerbit) / 8;
+		return (header[headerbyte] & (1 << headerbit)) != 0;
+	}
+
+	/**
+	 * Abstraction to fill or clear a slot on this page.
+	 */
+	private void markSlotUsed(int i, boolean value) {
+		int headerbit = i % 8;
+		int headerbyte = (i - headerbit) / 8;
+
+		Debug.log(1, "BTreeInternalPage.setSlot: setting slot %d to %b", i, value);
+		if(value)
+			header[headerbyte] |= 1 << headerbit;
+		else
+			header[headerbyte] &= (0xFF ^ (1 << headerbit));
+	}
+
+	/**
+	 * @return an iterator over all entries on this page (calling remove on this iterator throws an UnsupportedOperationException)
+	 * (note that this iterator shouldn't return entries in empty slots!)
+	 */
+	public Iterator<BTreeEntry> iterator() {
+		return new BTreeInternalPageIterator(this);
+	}
+	
+	/**
+	 * @return a reverse iterator over all entries on this page (calling remove on this iterator throws an UnsupportedOperationException)
+	 * (note that this iterator shouldn't return entries in empty slots!)
+	 */
+	public Iterator<BTreeEntry> reverseIterator() {
+		return new BTreeInternalPageReverseIterator(this);
+	}
+
+	/**
+	 * protected method used by the iterator to get the ith key out of this page
+	 * @param i - the index of the key
+	 * @return the ith key
+	 * @throws NoSuchElementException
+	 */
+	protected Field getKey(int i) throws NoSuchElementException {
+
+		// key at slot 0 is not used
+		if (i <= 0 || i >= keys.length)
+			throw new NoSuchElementException();
+
+		try {
+			if(!isSlotUsed(i)) {
+				Debug.log(1, "BTreeInternalPage.getKey: slot %d in %d:%d is not used", i, pid.getTableId(), pid.pageNumber());
+				return null;
+			}
+
+			Debug.log(1, "BTreeInternalPage.getKey: returning key %d", i);
+			return keys[i];
+
+		} catch (ArrayIndexOutOfBoundsException e) {
+			throw new NoSuchElementException();
+		}
+	}
+
+	/**
+	 * protected method used by the iterator to get the ith child page id out of this page
+	 * @param i - the index of the child page id
+	 * @return the ith child page id
+	 * @throws NoSuchElementException
+	 */
+	protected BTreePageId getChildId(int i) throws NoSuchElementException {
+
+		if (i < 0 || i >= children.length)
+			throw new NoSuchElementException();
+
+		try {
+			if(!isSlotUsed(i)) {
+				Debug.log(1, "BTreeInternalPage.getChildId: slot %d in %d:%d is not used", i, pid.getTableId(), pid.pageNumber());
+				return null;
+			}
+
+			Debug.log(1, "BTreeInternalPage.getChildId: returning child id %d", i);
+			return new BTreePageId(pid.getTableId(), children[i], childCategory);
+
+		} catch (ArrayIndexOutOfBoundsException e) {
+			throw new NoSuchElementException();
+		}
+	}
+}
+
+/**
+ * Helper class that implements the Java Iterator for entries on a BTreeInternalPage.
+ */
+class BTreeInternalPageIterator implements Iterator<BTreeEntry> {
+	int curEntry = 1;
+	BTreePageId prevChildId = null;
+	BTreeEntry nextToReturn = null;
+	BTreeInternalPage p;
+
+	public BTreeInternalPageIterator(BTreeInternalPage p) {
+		this.p = p;
+	}
+
+	public boolean hasNext() {
+		if (nextToReturn != null)
+			return true;
+
+		try {
+			if(prevChildId == null) {
+				prevChildId = p.getChildId(0);
+				if(prevChildId == null) {
+					return false;
+				}
+			}
+			while (true) {
+				int entry = curEntry++;
+				Field key = p.getKey(entry);
+				BTreePageId childId = p.getChildId(entry);
+				if(key != null && childId != null) {
+					nextToReturn = new BTreeEntry(key, prevChildId, childId);
+					nextToReturn.setRecordId(new RecordId(p.pid, entry));
+					prevChildId = childId;
+					return true;
+				}
+			}
+		} catch(NoSuchElementException e) {
+			return false;
+		}
+	}
+
+	public BTreeEntry next() {
+		BTreeEntry next = nextToReturn;
+
+		if (next == null) {
+			if (hasNext()) {
+				next = nextToReturn;
+				nextToReturn = null;
+				return next;
+			} else
+				throw new NoSuchElementException();
+		} else {
+			nextToReturn = null;
+			return next;
+		}
+	}
+
+	public void remove() {
+		throw new UnsupportedOperationException();
+	}
+}
+
+/**
+ * Helper class that implements the Java Iterator for entries on a BTreeInternalPage in reverse.
+ */
+class BTreeInternalPageReverseIterator implements Iterator<BTreeEntry> {
+	int curEntry;
+	BTreePageId childId = null;
+	Field key = null;
+	RecordId recordId = null;
+	BTreeEntry nextToReturn = null;
+	BTreeInternalPage p;
+
+	public BTreeInternalPageReverseIterator(BTreeInternalPage p) {
+		this.p = p;
+		this.curEntry = p.getMaxEntries();
+		while(!p.isSlotUsed(curEntry) && curEntry > 0) {
+			--curEntry;
+		}
+	}
+
+	public boolean hasNext() {
+		if (nextToReturn != null)
+			return true;
+
+		try {
+			if(childId == null || key == null || recordId == null) {
+				childId = p.getChildId(curEntry);
+				key = p.getKey(curEntry);
+				recordId = new RecordId(p.pid, curEntry);
+				if(childId == null || key == null) {
+					return false;
+				}
+			}
+			while (curEntry > 0) {
+				int entry = --curEntry;
+				BTreePageId nextChildId = p.getChildId(entry);
+				if(nextChildId != null) {
+					nextToReturn = new BTreeEntry(key, nextChildId, childId);
+					nextToReturn.setRecordId(recordId);
+					childId = nextChildId;
+					key = p.getKey(entry);
+					recordId = new RecordId(p.pid, entry);
+					return true;
+				}
+			}
+			return false;
+		} catch(NoSuchElementException e) {
+			return false;
+		}
+	}
+
+	public BTreeEntry next() {
+		BTreeEntry next = nextToReturn;
+
+		if (next == null) {
+			if (hasNext()) {
+				next = nextToReturn;
+				nextToReturn = null;
+				return next;
+			} else
+				throw new NoSuchElementException();
+		} else {
+			nextToReturn = null;
+			return next;
+		}
+	}
+
+	public void remove() {
+		throw new UnsupportedOperationException();
+	}
+}
+
diff -Naur lab2/src/java/simpledb/BTreeLeafPage.java lab3/src/java/simpledb/BTreeLeafPage.java
--- lab2/src/java/simpledb/BTreeLeafPage.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeLeafPage.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,595 @@
+package simpledb;
+
+import java.util.*;
+import java.io.*;
+
+/**
+ * Each instance of BTreeLeafPage stores data for one page of a BTreeFile and 
+ * implements the Page interface that is used by BufferPool.
+ *
+ * @see BTreeFile
+ * @see BufferPool
+ *
+ */
+public class BTreeLeafPage extends BTreePage {
+	private final byte header[];
+	private final Tuple tuples[];
+	private final int numSlots;
+	
+	private int leftSibling; // leaf node or 0
+	private int rightSibling; // leaf node or 0
+
+	/**
+	 * Create a BTreeLeafPage from a set of bytes of data read from disk.
+	 * The format of a BTreeLeafPage is a set of header bytes indicating
+	 * the slots of the page that are in use, and some number of tuple slots, 
+	 * as well as some extra bytes for the parent and sibling pointers.
+	 *  Specifically, the number of tuples is equal to: <p>
+	 *          floor((BufferPool.getPageSize()*8 - extra bytes*8) / (tuple size * 8 + 1))
+	 * <p> where tuple size is the size of tuples in this
+	 * database table, which can be determined via {@link Catalog#getTupleDesc}.
+	 * The number of 8-bit header words is equal to:
+	 * <p>
+	 *      ceiling(no. tuple slots / 8)
+	 * <p>
+	 * @see Database#getCatalog
+	 * @see Catalog#getTupleDesc
+	 * @see BufferPool#getPageSize()
+	 * 
+	 * @param id - the id of this page
+	 * @param data - the raw data of this page
+	 * @param key - the field which the index is keyed on
+	 */
+	public BTreeLeafPage(BTreePageId id, byte[] data, int key) throws IOException {
+		super(id, key);
+		this.numSlots = getMaxTuples();
+		DataInputStream dis = new DataInputStream(new ByteArrayInputStream(data));
+
+		// Read the parent and sibling pointers
+		try {
+			Field f = Type.INT_TYPE.parse(dis);
+			this.parent = ((IntField) f).getValue();
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+		}
+
+		try {
+			Field f = Type.INT_TYPE.parse(dis);
+			this.leftSibling = ((IntField) f).getValue();
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+		}
+
+		try {
+			Field f = Type.INT_TYPE.parse(dis);
+			this.rightSibling = ((IntField) f).getValue();
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+		}
+
+		// allocate and read the header slots of this page
+		header = new byte[getHeaderSize()];
+		for (int i=0; i<header.length; i++)
+			header[i] = dis.readByte();
+
+		tuples = new Tuple[numSlots];
+		try{
+			// allocate and read the actual records of this page
+			for (int i=0; i<tuples.length; i++)
+				tuples[i] = readNextTuple(dis,i);
+		}catch(NoSuchElementException e){
+			e.printStackTrace();
+		}
+		dis.close();
+
+		setBeforeImage();
+	}
+
+	/** 
+	 * Retrieve the maximum number of tuples this page can hold.
+	 */
+	public int getMaxTuples() {        
+		int bitsPerTupleIncludingHeader = td.getSize() * 8 + 1;
+		// extraBits are: left sibling pointer, right sibling pointer, parent pointer
+		int extraBits = 3 * INDEX_SIZE * 8; 
+		int tuplesPerPage = (BufferPool.getPageSize()*8 - extraBits) / bitsPerTupleIncludingHeader; //round down
+		return tuplesPerPage;
+	}
+
+	/**
+	 * Computes the number of bytes in the header of a page in a BTreeFile with each tuple occupying tupleSize bytes
+	 */
+	private int getHeaderSize() {        
+		int tuplesPerPage = getMaxTuples();
+		int hb = (tuplesPerPage / 8);
+		if (hb * 8 < tuplesPerPage) hb++;
+
+		return hb;
+	}
+
+	/** Return a view of this page before it was modified
+        -- used by recovery */
+	public BTreeLeafPage getBeforeImage(){
+		try {
+			byte[] oldDataRef = null;
+			synchronized(oldDataLock)
+			{
+				oldDataRef = oldData;
+			}
+			return new BTreeLeafPage(pid,oldDataRef,keyField);
+		} catch (IOException e) {
+			e.printStackTrace();
+			//should never happen -- we parsed it OK before!
+			System.exit(1);
+		}
+		return null;
+	}
+
+	public void setBeforeImage() {
+		synchronized(oldDataLock)
+		{
+			oldData = getPageData().clone();
+		}
+	}
+
+	/**
+	 * Read tuples from the source file.
+	 */
+	private Tuple readNextTuple(DataInputStream dis, int slotId) throws NoSuchElementException {
+		// if associated bit is not set, read forward to the next tuple, and
+		// return null.
+		if (!isSlotUsed(slotId)) {
+			for (int i=0; i<td.getSize(); i++) {
+				try {
+					dis.readByte();
+				} catch (IOException e) {
+					throw new NoSuchElementException("error reading empty tuple");
+				}
+			}
+			return null;
+		}
+
+		// read fields in the tuple
+		Tuple t = new Tuple(td);
+		RecordId rid = new RecordId(pid, slotId);
+		t.setRecordId(rid);
+		try {
+			for (int j=0; j<td.numFields(); j++) {
+				Field f = td.getFieldType(j).parse(dis);
+				t.setField(j, f);
+			}
+		} catch (java.text.ParseException e) {
+			e.printStackTrace();
+			throw new NoSuchElementException("parsing error!");
+		}
+
+		return t;
+	}
+
+	/**
+	 * Generates a byte array representing the contents of this page.
+	 * Used to serialize this page to disk.
+	 * <p>
+	 * The invariant here is that it should be possible to pass the byte
+	 * array generated by getPageData to the BTreeLeafPage constructor and
+	 * have it produce an identical BTreeLeafPage object.
+	 *
+	 * @see #BTreeLeafPage
+	 * @return A byte array corresponding to the bytes of this page.
+	 */
+	public byte[] getPageData() {
+		int len = BufferPool.getPageSize();
+		ByteArrayOutputStream baos = new ByteArrayOutputStream(len);
+		DataOutputStream dos = new DataOutputStream(baos);
+
+		// write out the parent and sibling pointers
+		try {
+			dos.writeInt(parent);
+
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+		try {
+			dos.writeInt(leftSibling);
+
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+		try {
+			dos.writeInt(rightSibling);
+
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		// create the header of the page
+		for (int i=0; i<header.length; i++) {
+			try {
+				dos.writeByte(header[i]);
+			} catch (IOException e) {
+				// this really shouldn't happen
+				e.printStackTrace();
+			}
+		}
+
+		// create the tuples
+		for (int i=0; i<tuples.length; i++) {
+
+			// empty slot
+			if (!isSlotUsed(i)) {
+				for (int j=0; j<td.getSize(); j++) {
+					try {
+						dos.writeByte(0);
+					} catch (IOException e) {
+						e.printStackTrace();
+					}
+
+				}
+				continue;
+			}
+
+			// non-empty slot
+			for (int j=0; j<td.numFields(); j++) {
+				Field f = tuples[i].getField(j);
+				try {
+					f.serialize(dos);
+
+				} catch (IOException e) {
+					e.printStackTrace();
+				}
+			}
+		}
+
+		// padding
+		int zerolen = BufferPool.getPageSize() - (header.length + td.getSize() * tuples.length + 3 * INDEX_SIZE); //- numSlots * td.getSize();
+		byte[] zeroes = new byte[zerolen];
+		try {
+			dos.write(zeroes, 0, zerolen);
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		try {
+			dos.flush();
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		return baos.toByteArray();
+	}
+
+	/**
+	 * Delete the specified tuple from the page;  the tuple should be updated to reflect
+	 *   that it is no longer stored on any page.
+	 * @throws DbException if this tuple is not on this page, or tuple slot is
+	 *         already empty.
+	 * @param t The tuple to delete
+	 */
+	public void deleteTuple(Tuple t) throws DbException {
+		RecordId rid = t.getRecordId();
+		if(rid == null)
+			throw new DbException("tried to delete tuple with null rid");
+		if((rid.getPageId().pageNumber() != pid.pageNumber()) || (rid.getPageId().getTableId() != pid.getTableId()))
+			throw new DbException("tried to delete tuple on invalid page or table");
+		if (!isSlotUsed(rid.tupleno()))
+			throw new DbException("tried to delete null tuple.");
+		markSlotUsed(rid.tupleno(), false);
+		t.setRecordId(null);
+	}
+
+	/**
+	 * Adds the specified tuple to the page such that all records remain in sorted order;  
+	 * the tuple should be updated to reflect
+	 *  that it is now stored on this page.
+	 * @throws DbException if the page is full (no empty slots) or tupledesc
+	 *         is mismatch.
+	 * @param t The tuple to add.
+	 */
+	public void insertTuple(Tuple t) throws DbException {
+		if (!t.getTupleDesc().equals(td))
+			throw new DbException("type mismatch, in addTuple");
+
+		// find the first empty slot 
+		int emptySlot = -1;
+		for (int i=0; i<numSlots; i++) {
+			if (!isSlotUsed(i)) {
+				emptySlot = i;
+				break;
+			}
+		}
+
+		if (emptySlot == -1)
+			throw new DbException("called addTuple on page with no empty slots.");
+
+		// find the last key less than or equal to the key being inserted
+		int lessOrEqKey = -1;
+		Field key = t.getField(keyField);
+		for (int i=0; i<numSlots; i++) {
+			if(isSlotUsed(i)) {
+				if(tuples[i].getField(keyField).compare(Predicate.Op.LESS_THAN_OR_EQ, key))
+					lessOrEqKey = i;
+				else
+					break;	
+			}
+		}
+
+		// shift records back or forward to fill empty slot and make room for new record
+		// while keeping records in sorted order
+		int goodSlot = -1;
+		if(emptySlot < lessOrEqKey) {
+			for(int i = emptySlot; i < lessOrEqKey; i++) {
+				moveRecord(i+1, i);
+			}
+			goodSlot = lessOrEqKey;
+		}
+		else {
+			for(int i = emptySlot; i > lessOrEqKey + 1; i--) {
+				moveRecord(i-1, i);
+			}
+			goodSlot = lessOrEqKey + 1;
+		}
+
+		// insert new record into the correct spot in sorted order
+		markSlotUsed(goodSlot, true);
+		Debug.log(1, "BTreeLeafPage.insertTuple: new tuple, tableId = %d pageId = %d slotId = %d", pid.getTableId(), pid.pageNumber(), goodSlot);
+		RecordId rid = new RecordId(pid, goodSlot);
+		t.setRecordId(rid);
+		tuples[goodSlot] = t;
+	}
+
+	/**
+	 * Move a record from one slot to another slot, and update the corresponding
+	 * headers and RecordId
+	 */
+	private void moveRecord(int from, int to) {
+		if(!isSlotUsed(to) && isSlotUsed(from)) {
+			markSlotUsed(to, true);
+			RecordId rid = new RecordId(pid, to);
+			tuples[to] = tuples[from];
+			tuples[to].setRecordId(rid);
+			markSlotUsed(from, false);
+		}
+	}
+
+	/**
+	 * Get the id of the left sibling of this page
+	 * @return the id of the left sibling
+	 */
+	public BTreePageId getLeftSiblingId() {
+		if(leftSibling == 0) {
+			return null;
+		}
+		return new BTreePageId(pid.getTableId(), leftSibling, BTreePageId.LEAF);
+	}
+
+	/**
+	 * Get the id of the right sibling of this page
+	 * @return the id of the right sibling
+	 */
+	public BTreePageId getRightSiblingId() {
+		if(rightSibling == 0) {
+			return null;
+		}
+		return new BTreePageId(pid.getTableId(), rightSibling, BTreePageId.LEAF);
+	}
+
+	/**
+	 * Set the left sibling id of this page
+	 * @param id - the new left sibling id
+	 * @throws DbException if the id is not valid
+	 */
+	public void setLeftSiblingId(BTreePageId id) throws DbException {
+		if(id == null) {
+			leftSibling = 0;
+		}
+		else {
+			if(id.getTableId() != pid.getTableId()) {
+				throw new DbException("table id mismatch in setLeftSiblingId");
+			}
+			if(id.pgcateg() != BTreePageId.LEAF) {
+				throw new DbException("leftSibling must be a leaf node");
+			}
+			leftSibling = id.pageNumber();
+		}
+	}
+
+	/**
+	 * Set the right sibling id of this page
+	 * @param id - the new right sibling id
+	 * @throws DbException if the id is not valid
+	 */
+	public void setRightSiblingId(BTreePageId id) throws DbException {
+		if(id == null) {
+			rightSibling = 0;
+		}
+		else {
+			if(id.getTableId() != pid.getTableId()) {
+				throw new DbException("table id mismatch in setRightSiblingId");
+			}
+			if(id.pgcateg() != BTreePageId.LEAF) {
+				throw new DbException("rightSibling must be a leaf node");
+			}
+			rightSibling = id.pageNumber();
+		}
+	}
+
+	/**
+	 * Returns the number of tuples currently stored on this page
+	 */
+	public int getNumTuples() {
+		return numSlots - getNumEmptySlots();
+	}
+
+	/**
+	 * Returns the number of empty slots on this page.
+	 */
+	public int getNumEmptySlots() {
+		int cnt = 0;
+		for(int i=0; i<numSlots; i++)
+			if(!isSlotUsed(i))
+				cnt++;
+		return cnt;
+	}
+
+	/**
+	 * Returns true if associated slot on this page is filled.
+	 */
+	public boolean isSlotUsed(int i) {
+		int headerbit = i % 8;
+		int headerbyte = (i - headerbit) / 8;
+		return (header[headerbyte] & (1 << headerbit)) != 0;
+	}
+
+	/**
+	 * Abstraction to fill or clear a slot on this page.
+	 */
+	private void markSlotUsed(int i, boolean value) {
+		int headerbit = i % 8;
+		int headerbyte = (i - headerbit) / 8;
+
+		Debug.log(1, "BTreeLeafPage.setSlot: setting slot %d to %b", i, value);
+		if(value)
+			header[headerbyte] |= 1 << headerbit;
+		else
+			header[headerbyte] &= (0xFF ^ (1 << headerbit));
+	}
+
+	/**
+	 * @return an iterator over all tuples on this page (calling remove on this iterator throws an UnsupportedOperationException)
+	 * (note that this iterator shouldn't return tuples in empty slots!)
+	 */
+	public Iterator<Tuple> iterator() {
+		return new BTreeLeafPageIterator(this);
+	}
+
+	/**
+	 * @return a reverse iterator over all tuples on this page (calling remove on this iterator throws an UnsupportedOperationException)
+	 * (note that this iterator shouldn't return tuples in empty slots!)
+	 */
+	public Iterator<Tuple> reverseIterator() {
+		return new BTreeLeafPageReverseIterator(this);
+	}
+
+	/**
+	 * protected method used by the iterator to get the ith tuple out of this page
+	 * @param i - the index of the tuple
+	 * @return the ith tuple in the page
+	 * @throws NoSuchElementException
+	 */
+	Tuple getTuple(int i) throws NoSuchElementException {
+
+		if (i >= tuples.length)
+			throw new NoSuchElementException();
+
+		try {
+			if(!isSlotUsed(i)) {
+				Debug.log(1, "BTreeLeafPage.getTuple: slot %d in %d:%d is not used", i, pid.getTableId(), pid.pageNumber());
+				return null;
+			}
+
+			Debug.log(1, "BTreeLeafPage.getTuple: returning tuple %d", i);
+			return tuples[i];
+
+		} catch (ArrayIndexOutOfBoundsException e) {
+			throw new NoSuchElementException();
+		}
+	}
+}
+
+/**
+ * Helper class that implements the Java Iterator for tuples on a BTreeLeafPage.
+ */
+class BTreeLeafPageIterator implements Iterator<Tuple> {
+	int curTuple = 0;
+	Tuple nextToReturn = null;
+	BTreeLeafPage p;
+
+	public BTreeLeafPageIterator(BTreeLeafPage p) {
+		this.p = p;
+	}
+
+	public boolean hasNext() {
+		if (nextToReturn != null)
+			return true;
+
+		try {
+			while (true) {
+				nextToReturn = p.getTuple(curTuple++);
+				if(nextToReturn != null)
+					return true;
+			}
+		} catch(NoSuchElementException e) {
+			return false;
+		}
+	}
+
+	public Tuple next() {
+		Tuple next = nextToReturn;
+
+		if (next == null) {
+			if (hasNext()) {
+				next = nextToReturn;
+				nextToReturn = null;
+				return next;
+			} else
+				throw new NoSuchElementException();
+		} else {
+			nextToReturn = null;
+			return next;
+		}
+	}
+
+	public void remove() {
+		throw new UnsupportedOperationException();
+	}
+}
+
+/**
+ * Helper class that implements the Java Iterator for tuples on a BTreeLeafPage in reverse.
+ */
+class BTreeLeafPageReverseIterator implements Iterator<Tuple> {
+	int curTuple;
+	Tuple nextToReturn = null;
+	BTreeLeafPage p;
+
+	public BTreeLeafPageReverseIterator(BTreeLeafPage p) {
+		this.p = p;
+		this.curTuple = p.getMaxTuples() - 1;
+	}
+
+	public boolean hasNext() {
+		if (nextToReturn != null)
+			return true;
+
+		try {
+			while (curTuple >= 0) {
+				nextToReturn = p.getTuple(curTuple--);
+				if(nextToReturn != null)
+					return true;
+			}
+			return false;
+		} catch(NoSuchElementException e) {
+			return false;
+		}
+	}
+
+	public Tuple next() {
+		Tuple next = nextToReturn;
+
+		if (next == null) {
+			if (hasNext()) {
+				next = nextToReturn;
+				nextToReturn = null;
+				return next;
+			} else
+				throw new NoSuchElementException();
+		} else {
+			nextToReturn = null;
+			return next;
+		}
+	}
+
+	public void remove() {
+		throw new UnsupportedOperationException();
+	}
+}
diff -Naur lab2/src/java/simpledb/BTreePage.java lab3/src/java/simpledb/BTreePage.java
--- lab2/src/java/simpledb/BTreePage.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreePage.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,145 @@
+package simpledb;
+
+import java.util.*;
+import java.io.*;
+
+import simpledb.Predicate.Op;
+
+/**
+ * Each instance of BTreeInternalPage stores data for one page of a BTreeFile and 
+ * implements the Page interface that is used by BufferPool.
+ *
+ * @see BTreeFile
+ * @see BufferPool
+ *
+ */
+public abstract class BTreePage implements Page {
+	protected volatile boolean dirty = false;
+	protected volatile TransactionId dirtier = null;
+
+	protected final static int INDEX_SIZE = Type.INT_TYPE.getLen();
+
+	protected final BTreePageId pid;
+	protected final TupleDesc td;
+	protected final int keyField;
+
+	protected int parent; // parent is always internal node or 0 for root node
+	protected byte[] oldData;
+	protected final Byte oldDataLock=new Byte((byte)0);
+
+	/**
+	 * Create a BTreeInternalPage from a set of bytes of data read from disk.
+	 * The format of a BTreeInternalPage is a set of header bytes indicating
+	 * the slots of the page that are in use, some number of entry slots, and extra
+	 * bytes for the parent pointer, one extra child pointer (a node with m entries 
+	 * has m+1 pointers to children), and the category of all child pages (either 
+	 * leaf or internal).
+	 *  Specifically, the number of entries is equal to: <p>
+	 *          floor((BufferPool.getPageSize()*8 - extra bytes*8) / (entry size * 8 + 1))
+	 * <p> where entry size is the size of entries in this index node
+	 * (key + child pointer), which can be determined via the key field and 
+	 * {@link Catalog#getTupleDesc}.
+	 * The number of 8-bit header words is equal to:
+	 * <p>
+	 *      ceiling((no. entry slots + 1) / 8)
+	 * <p>
+	 * @see Database#getCatalog
+	 * @see Catalog#getTupleDesc
+	 * @see BufferPool#getPageSize()
+	 * 
+	 * @param id - the id of this page
+	 * @param data - the raw data of this page
+	 * @param key - the field which the index is keyed on
+	 */
+	public BTreePage(BTreePageId id, int key) throws IOException {
+		this.pid = id;
+		this.keyField = key;
+		this.td = Database.getCatalog().getTupleDesc(id.getTableId());
+	}
+
+	/**
+	 * @return the PageId associated with this page.
+	 */
+	public BTreePageId getId() {
+		return pid;
+	}
+
+	/**
+	 * Static method to generate a byte array corresponding to an empty
+	 * BTreePage.
+	 * Used to add new, empty pages to the file. Passing the results of
+	 * this method to the BTreeInternalPage or BTreeLeafPage constructor will create a BTreePage with
+	 * no valid entries in it.
+	 *
+	 * @return The returned ByteArray.
+	 */
+	public static byte[] createEmptyPageData() {
+		int len = BufferPool.getPageSize();
+		return new byte[len]; //all 0
+	}
+
+	/**
+	 * Get the parent id of this page
+	 * @return the parent id
+	 */
+	public BTreePageId getParentId() {
+		if(parent == 0) {
+			return BTreeRootPtrPage.getId(pid.getTableId());
+		}
+		return new BTreePageId(pid.getTableId(), parent, BTreePageId.INTERNAL);
+	}
+
+	/**
+	 * Set the parent id
+	 * @param id - the id of the parent of this page
+	 * @throws DbException if the id is not valid
+	 */
+	public void setParentId(BTreePageId id) throws DbException {
+		if(id == null) {
+			throw new DbException("parent id must not be null");
+		}
+		if(id.getTableId() != pid.getTableId()) {
+			throw new DbException("table id mismatch in setParentId");
+		}
+		if(id.pgcateg() != BTreePageId.INTERNAL && id.pgcateg() != BTreePageId.ROOT_PTR) {
+			throw new DbException("parent must be an internal node or root pointer");
+		}
+		if(id.pgcateg() == BTreePageId.ROOT_PTR) {
+			parent = 0;
+		}
+		else {
+			parent = id.pageNumber();
+		}
+	}
+
+	/**
+	 * Marks this page as dirty/not dirty and record that transaction
+	 * that did the dirtying
+	 */
+	public void markDirty(boolean dirty, TransactionId tid) {
+		this.dirty = dirty;
+		if (dirty) this.dirtier = tid;
+	}
+
+	/**
+	 * Returns the tid of the transaction that last dirtied this page, or null if the page is not dirty
+	 */
+	public TransactionId isDirty() {
+		if (this.dirty)
+			return this.dirtier;
+		else
+			return null;
+	}
+
+	/**
+	 * Returns the number of empty slots on this page.
+	 */
+	public abstract int getNumEmptySlots();
+	
+	/**
+	 * Returns true if associated slot on this page is filled.
+	 */
+	public abstract boolean isSlotUsed(int i);
+
+}
+
diff -Naur lab2/src/java/simpledb/BTreePageId.java lab3/src/java/simpledb/BTreePageId.java
--- lab2/src/java/simpledb/BTreePageId.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreePageId.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,92 @@
+package simpledb;
+
+/** Unique identifier for BTreeInternalPage, BTreeLeafPage, BTreeHeaderPage
+ *  and BTreeRootPtrPage objects. 
+ */
+public class BTreePageId implements PageId {
+
+	public final static int ROOT_PTR = 0;
+	public final static int INTERNAL = 1;
+	public final static int LEAF = 2;
+	public final static int HEADER = 3;
+
+	private final int tableId;
+	private final int pgNo;
+	private int pgcateg;
+
+	/**
+	 * Constructor. Create a page id structure for a specific page of a
+	 * specific table.
+	 *
+	 * @param tableId The table that is being referenced
+	 * @param pgNo The page number in that table.
+	 * @param pgcateg which kind of page it is
+	 */
+	public BTreePageId(int tableId, int pgNo, int pgcateg) {
+		this.tableId = tableId;
+		this.pgNo = pgNo;
+		this.pgcateg = pgcateg;
+	}
+
+	/** @return the table associated with this PageId */
+	public int getTableId() {
+		return tableId;
+	}
+
+	/**
+	 * @return the page number in the table getTableId() associated with
+	 *   this PageId
+	 */
+	public int pageNumber() {
+		return pgNo;
+	}
+
+	/**
+	 * @return the category of this page
+	 */
+	public int pgcateg() {
+		return pgcateg;
+	}
+
+	/**
+	 * @return a hash code for this page, represented by the concatenation of
+	 *   the table number, page number, and pgcateg (needed if a PageId is used as a
+	 *   key in a hash table in the BufferPool, for example.)
+	 * @see BufferPool
+	 */
+	public int hashCode() {
+		int code = (tableId << 16) + (pgNo << 2) + pgcateg;
+		return code;
+	}
+
+	/**
+	 * Compares one PageId to another.
+	 *
+	 * @param o The object to compare against (must be a PageId)
+	 * @return true if the objects are equal (e.g., page numbers, table
+	 *   ids and pgcateg are the same)
+	 */
+	public boolean equals(Object o) {
+		if (!(o instanceof BTreePageId))
+			return false;
+		BTreePageId p = (BTreePageId)o;
+		return tableId == p.tableId && pgNo == p.pgNo && pgcateg == p.pgcateg;
+	}
+
+	/**
+	 *  Return a representation of this object as an array of
+	 *  integers, for writing to disk.  Size of returned array must contain
+	 *  number of integers that corresponds to number of args to one of the
+	 *  constructors.
+	 */
+	public int[] serialize() {
+		int data[] = new int[3];
+
+		data[0] = tableId;
+		data[1] = pgNo;
+		data[2] = pgcateg;
+
+		return data;
+	}
+
+}
diff -Naur lab2/src/java/simpledb/BTreeRootPtrPage.java lab3/src/java/simpledb/BTreeRootPtrPage.java
--- lab2/src/java/simpledb/BTreeRootPtrPage.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeRootPtrPage.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,226 @@
+package simpledb;
+
+import java.io.*;
+
+/**
+ * BTreeRootPtrPage stores the pointer to the root node used in the B+ tree and
+ * implements Page Interface that is used by BufferPool
+ *
+ * @see BufferPool
+ */
+public class BTreeRootPtrPage implements Page {
+	// size of this page
+	public final static int PAGE_SIZE = 9;
+
+	private boolean dirty = false;
+	private TransactionId dirtier = null;
+
+	private BTreePageId pid;
+	private DataInputStream dis;
+
+	private int root; 
+	private int rootCategory;
+	private int header;
+
+	private byte[] oldData;
+
+	/**
+	 * Constructor.
+	 * Construct the BTreeRootPtrPage from a set of bytes of data read from
+	 * disk.
+	 * The format of an BTreeRootPtrPage is an integer for the page number
+	 * of the root node, followed by a byte to encode the category of the root page
+	 * (either leaf or internal), followed by an integer for the page number
+	 * of the first header page
+	 */
+	public BTreeRootPtrPage(BTreePageId id, byte[] data) throws IOException {
+		this.pid = id;
+		this.dis = new DataInputStream(new ByteArrayInputStream(data));
+
+		// read in the root pointer
+		root = dis.readInt();
+		rootCategory = (int) dis.readByte();
+
+		// read in the header pointer
+		header = dis.readInt();
+		
+		setBeforeImage();
+	}
+
+	public void setBeforeImage() {
+		oldData = getPageData().clone();
+	}
+
+	/**
+	 * @return the PageId associated with this page.
+	 */
+	public BTreePageId getId() {
+		return pid;
+	}
+
+	/**
+	 * There is only one instance of a BTreeRootPtrPage per table. This static 
+	 * method is separate from getId() in order to maintain the Page interface
+	 * @param tableid - the tableid of this table
+	 * @return the root pointer page id for the given table
+	 */
+	public static BTreePageId getId(int tableid) {
+		return new BTreePageId(tableid, 0, BTreePageId.ROOT_PTR);
+	}
+
+	/**
+	 * Generates a byte array representing the contents of this root pointer page.
+	 * Used to serialize this root pointer page to disk.
+	 * The invariant here is that it should be possible to pass the byte array
+	 * generated by getPageData to the BTreeRootPtrPage constructor and have it
+	 * produce an identical BTreeRootPtrPage object.
+	 *
+	 * @return A byte array corresponding to the bytes of this root pointer page.
+	 */
+	public byte[] getPageData(){
+		int len = PAGE_SIZE;
+		ByteArrayOutputStream baos = new ByteArrayOutputStream(len);
+		DataOutputStream dos = new DataOutputStream(baos);
+
+		// write out the root pointer (page number of the root page)
+		try{
+			dos.writeInt(root);
+		}catch(IOException e){
+			e.printStackTrace();
+		}
+
+		// write out the category of the root page (leaf or internal)
+		try{
+			dos.writeByte((byte) rootCategory);
+		}catch(IOException e){
+			e.printStackTrace();
+		}
+
+		// write out the header pointer (page number of the first header page)
+		try{
+			dos.writeInt(header);
+		}catch(IOException e){
+			e.printStackTrace();
+		}
+
+		try {
+			dos.flush();
+		}catch(IOException e) {
+			e.printStackTrace();
+		}
+
+		return baos.toByteArray();
+	}
+
+	/**
+	 * Static method to generate a byte array corresponding to an empty
+	 * BTreeRootPtrPage.
+	 * Used to add new, empty pages to the file. Passing the results of
+	 * this method to the BTreeRootPtrPage constructor will create a BTreeRootPtrPage with
+	 * no valid entries in it.
+	 *
+	 * @return The returned ByteArray.
+	 */
+	public static byte[] createEmptyPageData() {
+		int len = PAGE_SIZE;
+		return new byte[len]; //all 0
+	}
+
+	public void markDirty(boolean dirty, TransactionId tid){
+		this.dirty = dirty;
+		if (dirty) this.dirtier = tid;
+	}
+
+	public TransactionId isDirty() {
+		if (this.dirty)
+			return this.dirtier;
+		else
+			return null;
+	}
+
+	/** Return a view of this page before it was modified
+        -- used by recovery */
+	public BTreeRootPtrPage getBeforeImage(){
+		try {
+			return new BTreeRootPtrPage(pid,oldData);
+		} catch (IOException e) {
+			e.printStackTrace();
+			//should never happen -- we parsed it OK before!
+			System.exit(1);
+		}
+		return null;
+	}
+
+	/**
+	 * Get the id of the root page in this B+ tree
+	 * @return the id of the root page
+	 */
+	public BTreePageId getRootId() {
+		if(root == 0) {
+			return null;
+		}
+		return new BTreePageId(pid.getTableId(), root, rootCategory);
+	}
+
+	/**
+	 * Set the id of the root page in this B+ tree
+	 * @param id - the id of the root page
+	 * @throws DbException if the id is invalid
+	 */
+	public void setRootId(BTreePageId id) throws DbException {
+		if(id == null) {
+			root = 0;
+		}
+		else {
+			if(id.getTableId() != pid.getTableId()) {
+				throw new DbException("table id mismatch in setRootId");
+			}
+			if(id.pgcateg() != BTreePageId.INTERNAL && id.pgcateg() != BTreePageId.LEAF) {
+				throw new DbException("root must be an internal node or leaf node");
+			}
+			root = id.pageNumber();
+			rootCategory = id.pgcateg();
+		}
+	}
+
+	/**
+	 * Get the id of the first header page, or null if none exists
+	 * @return the id of the first header page
+	 */
+	public BTreePageId getHeaderId() {
+		if(header == 0) {
+			return null;
+		}
+		return new BTreePageId(pid.getTableId(), header, BTreePageId.HEADER);
+	}
+
+	/**
+	 * Set the page id of the first header page
+	 * @param id - the id of the first header page
+	 * @throws DbException if the id is invalid
+	 */
+	public void setHeaderId(BTreePageId id) throws DbException {
+		if(id == null) {
+			header = 0;
+		}
+		else {
+			if(id.getTableId() != pid.getTableId()) {
+				throw new DbException("table id mismatch in setHeaderId");
+			}
+			if(id.pgcateg() != BTreePageId.HEADER) {
+				throw new DbException("header must be of type BTreePageId.HEADER");
+			}
+			header = id.pageNumber();
+		}
+	}
+
+	/**
+	 * Get the page size of root pointer pages
+	 * @return the page size
+	 */
+	public static int getPageSize() {
+		return PAGE_SIZE;
+	}
+
+}
+
diff -Naur lab2/src/java/simpledb/BTreeScan.java lab3/src/java/simpledb/BTreeScan.java
--- lab2/src/java/simpledb/BTreeScan.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeScan.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,147 @@
+package simpledb;
+
+import java.util.*;
+
+/**
+ * BTreeScan is an operator which reads tuples in sorted order 
+ * according to a predicate
+ */
+public class BTreeScan implements DbIterator {
+
+	private static final long serialVersionUID = 1L;
+
+	private boolean isOpen = false;
+	private TransactionId tid;
+	private TupleDesc myTd;
+	private IndexPredicate ipred = null;
+	private transient DbFileIterator it;
+	private String tablename;
+	private String alias;
+
+	/**
+	 * Creates a B+ tree scan over the specified table as a part of the
+	 * specified transaction.
+	 * 
+	 * @param tid
+	 *            The transaction this scan is running as a part of.
+	 * @param tableid
+	 *            the table to scan.
+	 * @param tableAlias
+	 *            the alias of this table (needed by the parser); the returned
+	 *            tupleDesc should have fields with name tableAlias.fieldName
+	 *            (note: this class is not responsible for handling a case where
+	 *            tableAlias or fieldName are null. It shouldn't crash if they
+	 *            are, but the resulting name can be null.fieldName,
+	 *            tableAlias.null, or null.null).
+	 * @param ipred
+	 * 			  The index predicate to match. If null, the scan will return all tuples
+	 *            in sorted order
+	 */
+	public BTreeScan(TransactionId tid, int tableid, String tableAlias, IndexPredicate ipred) {
+		this.tid = tid;
+		this.ipred = ipred;
+		reset(tableid,tableAlias);
+	}
+
+	/**
+	 * @return
+	 *       return the table name of the table the operator scans. This should
+	 *       be the actual name of the table in the catalog of the database
+	 * */
+	public String getTableName() {
+		return this.tablename;
+	}
+
+	/**
+	 * @return Return the alias of the table this operator scans. 
+	 * */
+	public String getAlias()
+	{
+		return this.alias;
+	}
+
+	/**
+	 * Reset the tableid, and tableAlias of this operator.
+	 * @param tableid
+	 *            the table to scan.
+	 * @param tableAlias
+	 *            the alias of this table (needed by the parser); the returned
+	 *            tupleDesc should have fields with name tableAlias.fieldName
+	 *            (note: this class is not responsible for handling a case where
+	 *            tableAlias or fieldName are null. It shouldn't crash if they
+	 *            are, but the resulting name can be null.fieldName,
+	 *            tableAlias.null, or null.null).
+	 */
+	public void reset(int tableid, String tableAlias) {
+		this.isOpen=false;
+		this.alias = tableAlias;
+		this.tablename = Database.getCatalog().getTableName(tableid);
+		if(ipred == null) {
+			this.it = Database.getCatalog().getDatabaseFile(tableid).iterator(tid);
+		}
+		else {
+			this.it = ((BTreeFile) Database.getCatalog().getDatabaseFile(tableid)).indexIterator(tid, ipred);
+		}
+		myTd = Database.getCatalog().getTupleDesc(tableid);
+		String[] newNames = new String[myTd.numFields()];
+		Type[] newTypes = new Type[myTd.numFields()];
+		for (int i = 0; i < myTd.numFields(); i++) {
+			String name = myTd.getFieldName(i);
+			Type t = myTd.getFieldType(i);
+
+			newNames[i] = tableAlias + "." + name;
+			newTypes[i] = t;
+		}
+		myTd = new TupleDesc(newTypes, newNames);
+	}
+
+	public BTreeScan(TransactionId tid, int tableid, IndexPredicate ipred) {
+		this(tid, tableid, Database.getCatalog().getTableName(tableid), ipred);
+	}
+
+	public void open() throws DbException, TransactionAbortedException {
+		if (isOpen)
+			throw new DbException("double open on one DbIterator.");
+
+		it.open();
+		isOpen = true;
+	}
+
+	/**
+	 * Returns the TupleDesc with field names from the underlying BTreeFile,
+	 * prefixed with the tableAlias string from the constructor. This prefix
+	 * becomes useful when joining tables containing a field(s) with the same
+	 * name.
+	 * 
+	 * @return the TupleDesc with field names from the underlying BTreeFile,
+	 *         prefixed with the tableAlias string from the constructor.
+	 */
+	public TupleDesc getTupleDesc() {
+		return myTd;
+	}
+
+	public boolean hasNext() throws TransactionAbortedException, DbException {
+		if (!isOpen)
+			throw new IllegalStateException("iterator is closed");
+		return it.hasNext();
+	}
+
+	public Tuple next() throws NoSuchElementException,
+	TransactionAbortedException, DbException {
+		if (!isOpen)
+			throw new IllegalStateException("iterator is closed");
+
+		return it.next();
+	}
+
+	public void close() {
+		it.close();
+		isOpen = false;
+	}
+
+	public void rewind() throws DbException, NoSuchElementException,
+	TransactionAbortedException {
+		close();
+		open();
+	}
+}
diff -Naur lab2/src/java/simpledb/BTreeUtility.java lab3/src/java/simpledb/BTreeUtility.java
--- lab2/src/java/simpledb/BTreeUtility.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/BTreeUtility.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,848 @@
+package simpledb;
+
+import java.io.BufferedOutputStream;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Map;
+import java.util.Random;
+import java.util.UUID;
+import java.util.concurrent.BlockingQueue;
+
+import simpledb.Predicate.Op;
+
+/** Helper methods used for testing and implementing random features. */
+public class BTreeUtility {
+
+	public static final int MAX_RAND_VALUE = 1 << 16;
+
+	public static ArrayList<Integer> tupleToList(Tuple tuple) {
+        ArrayList<Integer> list = new ArrayList<Integer>();
+        for (int i = 0; i < tuple.getTupleDesc().numFields(); ++i) {
+            int value = ((IntField)tuple.getField(i)).getValue();
+            list.add(value);
+        }
+        return list;
+    }
+	
+	/**
+	 * @return a Tuple with a single IntField with value n and with
+	 *   RecordId(BTreePageId(1,2, BTreePageId.LEAF), 3)
+	 */
+	public static Tuple getBTreeTuple(int n) {
+		Tuple tup = new Tuple(Utility.getTupleDesc(1));
+		tup.setRecordId(new RecordId(new BTreePageId(1, 2, BTreePageId.LEAF), 3));
+		tup.setField(0, new IntField(n));
+		return tup;
+	}
+
+	/**
+	 * @return a Tuple with an IntField for every element of tupdata
+	 *   and RecordId(BTreePageId(1, 2, BTreePageId.LEAF), 3)
+	 */
+	public static Tuple getBTreeTuple(int[] tupdata) {
+		Tuple tup = new Tuple(Utility.getTupleDesc(tupdata.length));
+		tup.setRecordId(new RecordId(new BTreePageId(1, 2, BTreePageId.LEAF), 3));
+		for (int i = 0; i < tupdata.length; ++i)
+			tup.setField(i, new IntField(tupdata[i]));
+		return tup;
+	}
+	
+	/**
+	 * @return a Tuple with an IntField for every element of tupdata
+	 *   and RecordId(BTreePageId(1, 2, BTreePageId.LEAF), 3)
+	 */
+	public static Tuple getBTreeTuple(ArrayList<Integer> tupdata) {
+		Tuple tup = new Tuple(Utility.getTupleDesc(tupdata.size()));
+		tup.setRecordId(new RecordId(new BTreePageId(1, 2, BTreePageId.LEAF), 3));
+		for (int i = 0; i < tupdata.size(); ++i)
+			tup.setField(i, new IntField(tupdata.get(i)));
+		return tup;
+	}
+
+	/**
+	 * @return a Tuple with a 'width' IntFields each with value n and
+	 *   with RecordId(BTreePageId(1, 2, BTreePageId.LEAF), 3)
+	 */
+	public static Tuple getBTreeTuple(int n, int width) {
+		Tuple tup = new Tuple(Utility.getTupleDesc(width));
+		tup.setRecordId(new RecordId(new BTreePageId(1, 2, BTreePageId.LEAF), 3));
+		for (int i = 0; i < width; ++i)
+			tup.setField(i, new IntField(n));
+		return tup;
+	}
+
+	/**
+	 * @return a BTreeEntry with an IntField with value n and with
+	 *   RecordId(BTreePageId(1,2, BTreePageId.INTERNAL), 3)
+	 */
+	public static BTreeEntry getBTreeEntry(int n) {
+		BTreePageId leftChild = new BTreePageId(1, n, BTreePageId.LEAF);
+		BTreePageId rightChild = new BTreePageId(1, n+1, BTreePageId.LEAF);
+		BTreeEntry e = new BTreeEntry(new IntField(n), leftChild, rightChild);
+		e.setRecordId(new RecordId(new BTreePageId(1, 2, BTreePageId.INTERNAL), 3));
+		return e;
+	}
+
+	/**
+	 * @return a BTreeEntry with an IntField with value n and with
+	 *   RecordId(BTreePageId(tableid,2, BTreePageId.INTERNAL), 3)
+	 */
+	public static BTreeEntry getBTreeEntry(int n, int tableid) {
+		BTreePageId leftChild = new BTreePageId(tableid, n, BTreePageId.LEAF);
+		BTreePageId rightChild = new BTreePageId(tableid, n+1, BTreePageId.LEAF);
+		BTreeEntry e = new BTreeEntry(new IntField(n), leftChild, rightChild);
+		e.setRecordId(new RecordId(new BTreePageId(tableid, 2, BTreePageId.INTERNAL), 3));
+		return e;
+	}
+
+	/**
+	 * @return a BTreeEntry with an IntField with value key and with
+	 *   RecordId(BTreePageId(tableid,2, BTreePageId.INTERNAL), 3)
+	 */
+	public static BTreeEntry getBTreeEntry(int n, int key, int tableid) {
+		BTreePageId leftChild = new BTreePageId(tableid, n, BTreePageId.LEAF);
+		BTreePageId rightChild = new BTreePageId(tableid, n+1, BTreePageId.LEAF);
+		BTreeEntry e = new BTreeEntry(new IntField(key), leftChild, rightChild);
+		e.setRecordId(new RecordId(new BTreePageId(tableid, 2, BTreePageId.INTERNAL), 3));
+		return e;
+	}
+
+	/** @param columnSpecification Mapping between column index and value. */
+	public static BTreeFile createRandomBTreeFile(
+			int columns, int rows, Map<Integer, Integer> columnSpecification,
+			ArrayList<ArrayList<Integer>> tuples, int keyField)
+					throws IOException, DbException, TransactionAbortedException {
+		return createRandomBTreeFile(columns, rows, MAX_RAND_VALUE, columnSpecification, tuples, keyField);
+	}
+
+	/**
+	 * Generates a random B+ tree file for testing
+	 * @param columns - number of columns
+	 * @param rows - number of rows
+	 * @param maxValue - the maximum random value in this B+ tree
+	 * @param columnSpecification - optional column specification
+	 * @param tuples - optional list of tuples to return
+	 * @param keyField - the index of the key field
+	 * @return a BTreeFile
+	 * @throws IOException
+	 * @throws DbException
+	 * @throws TransactionAbortedException
+	 */
+	public static BTreeFile createRandomBTreeFile(int columns, int rows,
+			int maxValue, Map<Integer, Integer> columnSpecification,
+			ArrayList<ArrayList<Integer>> tuples, int keyField) 
+					throws IOException, DbException, TransactionAbortedException {
+
+		if (tuples != null) {
+			tuples.clear();
+		} else {
+			tuples = new ArrayList<ArrayList<Integer>>(rows);
+		}
+
+		generateRandomTuples(columns, rows, maxValue, columnSpecification, tuples);
+		
+		// Convert the tuples list to a B+ tree file
+		File hFile = File.createTempFile("table", ".dat");
+		hFile.deleteOnExit();
+
+		File bFile = File.createTempFile("table_index", ".dat");
+		bFile.deleteOnExit();
+
+		Type[] typeAr = new Type[columns];
+		Arrays.fill(typeAr, Type.INT_TYPE);
+		return BTreeFileEncoder.convert(tuples, hFile, bFile, BufferPool.getPageSize(),
+				columns, typeAr, ',', keyField) ;
+	}
+	
+	/**
+	 * Generate a random set of tuples for testing
+	 * @param columns - number of columns
+	 * @param rows - number of rows
+	 * @param maxValue - the maximum random value in this B+ tree
+	 * @param columnSpecification - optional column specification
+	 * @param tuples - list of tuples to return
+	 */
+	public static void generateRandomTuples(int columns, int rows,
+			int maxValue, Map<Integer, Integer> columnSpecification,
+			ArrayList<ArrayList<Integer>> tuples) {
+		generateRandomTuples(columns, rows, 0, maxValue, columnSpecification, tuples);
+	}
+	
+	/**
+	 * Generate a random set of tuples for testing
+	 * @param columns - number of columns
+	 * @param rows - number of rows
+	 * @param minValue - the minimum random value in this B+ tree
+	 * @param maxValue - the maximum random value in this B+ tree
+	 * @param columnSpecification - optional column specification
+	 * @param tuples - list of tuples to return
+	 */
+	public static void generateRandomTuples(int columns, int rows,
+			int minValue, int maxValue, Map<Integer, Integer> columnSpecification,
+			ArrayList<ArrayList<Integer>> tuples) {
+
+		Random r = new Random();
+
+		// Fill the tuples list with generated values
+		for (int i = 0; i < rows; ++i) {
+			ArrayList<Integer> tuple = new ArrayList<Integer>(columns);
+			for (int j = 0; j < columns; ++j) {
+				// Generate random values, or use the column specification
+				Integer columnValue = null;
+				if (columnSpecification != null) columnValue = columnSpecification.get(j);
+				if (columnValue == null) {
+					columnValue = r.nextInt(maxValue-minValue) + minValue;
+				}
+				tuple.add(columnValue);
+			}
+			tuples.add(tuple);
+		}
+	}
+	
+	/**
+	 * Generate a random set of entries for testing
+	 * @param numKeys - number of keys
+	 * @param minKey - the minimum key value
+	 * @param maxKey - the maximum key value
+	 * @param minChildPtr - the first child pointer
+	 * @param childPointers - list of child pointers to return
+	 * @param keys - list of keys to return
+	 */
+	public static void generateRandomEntries(int numKeys, int minKey, int maxKey, int minChildPtr,
+			ArrayList<Integer> childPointers, ArrayList<Integer> keys) {
+
+		Random r = new Random();
+
+		// Fill the keys and childPointers lists with generated values
+		int child = minChildPtr;
+		for (int i = 0; i < numKeys; ++i) {
+			keys.add(r.nextInt(maxKey-minKey) + minKey);
+			childPointers.add(child);
+			++child;
+		}
+		
+		// one extra child pointer
+		childPointers.add(child);
+	}
+	
+	/**
+	 * Generate a random set of tuples for testing
+	 * @param columns - number of columns
+	 * @param rows - number of rows
+	 * @param min - the minimum value
+	 * @param max - the maximum value
+	 * @return the list of tuples
+	 */
+	public static ArrayList<Tuple> generateRandomTuples(int columns, int rows, int min, int max) {
+		ArrayList<ArrayList<Integer>> tuples = new ArrayList<ArrayList<Integer>>(rows);
+		generateRandomTuples(columns, rows, min, max, null, tuples);
+		ArrayList<Tuple> tupleList = new ArrayList<Tuple>();
+		for(ArrayList<Integer> tup : tuples) {
+			tupleList.add(getBTreeTuple(tup));	
+		}
+		return tupleList;
+	}
+	
+	/**
+	 * Generate a random set of entries for testing
+	 * @param numKeys - the number of keys
+	 * @param tableid - the tableid
+	 * @param childPageCategory - the child page category (LEAF or INTERNAL)
+	 * @param minKey - the minimum key value
+	 * @param maxKey - the maximum key value
+	 * @param minChildPtr - the first child pointer
+	 * @return the list of entries
+	 */
+	public static ArrayList<BTreeEntry> generateRandomEntries(int numKeys, int tableid, int childPageCategory, int minKey, int maxKey, int minChildPtr) {
+		ArrayList<Integer> keys = new ArrayList<Integer>(numKeys);
+		ArrayList<Integer> childPointers = new ArrayList<Integer>(numKeys+1);
+		generateRandomEntries(numKeys, minKey, maxKey, minChildPtr, childPointers, keys);
+		Collections.sort(keys);
+		ArrayList<BTreeEntry> entryList = new ArrayList<BTreeEntry>();
+		for(int i = 0; i < numKeys; ++i) {
+			entryList.add(new BTreeEntry(new IntField(keys.get(i)), 
+					new BTreePageId(tableid, childPointers.get(i), childPageCategory), 
+					new BTreePageId(tableid, childPointers.get(i+1), childPageCategory)));
+		}
+		return entryList;
+	}
+	
+	/**
+	 * Get the number of tuples that can fit on a page with the specified number of integer fields
+	 * @param columns - the number of columns
+	 * @return the number of tuples per page
+	 */
+	public static int getNumTuplesPerPage(int columns) {
+		int bytesPerTuple = Type.INT_TYPE.getLen() * columns * 8;
+		int tuplesPerPage = (BufferPool.getPageSize() * 8 - 3 * BTreeLeafPage.INDEX_SIZE * 8) /  (bytesPerTuple + 1);
+		return tuplesPerPage;
+	}
+	
+	/**
+	 * Create a random leaf page for testing
+	 * @param pid - the page id of the leaf page
+	 * @param columns - the number of fields per tuple
+	 * @param keyField - the index of the key field in each tuple
+	 * @param min - the minimum value
+	 * @param max - the maximum value
+	 * @return the leaf page
+	 * @throws IOException
+	 */
+	public static BTreeLeafPage createRandomLeafPage(BTreePageId pid, int columns, int keyField, int min, int max) throws IOException {
+		int tuplesPerPage = getNumTuplesPerPage(columns);
+		return createRandomLeafPage(pid, columns, keyField, tuplesPerPage, min, max);
+	}
+	
+	/**
+	 * Create a random leaf page for testing
+	 * @param pid - the page id of the leaf page
+	 * @param columns - the number of fields per tuple
+	 * @param keyField - the index of the key field in each tuple
+	 * @param numTuples - the number of tuples to insert
+	 * @param min - the minimum value
+	 * @param max - the maximum value
+	 * @return the leaf page
+	 * @throws IOException
+	 */
+	public static BTreeLeafPage createRandomLeafPage(BTreePageId pid, int columns, int keyField, int numTuples, int min, int max) throws IOException {
+		Type[] typeAr = new Type[columns];
+		Arrays.fill(typeAr, Type.INT_TYPE);
+		byte[] data = BTreeFileEncoder.convertToLeafPage(BTreeUtility.generateRandomTuples(columns, numTuples, min, max), 
+				BufferPool.getPageSize(), columns, typeAr, keyField);
+		BTreeLeafPage page = new BTreeLeafPage(pid, data, keyField);
+		return page;
+	}
+
+	/**
+	 * The number of entries that can fit on a page with integer key fields
+	 * @return the number of entries per page
+	 */
+	public static int getNumEntriesPerPage() {
+		int nentrybytes = Type.INT_TYPE.getLen() + BTreeInternalPage.INDEX_SIZE;
+		// pointerbytes: one extra child pointer, parent pointer, child page category
+		int internalpointerbytes = 2 * BTreeLeafPage.INDEX_SIZE + 1; 
+		int entriesPerPage = (BufferPool.getPageSize() * 8 - internalpointerbytes * 8 - 1) /  (nentrybytes * 8 + 1);  //floor comes for free
+		return entriesPerPage;
+	}
+	
+	/**
+	 * Create a random internal page for testing
+	 * @param pid - the page id of the internal page
+	 * @param keyField - the index of the key field in each tuple
+	 * @param childPageCategory - the child page category (LEAF or INTERNAL)
+	 * @param minKey - the minimum key value
+	 * @param maxKey - the maximum key value
+	 * @param minChildPtr - the first child pointer
+	 * @return the internal page
+	 * @throws IOException
+	 */
+	public static BTreeInternalPage createRandomInternalPage(BTreePageId pid, int keyField, int childPageCategory, int minKey, int maxKey, int minChildPtr) throws IOException {
+		int entriesPerPage = getNumEntriesPerPage();
+		return createRandomInternalPage(pid, keyField, childPageCategory, entriesPerPage, minKey, maxKey, minChildPtr);
+	}
+	
+	/**
+	 * Create a random internal page for testing
+	 * @param pid - the page id of the internal page
+	 * @param keyField - the index of the key field in each tuple
+	 * @param childPageCategory - the child page category (LEAF or INTERNAL)
+	 * @param numKeys - the number of keys to insert
+	 * @param minKey - the minimum key value
+	 * @param maxKey - the maximum key value
+	 * @param minChildPtr - the first child pointer
+	 * @return the internal page
+	 * @throws IOException
+	 */
+	public static BTreeInternalPage createRandomInternalPage(BTreePageId pid, int keyField, int childPageCategory, int numKeys, int minKey, int maxKey, int minChildPtr) throws IOException {
+		byte[] data = BTreeFileEncoder.convertToInternalPage(BTreeUtility.generateRandomEntries(numKeys, pid.getTableId(), childPageCategory, minKey, maxKey, minChildPtr), 
+				BufferPool.getPageSize(), Type.INT_TYPE, childPageCategory);
+		BTreeInternalPage page = new BTreeInternalPage(pid, data, keyField);
+		return page;
+	}
+
+	/**
+	 * creates a *non* random B+ tree file for testing
+	 * @param columns - number of columns
+	 * @param rows - number of rows
+	 * @param columnSpecification - optional column specification
+	 * @param tuples - optional list of tuples to return
+	 * @param keyField - the index of the key field
+	 * @return a BTreeFile
+	 * @throws IOException
+	 * @throws DbException
+	 * @throws TransactionAbortedException
+	 */
+	public static BTreeFile createBTreeFile(int columns, int rows,
+			Map<Integer, Integer> columnSpecification,
+			ArrayList<ArrayList<Integer>> tuples, int keyField) 
+					throws IOException, DbException, TransactionAbortedException {
+		if (tuples != null) {
+			tuples.clear();
+		} else {
+			tuples = new ArrayList<ArrayList<Integer>>(rows);
+		}
+
+		// Fill the tuples list with generated values
+		for (int i = 0; i < rows; ++i) {
+			ArrayList<Integer> tuple = new ArrayList<Integer>(columns);
+			for (int j = 0; j < columns; ++j) {
+				// Generate values, or use the column specification
+				Integer columnValue = null;
+				if (columnSpecification != null) columnValue = columnSpecification.get(j);
+				if (columnValue == null) {
+					columnValue = (i+1)*(j+1);
+				}
+				tuple.add(columnValue);
+			}
+			tuples.add(tuple);
+		}
+
+		// Convert the tuples list to a B+ tree file
+		File hFile = File.createTempFile("table", ".dat");
+		hFile.deleteOnExit();
+
+		File bFile = File.createTempFile("table_index", ".dat");
+		bFile.deleteOnExit();
+
+		Type[] typeAr = new Type[columns];
+		Arrays.fill(typeAr, Type.INT_TYPE);
+		return BTreeFileEncoder.convert(tuples, hFile, bFile, BufferPool.getPageSize(),
+				columns, typeAr, ',', keyField) ;
+	}
+
+	/** Opens a BTreeFile and adds it to the catalog.
+	 *
+	 * @param cols number of columns in the table.
+	 * @param f location of the file storing the table.
+	 * @param keyField the field the B+ tree is keyed on
+	 * @return the opened table.
+	 */
+	public static BTreeFile openBTreeFile(int cols, File f, int keyField) {
+		// create the BTreeFile and add it to the catalog
+		TupleDesc td = Utility.getTupleDesc(cols);
+		BTreeFile bf = new BTreeFile(f, keyField, td);
+		Database.getCatalog().addTable(bf, UUID.randomUUID().toString());
+		return bf;
+	}
+
+	public static BTreeFile openBTreeFile(int cols, String colPrefix, File f, int keyField) {
+		// create the BTreeFile and add it to the catalog
+		TupleDesc td = Utility.getTupleDesc(cols, colPrefix);
+		BTreeFile bf = new BTreeFile(f, keyField, td);
+		Database.getCatalog().addTable(bf, UUID.randomUUID().toString());
+		return bf;
+	}
+
+	/**
+	 * A utility method to create a new BTreeFile with no data,
+	 * assuming the path does not already exist. If the path exists, the file
+	 * will be overwritten. The new table will be added to the Catalog with
+	 * the specified number of columns as IntFields indexed on the keyField.
+	 */
+	public static BTreeFile createEmptyBTreeFile(String path, int cols, int keyField)
+			throws IOException {
+		File f = new File(path);
+		// touch the file
+		FileOutputStream fos = new FileOutputStream(f);
+		fos.write(new byte[0]);
+		fos.close();
+
+		BTreeFile bf = openBTreeFile(cols, f, keyField);
+
+		return bf;
+	}
+
+	/**
+	 * A utility method to create a new BTreeFile with no data, with the specified
+	 * number of pages, assuming the path does not already exist. If the path exists, 
+	 * the file will be overwritten. The new table will be added to the Catalog with
+	 * the specified number of columns as IntFields indexed on the keyField.
+	 */
+	public static BTreeFile createEmptyBTreeFile(String path, int cols, int keyField, int pages)
+			throws IOException {
+		File f = new File(path);
+		BufferedOutputStream bw = new BufferedOutputStream(
+				new FileOutputStream(f, true));
+		byte[] emptyRootPtrData = BTreeRootPtrPage.createEmptyPageData();
+		byte[] emptyPageData = BTreePage.createEmptyPageData();
+		bw.write(emptyRootPtrData);
+		for(int i = 0; i < pages; ++i) {
+			bw.write(emptyPageData);
+		}
+		bw.close();
+
+		BTreeFile bf = openBTreeFile(cols, f, keyField);
+
+		return bf;
+	}
+
+	/**
+	 * Helper class that attempts to insert a tuple in a new thread
+	 *
+	 * @return a handle to the Thread that will attempt insertion after it
+	 *   has been started
+	 */
+	static class BTreeWriter extends Thread {
+
+		TransactionId tid;
+		BTreeFile bf;
+		int item;
+		int count;
+		boolean success;
+		Exception error;
+		Object slock;
+		Object elock;
+
+		/**
+		 * @param tid the transaction on whose behalf we want to insert the tuple
+		 * @param bf the B+ tree file into which we want to insert the tuple
+		 * @param item the key of the tuple to insert
+		 * @param count the number of times to insert the tuple
+		 */
+		public BTreeWriter(TransactionId tid, BTreeFile bf, int item, int count) {
+			this.tid = tid;
+			this.bf = bf;
+			this.item = item;
+			this.count = count;
+			this.success = false;
+			this.error = null;
+			this.slock = new Object();
+			this.elock = new Object();
+		}
+
+		public void run() {
+			try {
+				int c = 0;
+				while(c < count) {
+					Tuple t = BTreeUtility.getBTreeTuple(item, 2);
+					Database.getBufferPool().insertTuple(tid, bf.getId(), t);
+
+					IndexPredicate ipred = new IndexPredicate(Op.EQUALS, t.getField(bf.keyField()));
+					DbFileIterator it = bf.indexIterator(tid, ipred);
+					it.open();
+					c = 0;
+					while(it.hasNext()) {
+						it.next();
+						c++;
+					}
+					it.close();
+				}
+				synchronized(slock) {
+					success = true;
+				}
+			} catch (Exception e) {
+				e.printStackTrace();
+				synchronized(elock) {
+					error = e;
+				}
+
+				try {
+					Database.getBufferPool().transactionComplete(tid, false);
+				} catch (java.io.IOException e2) {
+					e2.printStackTrace();
+				}
+			}
+		}
+
+		/**
+		 * @return true if we successfully inserted the tuple
+		 */
+		 public boolean succeeded() {
+			 synchronized(slock) {
+				 return success;
+			 }
+		 }
+
+		/**
+		 * @return an Exception instance if one occurred while inserting the tuple;
+		 *   null otherwise
+		 */
+		 public Exception getError() {
+			 synchronized(elock) {
+				 return error;
+			 }
+		 }
+	}
+
+	/**
+	 * Helper class that searches for tuple(s) in a new thread
+	 *
+	 * @return a handle to the Thread that will attempt to search for tuple(s) after it
+	 *   has been started
+	 */
+	static class BTreeReader extends Thread {
+
+		TransactionId tid;
+		BTreeFile bf;
+		Field f;
+		int count;
+		boolean found;
+		Exception error;
+		Object slock;
+		Object elock;
+
+		/**
+		 * @param tid the transaction on whose behalf we want to search for the tuple(s)
+		 * @param bf the B+ tree file containing the tuple(s)
+		 * @param f the field to search for
+		 * @param count the number of tuples to search for
+		 */
+		public BTreeReader(TransactionId tid, BTreeFile bf, Field f, int count) {
+			this.tid = tid;
+			this.bf = bf;
+			this.f = f;
+			this.count = count;
+			this.found = false;
+			this.error = null;
+			this.slock = new Object();
+			this.elock = new Object();
+		}
+
+		public void run() {
+			try {
+				while(true) {
+					IndexPredicate ipred = new IndexPredicate(Op.EQUALS, f);
+					DbFileIterator it = bf.indexIterator(tid, ipred);
+					it.open();
+					int c = 0;
+					while(it.hasNext()) {
+						it.next();
+						c++;
+					}
+					it.close();
+					if(c >= count) {
+						synchronized(slock) {
+							found = true;
+						}
+					}
+				}
+
+			} catch (Exception e) {
+				e.printStackTrace();
+				synchronized(elock) {
+					error = e;
+				}
+
+				try {
+					Database.getBufferPool().transactionComplete(tid, false);
+				} catch (java.io.IOException e2) {
+					e2.printStackTrace();
+				}
+			}
+		}
+
+		/**
+		 * @return true if we successfully found the tuple(s)
+		 */
+		 public boolean found() {
+			 synchronized(slock) {
+				 return found;
+			 }
+		 }
+
+		/**
+		 * @return an Exception instance if one occurred while searching for the tuple(s);
+		 *   null otherwise
+		 */
+		 public Exception getError() {
+			 synchronized(elock) {
+				 return error;
+			 }
+		 }
+	}
+	
+	/**
+	 * Helper class that attempts to insert a tuple in a new thread
+	 *
+	 * @return a handle to the Thread that will attempt insertion after it
+	 *   has been started
+	 */
+	public static class BTreeInserter extends Thread {
+
+		TransactionId tid;
+		BTreeFile bf;
+		int[] tupdata;
+		BlockingQueue<ArrayList<Integer>> insertedTuples;
+		boolean success;
+		Exception error;
+		Object slock;
+		Object elock;
+
+		/**
+		 * @param bf the B+ tree file into which we want to insert the tuple
+		 * @param tupdata the data of the tuple to insert
+		 * @param the list of tuples that were successfully inserted
+		 */
+		public BTreeInserter(BTreeFile bf, int[] tupdata, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+			init(bf, tupdata, insertedTuples);
+		}
+
+		public void run() {
+			try {
+				Tuple t = BTreeUtility.getBTreeTuple(tupdata);
+				Database.getBufferPool().insertTuple(tid, bf.getId(), t);
+				Database.getBufferPool().transactionComplete(tid);
+				ArrayList<Integer> tuple = tupleToList(t);
+				insertedTuples.put(tuple);
+				synchronized(slock) {
+					success = true;
+				}
+			} catch (Exception e) {
+				if(!(e instanceof TransactionAbortedException)) {
+					e.printStackTrace();
+				}
+				synchronized(elock) {
+					error = e;
+				}
+
+				try {
+					Database.getBufferPool().transactionComplete(tid, false);
+				} catch (java.io.IOException e2) {
+					e2.printStackTrace();
+				}
+			}
+		}
+		
+		private void init(BTreeFile bf, int[] tupdata, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+			this.tid = new TransactionId();
+			this.bf = bf;
+			this.tupdata = tupdata;
+			this.insertedTuples = insertedTuples;
+			this.success = false;
+			this.error = null;
+			this.slock = new Object();
+			this.elock = new Object();
+		}
+		
+		public void rerun(BTreeFile bf, int[] tupdata, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+			init(bf, tupdata, insertedTuples);
+			run();
+		}
+
+		/**
+		 * @return true if we successfully inserted the tuple
+		 */
+		 public boolean succeeded() {
+			 synchronized(slock) {
+				 return success;
+			 }
+		 }
+
+		/**
+		 * @return an Exception instance if one occurred while inserting the tuple;
+		 *   null otherwise
+		 */
+		 public Exception getError() {
+			 synchronized(elock) {
+				 return error;
+			 }
+		 }
+	}
+    
+	/**
+	 * Helper class that attempts to delete tuple(s) in a new thread
+	 *
+	 * @return a handle to the Thread that will attempt deletion after it
+	 *   has been started
+	 */
+	public static class BTreeDeleter extends Thread {
+
+		TransactionId tid;
+		BTreeFile bf;
+		BlockingQueue<ArrayList<Integer>> insertedTuples;
+		ArrayList<Integer> tuple;
+		boolean success;
+		Exception error;
+		Object slock;
+		Object elock;
+
+		/**
+		 * @param bf the B+ tree file from which we want to delete the tuple(s)
+		 * @param the list of tuples to delete
+		 */
+		public BTreeDeleter(BTreeFile bf, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+			init(bf, insertedTuples);
+		}
+
+		public void run() {
+			try {
+				tuple = insertedTuples.take();
+				if(bf.getTupleDesc().numFields() != tuple.size()) {
+					throw new DbException("tuple desc mismatch");
+				}
+				IntField key = new IntField(tuple.get(bf.keyField()));
+				IndexPredicate ipred = new IndexPredicate(Op.EQUALS, key);
+				DbFileIterator it = bf.indexIterator(tid, ipred);
+				it.open();
+				while(it.hasNext()) {
+					Tuple t = it.next();
+					if(tupleToList(t).equals(tuple)) {
+						Database.getBufferPool().deleteTuple(tid, t);
+						break;
+					}
+				}
+				it.close();
+				Database.getBufferPool().transactionComplete(tid);
+				synchronized(slock) {
+					success = true;
+				}
+			} catch (Exception e) {
+				if(!(e instanceof TransactionAbortedException)) {
+					e.printStackTrace();
+				}
+				synchronized(elock) {
+					error = e;
+				}
+
+				try {
+					insertedTuples.put(tuple);
+					Database.getBufferPool().transactionComplete(tid, false);
+				} catch (java.io.IOException e2) {
+					e2.printStackTrace();
+				} catch (InterruptedException e3) {
+					e3.printStackTrace();
+				}
+			}
+		}
+		
+		private void init(BTreeFile bf, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+			this.tid = new TransactionId();
+			this.bf = bf;
+			this.insertedTuples = insertedTuples;
+			this.success = false;
+			this.error = null;
+			this.slock = new Object();
+			this.elock = new Object();
+		}
+		
+		public void rerun(BTreeFile bf, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+			init(bf, insertedTuples);
+			run();
+		}
+
+		/**
+		 * @return true if we successfully inserted the tuple
+		 */
+		 public boolean succeeded() {
+			 synchronized(slock) {
+				 return success;
+			 }
+		 }
+
+		/**
+		 * @return an Exception instance if one occurred while inserting the tuple;
+		 *   null otherwise
+		 */
+		 public Exception getError() {
+			 synchronized(elock) {
+				 return error;
+			 }
+		 }
+	}
+
+}
+
diff -Naur lab2/src/java/simpledb/IndexDbIterator.java lab3/src/java/simpledb/IndexDbIterator.java
--- lab2/src/java/simpledb/IndexDbIterator.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/IndexDbIterator.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,20 @@
+package simpledb;
+import java.util.*;
+
+/** IndexDBIterator is the interface that index access methods
+    implement in SimpleDb.
+*/
+public interface IndexDbIterator extends DbIterator {
+    /** Open the access method such that when getNext is called, it
+        iterates through the tuples that satisfy ipred.
+        @param ipred The predicate that is used to scan the index.
+    */
+    public void open(IndexPredicate ipred)
+        throws NoSuchElementException, DbException, TransactionAbortedException;
+
+    /** Begin a new index scan with the specified predicate.
+        @param ipred The predicate that is used to scan the index.
+    */
+    public void rewind(IndexPredicate ipred)
+        throws DbException, TransactionAbortedException;
+}
diff -Naur lab2/src/java/simpledb/IndexPredicate.java lab3/src/java/simpledb/IndexPredicate.java
--- lab2/src/java/simpledb/IndexPredicate.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/src/java/simpledb/IndexPredicate.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,49 @@
+package simpledb;
+
+import java.io.Serializable;
+
+/**
+ * IndexPredicate compares a field which has index on it against a given value
+ * @see simpledb.IndexDbIterator
+ */
+public class IndexPredicate implements Serializable {
+	
+    private static final long serialVersionUID = 1L;
+	
+    private Predicate.Op op;
+    private Field fieldvalue;
+
+    /**
+     * Constructor.
+     *
+     * @param fvalue The value that the predicate compares against.
+     * @param op The operation to apply (as defined in Predicate.Op); either
+     *   Predicate.Op.GREATER_THAN, Predicate.Op.LESS_THAN, Predicate.Op.EQUAL,
+     *   Predicate.Op.GREATER_THAN_OR_EQ, or Predicate.Op.LESS_THAN_OR_EQ
+     * @see Predicate
+     */
+    public IndexPredicate(Predicate.Op op, Field fvalue) {
+        this.op = op;
+        this.fieldvalue = fvalue;
+    }
+
+    public Field getField() {
+        return fieldvalue;
+    }
+
+    public Predicate.Op getOp() {
+        return op;
+    }
+
+    /** Return true if the fieldvalue in the supplied predicate
+        is satisfied by this predicate's fieldvalue and
+        operator.
+        @param ipd The field to compare against.
+    */
+    public boolean equals(IndexPredicate ipd) {
+        if (ipd == null)
+            return false;
+        return (op.equals(ipd.op) && fieldvalue.equals(ipd.fieldvalue));
+    }
+
+}
diff -Naur lab2/test/simpledb/BTreeDeadlockTest.java lab3/test/simpledb/BTreeDeadlockTest.java
--- lab2/test/simpledb/BTreeDeadlockTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeDeadlockTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,145 @@
+package simpledb;
+
+import simpledb.Predicate.Op;
+import simpledb.BTreeUtility.*;
+import simpledb.systemtest.SimpleDbTestBase;
+
+import java.util.*;
+import org.junit.Before;
+import org.junit.Test;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeDeadlockTest extends SimpleDbTestBase {
+	private Random rand;
+
+	private static final int POLL_INTERVAL = 100;
+	private static final int WAIT_INTERVAL = 200;
+
+	// just so we have a pointer shorter than Database.getBufferPool
+	private BufferPool bp;
+	private BTreeFile bf;
+	private int item1;
+	private int item2;
+	private int count1;
+	private int count2;
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before public void setUp() throws Exception {
+		// create a packed B+ tree with no empty slots
+		bf = BTreeUtility.createRandomBTreeFile(2, 253008, null, null, 0);
+		rand = new Random();
+		item1 = rand.nextInt(BTreeUtility.MAX_RAND_VALUE);
+		item2 = rand.nextInt(BTreeUtility.MAX_RAND_VALUE);
+		bp = Database.resetBufferPool(BufferPool.DEFAULT_PAGES);
+
+		// first make sure that item1 is not contained in our B+ tree
+		TransactionId tid = new TransactionId();
+		DbFileIterator it = bf.indexIterator(tid, new IndexPredicate(Op.EQUALS, new IntField(item1)));
+		it.open();
+		ArrayList<Tuple> tuples = new ArrayList<Tuple>();
+		while(it.hasNext()) {
+			tuples.add(it.next());
+		}
+		for(Tuple t : tuples) {
+			bp.deleteTuple(tid, t);
+		}
+
+		// this is the number of tuples we must insert to replace the deleted tuples 
+		// and cause the root node to split
+		count1 = tuples.size() + 1;
+
+		// do the same thing for item 2
+		it = bf.indexIterator(tid, new IndexPredicate(Op.EQUALS, new IntField(item2)));
+		it.open();
+		tuples.clear();
+		while(it.hasNext()) {
+			tuples.add(it.next());
+		}
+		for(Tuple t : tuples) {
+			bp.deleteTuple(tid, t);
+		}
+
+		// this is the number of tuples we must insert to replace the deleted tuples 
+		// and cause the root node to split
+		count2 = tuples.size() + 1;
+
+		// clear all state from the buffer pool, increase the number of pages
+		bp.flushAllPages();
+		bp = Database.resetBufferPool(500);
+
+	}
+
+	/**
+	 * Helper method to clean up the syntax of starting a BTreeWriter thread.
+	 * The parameters pass through to the BTreeWriter constructor.
+	 */
+	public BTreeUtility.BTreeWriter startWriter(TransactionId tid, 
+			int item, int count) {
+
+		BTreeWriter bw = new BTreeWriter(tid, bf, item, count);
+		bw.start();
+		return bw;
+	}
+
+	/**
+	 * Not-so-unit test to construct a deadlock situation.
+	 * 
+	 * This test causes two different transactions to update two (probably) different leaf nodes
+	 * Each transaction can happily insert tuples until the page fills up, but then 
+	 * it needs to obtain a write lock on the root node in order to split the page. This will cause
+	 * a deadlock situation.
+	 */
+	@Test public void testReadWriteDeadlock() throws Exception {
+		System.out.println("testReadWriteDeadlock constructing deadlock:");
+
+		TransactionId tid1 = new TransactionId();
+		TransactionId tid2 = new TransactionId();
+
+		Database.getBufferPool().getPage(tid1, BTreeRootPtrPage.getId(bf.getId()), Permissions.READ_ONLY);
+		Database.getBufferPool().getPage(tid2, BTreeRootPtrPage.getId(bf.getId()), Permissions.READ_ONLY);
+
+		// allow read locks to acquire
+		Thread.sleep(POLL_INTERVAL);
+		
+		BTreeWriter writer1 = startWriter(tid1, item1, count1);
+		BTreeWriter writer2 = startWriter(tid2, item2, count2);
+
+		while (true) {
+			Thread.sleep(POLL_INTERVAL);
+
+			if(writer1.succeeded() || writer2.succeeded()) break;
+
+			if (writer1.getError() != null) {
+				writer1 = null;
+				bp.transactionComplete(tid1);
+				Thread.sleep(rand.nextInt(WAIT_INTERVAL));
+
+				tid1 = new TransactionId();
+				writer1 = startWriter(tid1, item1, count1);
+			}
+
+			if (writer2.getError() != null) {
+				writer2 = null;
+				bp.transactionComplete(tid2);
+				Thread.sleep(rand.nextInt(WAIT_INTERVAL));
+
+				tid2 = new TransactionId();
+				writer2 = startWriter(tid2, item2, count2);
+			}
+
+		}
+
+		System.out.println("testReadWriteDeadlock resolved deadlock");
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeDeadlockTest.class);
+	}
+
+}
+
diff -Naur lab2/test/simpledb/BTreeFileDeleteTest.java lab3/test/simpledb/BTreeFileDeleteTest.java
--- lab2/test/simpledb/BTreeFileDeleteTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeFileDeleteTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,382 @@
+package simpledb;
+
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.Predicate.Op;
+
+import java.io.File;
+import java.util.*;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.*;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeFileDeleteTest extends SimpleDbTestBase {
+	private TransactionId tid;
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before
+	public void setUp() throws Exception {
+		tid = new TransactionId();
+	}
+
+	@After
+	public void tearDown() throws Exception {
+		Database.getBufferPool().transactionComplete(tid);
+	}
+
+	/**
+	 * Unit test for BTreeFile.deleteTuple()
+	 */
+	@Test public void deleteTuple() throws Exception {
+		BTreeFile f;
+		f = BTreeUtility.createRandomBTreeFile(2, 20, null, null, 0);
+		DbFileIterator it = f.iterator(tid);
+		it.open();
+		while(it.hasNext()) {
+			Tuple t = it.next();
+			f.deleteTuple(tid, t);
+		}
+		it.rewind();
+		assertFalse(it.hasNext());
+
+		// insert a couple of tuples
+		f.insertTuple(tid, BTreeUtility.getBTreeTuple(5, 2));
+		f.insertTuple(tid, BTreeUtility.getBTreeTuple(17, 2));
+
+		it.rewind();
+		assertTrue(it.hasNext());
+
+	}
+
+	@Test
+	public void testStealFromLeftLeafPage() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the leaf pages
+		BTreePageId pageId = new BTreePageId(tableid, 1, BTreePageId.LEAF);
+		BTreePageId siblingId = new BTreePageId(tableid, 2, BTreePageId.LEAF);
+		BTreeLeafPage page = BTreeUtility.createRandomLeafPage(pageId, 2, keyField, 
+				BTreeUtility.getNumTuplesPerPage(2)/2 - 1, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE);
+		BTreeLeafPage sibling = BTreeUtility.createRandomLeafPage(siblingId, 2, keyField, 0, BTreeUtility.MAX_RAND_VALUE/2);
+		
+		// create the parent page and the new entry
+		BTreePageId parentId = new BTreePageId(tableid, 3, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = new BTreeInternalPage(parentId, BTreeInternalPage.createEmptyPageData(), keyField);
+		Field key = page.iterator().next().getField(keyField);
+		BTreeEntry entry = new BTreeEntry(key, siblingId, pageId);
+		parent.insertEntry(entry);
+		
+		// set all the pointers
+		page.setParentId(parentId);
+		sibling.setParentId(parentId);
+		page.setLeftSiblingId(siblingId);
+		sibling.setRightSiblingId(pageId);
+		
+		int totalTuples = page.getNumTuples() + sibling.getNumTuples();
+		
+		empty.stealFromLeafPage(page, sibling, parent, entry, false);
+		assertEquals(totalTuples, page.getNumTuples() + sibling.getNumTuples());
+		assertTrue(page.getNumTuples() == totalTuples/2 || page.getNumTuples() == totalTuples/2 + 1);
+		assertTrue(sibling.getNumTuples() == totalTuples/2 || sibling.getNumTuples() == totalTuples/2 + 1);
+		assertTrue(sibling.reverseIterator().next().getField(keyField).compare(Op.LESS_THAN_OR_EQ, 
+				page.iterator().next().getField(keyField)));
+		assertEquals(parent.iterator().next().getKey(), page.iterator().next().getField(keyField));
+	} 
+
+	@Test
+	public void testStealFromRightLeafPage() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the leaf pages
+		BTreePageId pageId = new BTreePageId(tableid, 1, BTreePageId.LEAF);
+		BTreePageId siblingId = new BTreePageId(tableid, 2, BTreePageId.LEAF);
+		BTreeLeafPage page = BTreeUtility.createRandomLeafPage(pageId, 2, keyField, 
+				BTreeUtility.getNumTuplesPerPage(2)/2 - 1, 0, BTreeUtility.MAX_RAND_VALUE/2);
+		BTreeLeafPage sibling = BTreeUtility.createRandomLeafPage(siblingId, 2, keyField, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE);
+		
+		// create the parent page and the new entry
+		BTreePageId parentId = new BTreePageId(tableid, 3, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = new BTreeInternalPage(parentId, BTreeInternalPage.createEmptyPageData(), keyField);
+		Field key = page.iterator().next().getField(keyField);
+		BTreeEntry entry = new BTreeEntry(key, siblingId, pageId);
+		parent.insertEntry(entry);
+		
+		// set all the pointers
+		page.setParentId(parentId);
+		sibling.setParentId(parentId);
+		page.setRightSiblingId(siblingId);
+		sibling.setLeftSiblingId(pageId);
+		
+		int totalTuples = page.getNumTuples() + sibling.getNumTuples();
+		
+		empty.stealFromLeafPage(page, sibling, parent, entry, true);
+		assertEquals(totalTuples, page.getNumTuples() + sibling.getNumTuples());
+		assertTrue(page.getNumTuples() == totalTuples/2 || page.getNumTuples() == totalTuples/2 + 1);
+		assertTrue(sibling.getNumTuples() == totalTuples/2 || sibling.getNumTuples() == totalTuples/2 + 1);
+		assertTrue(page.reverseIterator().next().getField(keyField).compare(Op.LESS_THAN_OR_EQ, 
+				sibling.iterator().next().getField(keyField)));
+		assertEquals(parent.iterator().next().getKey(), sibling.iterator().next().getField(keyField));
+	} 
+
+	@Test
+	public void testMergeLeafPages() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0, 3);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the leaf pages
+		BTreePageId leftPageId = new BTreePageId(tableid, 2, BTreePageId.LEAF);
+		BTreePageId rightPageId = new BTreePageId(tableid, 3, BTreePageId.LEAF);
+		BTreeLeafPage leftPage = BTreeUtility.createRandomLeafPage(leftPageId, 2, keyField, 
+				BTreeUtility.getNumTuplesPerPage(2)/2 - 1, 0, BTreeUtility.MAX_RAND_VALUE/2);
+		BTreeLeafPage rightPage = BTreeUtility.createRandomLeafPage(rightPageId, 2, keyField, 
+				BTreeUtility.getNumTuplesPerPage(2)/2 - 1, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE);
+		
+		// create the parent page and the new entry
+		BTreePageId parentId = new BTreePageId(tableid, 1, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = BTreeUtility.createRandomInternalPage(parentId, keyField, 
+				BTreePageId.LEAF, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE, 2);
+		BTreeEntry entry = parent.iterator().next();
+		Field siblingKey = rightPage.iterator().next().getField(keyField);
+		Field parentKey = entry.getKey();
+		Field minKey = (siblingKey.compare(Op.LESS_THAN, parentKey) ? siblingKey : parentKey);
+		entry.setKey(minKey);
+		parent.updateEntry(entry);
+		int numEntries = parent.getNumEntries();
+		
+		// set all the pointers
+		leftPage.setParentId(parentId);
+		rightPage.setParentId(parentId);
+		leftPage.setRightSiblingId(rightPageId);
+		rightPage.setLeftSiblingId(leftPageId);
+		
+		int totalTuples = leftPage.getNumTuples() + rightPage.getNumTuples();
+		
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+		dirtypages.put(leftPageId, leftPage);
+		dirtypages.put(rightPageId, rightPage);
+		dirtypages.put(parentId, parent);
+		empty.mergeLeafPages(tid, dirtypages, leftPage, rightPage, parent, entry);
+		assertEquals(totalTuples, leftPage.getNumTuples());
+		assertEquals(0, rightPage.getNumTuples());
+		assertEquals(null, leftPage.getRightSiblingId());
+		assertEquals(numEntries - 1, parent.getNumEntries());
+		assertEquals(rightPageId.pageNumber(), empty.getEmptyPageNo(tid, dirtypages));
+	}
+
+	@Test
+	public void testStealFromLeftInternalPage() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		int entriesPerPage = BTreeUtility.getNumEntriesPerPage();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0, 5 + 3*entriesPerPage/2);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the internal pages
+		BTreePageId pageId = new BTreePageId(tableid, 1, BTreePageId.INTERNAL);
+		BTreePageId siblingId = new BTreePageId(tableid, 2, BTreePageId.INTERNAL);
+		BTreeInternalPage page = BTreeUtility.createRandomInternalPage(pageId, keyField, BTreePageId.LEAF,
+				entriesPerPage/2 - 1, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE, 5 + entriesPerPage);
+		BTreeInternalPage sibling = BTreeUtility.createRandomInternalPage(siblingId, keyField, 
+				BTreePageId.LEAF, 0, BTreeUtility.MAX_RAND_VALUE/2, 4);
+		
+		// create the parent page and the new entry
+		BTreePageId parentId = new BTreePageId(tableid, 3, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = new BTreeInternalPage(parentId, BTreeInternalPage.createEmptyPageData(), keyField);
+		Field key = page.iterator().next().getKey();
+		BTreeEntry entry = new BTreeEntry(key, siblingId, pageId);
+		parent.insertEntry(entry);
+				
+		// set all the pointers
+		page.setParentId(parentId);
+		sibling.setParentId(parentId);
+		
+		int totalEntries = page.getNumEntries() + sibling.getNumEntries();
+		int entriesToSteal = totalEntries/2 - page.getNumEntries();
+		
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+		dirtypages.put(pageId, page);
+		dirtypages.put(siblingId, sibling);
+		dirtypages.put(parentId, parent);
+		empty.stealFromLeftInternalPage(tid, dirtypages, page, sibling, parent, entry);
+		
+		// are all the entries still there?
+		assertEquals(totalEntries, page.getNumEntries() + sibling.getNumEntries());
+		
+		// have the entries been evenly distributed?
+		assertTrue(page.getNumEntries() == totalEntries/2 || page.getNumEntries() == totalEntries/2 + 1);
+		assertTrue(sibling.getNumEntries() == totalEntries/2 || sibling.getNumEntries() == totalEntries/2 + 1);
+		
+		// are the keys in the left page less than the keys in the right page?
+		assertTrue(sibling.reverseIterator().next().getKey().compare(Op.LESS_THAN_OR_EQ, 
+				page.iterator().next().getKey()));
+		
+		// is the parent key reasonable?
+		assertTrue(parent.iterator().next().getKey().compare(Op.LESS_THAN_OR_EQ, page.iterator().next().getKey()));
+		assertTrue(parent.iterator().next().getKey().compare(Op.GREATER_THAN_OR_EQ, sibling.reverseIterator().next().getKey()));
+		
+		// are all the parent pointers set?
+		Iterator<BTreeEntry> it = page.iterator();
+		BTreeEntry e = null;
+		int count = 0;
+		while(count < entriesToSteal) {
+			assertTrue(it.hasNext());
+			e = it.next();
+			BTreePage p = (BTreePage) dirtypages.get(e.getLeftChild());
+			assertEquals(pageId, p.getParentId());
+			++count;
+		}
+	}
+
+	@Test
+	public void testStealFromRightInternalPage() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		int entriesPerPage = BTreeUtility.getNumEntriesPerPage();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0, 5 + 3*entriesPerPage/2);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the internal pages
+		BTreePageId pageId = new BTreePageId(tableid, 1, BTreePageId.INTERNAL);
+		BTreePageId siblingId = new BTreePageId(tableid, 2, BTreePageId.INTERNAL);
+		BTreeInternalPage page = BTreeUtility.createRandomInternalPage(pageId, keyField, BTreePageId.LEAF,
+				entriesPerPage/2 - 1, 0, BTreeUtility.MAX_RAND_VALUE/2, 4);
+		BTreeInternalPage sibling = BTreeUtility.createRandomInternalPage(siblingId, keyField, 
+				BTreePageId.LEAF, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE, 4 + entriesPerPage/2);
+		
+		// create the parent page and the new entry
+		BTreePageId parentId = new BTreePageId(tableid, 3, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = new BTreeInternalPage(parentId, BTreeInternalPage.createEmptyPageData(), keyField);
+		Field key = sibling.iterator().next().getKey();
+		BTreeEntry entry = new BTreeEntry(key, pageId, siblingId);
+		parent.insertEntry(entry);
+				
+		// set all the pointers
+		page.setParentId(parentId);
+		sibling.setParentId(parentId);
+		
+		int totalEntries = page.getNumEntries() + sibling.getNumEntries();
+		int entriesToSteal = totalEntries/2 - page.getNumEntries();
+		
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+		dirtypages.put(pageId, page);
+		dirtypages.put(siblingId, sibling);
+		dirtypages.put(parentId, parent);
+		empty.stealFromRightInternalPage(tid, dirtypages, page, sibling, parent, entry);
+		
+		// are all the entries still there?
+		assertEquals(totalEntries, page.getNumEntries() + sibling.getNumEntries());
+		
+		// have the entries been evenly distributed?
+		assertTrue(page.getNumEntries() == totalEntries/2 || page.getNumEntries() == totalEntries/2 + 1);
+		assertTrue(sibling.getNumEntries() == totalEntries/2 || sibling.getNumEntries() == totalEntries/2 + 1);
+		
+		// are the keys in the left page less than the keys in the right page?
+		assertTrue(page.reverseIterator().next().getKey().compare(Op.LESS_THAN_OR_EQ, 
+				sibling.iterator().next().getKey()));
+		
+		// is the parent key reasonable?
+		assertTrue(parent.iterator().next().getKey().compare(Op.LESS_THAN_OR_EQ, sibling.iterator().next().getKey()));
+		assertTrue(parent.iterator().next().getKey().compare(Op.GREATER_THAN_OR_EQ, page.reverseIterator().next().getKey()));
+		
+		// are all the parent pointers set?
+		Iterator<BTreeEntry> it = page.reverseIterator();
+		BTreeEntry e = null;
+		int count = 0;
+		while(count < entriesToSteal) {
+			assertTrue(it.hasNext());
+			e = it.next();
+			BTreePage p = (BTreePage) dirtypages.get(e.getRightChild());
+			assertEquals(pageId, p.getParentId());
+			++count;
+		}
+	}
+
+	@Test
+	public void testMergeInternalPages() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		int entriesPerPage = BTreeUtility.getNumEntriesPerPage();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0, 1 + 2*entriesPerPage);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the internal pages
+		BTreePageId leftPageId = new BTreePageId(tableid, 2, BTreePageId.INTERNAL);
+		BTreePageId rightPageId = new BTreePageId(tableid, 3, BTreePageId.INTERNAL);
+		BTreeInternalPage leftPage = BTreeUtility.createRandomInternalPage(leftPageId, keyField, BTreePageId.LEAF,
+				entriesPerPage/2 - 1, 0, BTreeUtility.MAX_RAND_VALUE/2, 3 + entriesPerPage);
+		BTreeInternalPage rightPage = BTreeUtility.createRandomInternalPage(rightPageId, keyField, BTreePageId.LEAF,
+				entriesPerPage/2 - 1, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE, 2 + 3*entriesPerPage/2);
+		
+		// create the parent page and the new entry
+		BTreePageId parentId = new BTreePageId(tableid, 1, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = BTreeUtility.createRandomInternalPage(parentId, keyField, 
+				BTreePageId.LEAF, BTreeUtility.MAX_RAND_VALUE/2, BTreeUtility.MAX_RAND_VALUE, 2);
+		BTreeEntry entry = parent.iterator().next();
+		Field siblingKey = rightPage.iterator().next().getKey();
+		Field parentKey = entry.getKey();
+		Field minKey = (siblingKey.compare(Op.LESS_THAN, parentKey) ? siblingKey : parentKey);
+		entry.setKey(minKey);
+		parent.updateEntry(entry);
+		int numParentEntries = parent.getNumEntries();
+		
+		// set all the pointers
+		leftPage.setParentId(parentId);
+		rightPage.setParentId(parentId);
+		
+		int totalEntries = leftPage.getNumEntries() + rightPage.getNumEntries();
+		
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+		dirtypages.put(leftPageId, leftPage);
+		dirtypages.put(rightPageId, rightPage);
+		dirtypages.put(parentId, parent);
+		empty.mergeInternalPages(tid, dirtypages, leftPage, rightPage, parent, entry);
+		assertEquals(totalEntries + 1, leftPage.getNumEntries());
+		assertEquals(0, rightPage.getNumEntries());
+		assertEquals(numParentEntries - 1, parent.getNumEntries());
+		assertEquals(rightPageId.pageNumber(), empty.getEmptyPageNo(tid, dirtypages));
+
+		// are all the parent pointers set?
+		Iterator<BTreeEntry> it = leftPage.reverseIterator();
+		BTreeEntry e = null;
+		int count = 0;
+		while(count < entriesPerPage/2 - 1) {
+			assertTrue(it.hasNext());
+			e = it.next();
+			BTreePage p = (BTreePage) dirtypages.get(e.getRightChild());
+			assertEquals(leftPageId, p.getParentId());
+			++count;
+		}
+	}    
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeFileDeleteTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/BTreeFileInsertTest.java lab3/test/simpledb/BTreeFileInsertTest.java
--- lab2/test/simpledb/BTreeFileInsertTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeFileInsertTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,181 @@
+package simpledb;
+
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.Predicate.Op;
+
+import java.io.File;
+import java.util.*;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.*;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeFileInsertTest extends SimpleDbTestBase {
+	private TransactionId tid;
+	
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before
+	public void setUp() throws Exception {
+		tid = new TransactionId();
+	}
+
+	@After
+	public void tearDown() throws Exception {
+		Database.getBufferPool().transactionComplete(tid);
+		
+		// set the page size back to the default
+		BufferPool.resetPageSize();
+		Database.reset();
+	}
+
+	@Test
+	public void testSplitLeafPages() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0, 3);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the leaf page
+		BTreePageId leftPageId = new BTreePageId(tableid, 2, BTreePageId.LEAF);
+		BTreeLeafPage leftPage = BTreeUtility.createRandomLeafPage(leftPageId, 2, keyField, 
+				0, BTreeUtility.MAX_RAND_VALUE);
+				
+		// create the parent page
+		BTreePageId parentId = new BTreePageId(tableid, 1, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = new BTreeInternalPage(parentId, 
+				BTreeInternalPage.createEmptyPageData(), keyField);
+				
+		// set the pointers
+		leftPage.setParentId(parentId);
+		
+		Field field = new IntField(BTreeUtility.MAX_RAND_VALUE/2);
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+		dirtypages.put(leftPageId, leftPage);
+		dirtypages.put(parentId, parent);
+		BTreeLeafPage page = empty.splitLeafPage(tid, dirtypages, leftPage, field);
+		assertTrue(page.getLeftSiblingId() != null || page.getRightSiblingId() != null);
+		BTreeLeafPage otherPage;
+		if(page.getLeftSiblingId() != null) {
+			otherPage = (BTreeLeafPage) dirtypages.get(page.getLeftSiblingId());
+			assertTrue(field.compare(Op.GREATER_THAN_OR_EQ, 
+					otherPage.reverseIterator().next().getField(keyField)));
+		}
+		else { // page.getRightSiblingId() != null
+			otherPage = (BTreeLeafPage) dirtypages.get(page.getRightSiblingId());
+			assertTrue(field.compare(Op.LESS_THAN_OR_EQ, 
+					otherPage.iterator().next().getField(keyField)));
+		}
+		
+		int totalTuples = page.getNumTuples() + otherPage.getNumTuples();
+		assertEquals(BTreeUtility.getNumTuplesPerPage(2), totalTuples);
+		assertTrue(BTreeUtility.getNumTuplesPerPage(2)/2 == page.getNumTuples() || 
+				BTreeUtility.getNumTuplesPerPage(2)/2 + 1 == page.getNumTuples());
+		assertTrue(BTreeUtility.getNumTuplesPerPage(2)/2 == otherPage.getNumTuples() || 
+				BTreeUtility.getNumTuplesPerPage(2)/2 + 1 == otherPage.getNumTuples());
+		assertEquals(1, parent.getNumEntries());
+	}
+
+	@Test
+	public void testSplitInternalPages() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		int entriesPerPage = BTreeUtility.getNumEntriesPerPage();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0, 3 + entriesPerPage);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the internal page
+		BTreePageId leftPageId = new BTreePageId(tableid, 2, BTreePageId.INTERNAL);
+		BTreeInternalPage leftPage = BTreeUtility.createRandomInternalPage(leftPageId, keyField, BTreePageId.LEAF,
+				0, BTreeUtility.MAX_RAND_VALUE, 3);
+				
+		// create the parent page
+		BTreePageId parentId = new BTreePageId(tableid, 1, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = new BTreeInternalPage(parentId, 
+				BTreeInternalPage.createEmptyPageData(), keyField);
+				
+		// set the pointers
+		leftPage.setParentId(parentId);
+		
+		Field field = new IntField(BTreeUtility.MAX_RAND_VALUE/2);
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+		dirtypages.put(leftPageId, leftPage);
+		dirtypages.put(parentId, parent);
+		BTreeInternalPage page = empty.splitInternalPage(tid, dirtypages, leftPage, field);
+		BTreeInternalPage otherPage;
+		assertEquals(1, parent.getNumEntries());
+		BTreeEntry parentEntry = parent.iterator().next();
+		if(parentEntry.getLeftChild().equals(page.getId())) {
+			otherPage = (BTreeInternalPage) dirtypages.get(parentEntry.getRightChild());
+			assertTrue(field.compare(Op.LESS_THAN_OR_EQ, 
+					otherPage.iterator().next().getKey()));
+		}
+		else { // parentEntry.getRightChild().equals(page.getId())
+			otherPage = (BTreeInternalPage) dirtypages.get(parentEntry.getLeftChild());
+			assertTrue(field.compare(Op.GREATER_THAN_OR_EQ, 
+					otherPage.reverseIterator().next().getKey()));
+		}
+		
+		int totalEntries = page.getNumEntries() + otherPage.getNumEntries();
+		assertEquals(entriesPerPage - 1, totalEntries);
+		assertTrue(entriesPerPage/2 == page.getNumEntries() || 
+				entriesPerPage/2 - 1 == page.getNumEntries());
+		assertTrue(entriesPerPage/2 == otherPage.getNumEntries() || 
+				entriesPerPage/2 - 1 == otherPage.getNumEntries());
+	}    
+
+	@Test
+	public void testReusePage() throws Exception {
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 0, 3);
+		int tableid = empty.getId();
+		int keyField = 0;
+
+		// create the leaf page
+		HashMap<PageId, Page> dirtypages = new HashMap<PageId, Page>();
+		empty.setEmptyPage(tid, dirtypages, 2);
+		BTreePageId leftPageId = new BTreePageId(tableid, 3, BTreePageId.LEAF);
+		BTreeLeafPage leftPage = BTreeUtility.createRandomLeafPage(leftPageId, 2, keyField, 
+				0, BTreeUtility.MAX_RAND_VALUE);
+				
+		// create the parent page
+		BTreePageId parentId = new BTreePageId(tableid, 1, BTreePageId.INTERNAL);
+		BTreeInternalPage parent = new BTreeInternalPage(parentId, 
+				BTreeInternalPage.createEmptyPageData(), keyField);
+				
+		// set the pointers
+		leftPage.setParentId(parentId);
+		
+		Field field = new IntField(BTreeUtility.MAX_RAND_VALUE/2);
+		dirtypages.put(leftPageId, leftPage);
+		dirtypages.put(parentId, parent);
+		BTreeLeafPage page = empty.splitLeafPage(tid, dirtypages, leftPage, field);
+		assertTrue(page.getLeftSiblingId() != null || page.getRightSiblingId() != null);
+		BTreeLeafPage otherPage;
+		if(page.getLeftSiblingId() != null) {
+			otherPage = (BTreeLeafPage) dirtypages.get(page.getLeftSiblingId());
+		}
+		else { // page.getRightSiblingId() != null
+			otherPage = (BTreeLeafPage) dirtypages.get(page.getRightSiblingId());
+		}
+		
+		assertTrue(page.getId().pageNumber() == 2 || otherPage.getId().pageNumber() == 2);
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeFileInsertTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/BTreeFileReadTest.java lab3/test/simpledb/BTreeFileReadTest.java
--- lab2/test/simpledb/BTreeFileReadTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeFileReadTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,210 @@
+package simpledb;
+
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.Predicate.Op;
+
+import java.util.*;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.*;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeFileReadTest extends SimpleDbTestBase {
+	private BTreeFile f;
+	private TransactionId tid;
+	private TupleDesc td;
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before
+	public void setUp() throws Exception {
+		f = BTreeUtility.createRandomBTreeFile(2, 20, null, null, 0);
+		td = Utility.getTupleDesc(2);
+		tid = new TransactionId();
+	}
+
+	@After
+	public void tearDown() throws Exception {
+		Database.getBufferPool().transactionComplete(tid);
+	}
+
+	/**
+	 * Unit test for BTreeFile.getId()
+	 */
+	@Test
+	public void getId() throws Exception {
+		int id = f.getId();
+
+		// NOTE(ghuo): the value could be anything. test determinism, at least.
+		assertEquals(id, f.getId());
+		assertEquals(id, f.getId());
+
+		BTreeFile other = BTreeUtility.createRandomBTreeFile(1, 1, null, null, 0);
+		assertTrue(id != other.getId());
+	}
+
+	/**
+	 * Unit test for BTreeFile.getTupleDesc()
+	 */
+	@Test
+	public void getTupleDesc() throws Exception {    	
+		assertEquals(td, f.getTupleDesc());        
+	}
+	/**
+	 * Unit test for BTreeFile.numPages()
+	 */
+	@Test
+	public void numPages() throws Exception {
+		assertEquals(1, f.numPages());
+	}
+
+	/**
+	 * Unit test for BTreeFile.readPage()
+	 */
+	@Test
+	public void readPage() throws Exception {
+		BTreePageId rootPtrPid = new BTreePageId(f.getId(), 0, BTreePageId.ROOT_PTR);
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) f.readPage(rootPtrPid);
+
+		assertEquals(1, rootPtr.getRootId().pageNumber());
+		assertEquals(BTreePageId.LEAF, rootPtr.getRootId().pgcateg());
+
+		BTreePageId pid = new BTreePageId(f.getId(), 1, BTreePageId.LEAF);
+		BTreeLeafPage page = (BTreeLeafPage) f.readPage(pid);
+
+		// NOTE(ghuo): we try not to dig too deeply into the Page API here; we
+		// rely on BTreePageTest for that. perform some basic checks.
+		assertEquals(482, page.getNumEmptySlots());
+		assertTrue(page.isSlotUsed(1));
+		assertFalse(page.isSlotUsed(20));
+	}
+
+	@Test
+	public void testIteratorBasic() throws Exception {
+		BTreeFile smallFile = BTreeUtility.createRandomBTreeFile(2, 3, null,
+				null, 0);
+
+		DbFileIterator it = smallFile.iterator(tid);
+		// Not open yet
+		assertFalse(it.hasNext());
+		try {
+			it.next();
+			fail("expected exception");
+		} catch (NoSuchElementException e) {
+		}
+
+		it.open();
+		int count = 0;
+		while (it.hasNext()) {
+			assertNotNull(it.next());
+			count += 1;
+		}
+		assertEquals(3, count);
+		it.close();
+	}
+
+	@Test
+	public void testIteratorClose() throws Exception {
+		// make more than 1 page. Previous closed iterator would start fetching
+		// from page 1.
+		BTreeFile twoLeafPageFile = BTreeUtility.createRandomBTreeFile(2, 520,
+				null, null, 0);
+
+		// there should be 3 pages - two leaf pages and one internal page (the root)
+		assertEquals(3, twoLeafPageFile.numPages());
+
+		DbFileIterator it = twoLeafPageFile.iterator(tid);
+		it.open();
+		assertTrue(it.hasNext());
+		it.close();
+		try {
+			it.next();
+			fail("expected exception");
+		} catch (NoSuchElementException e) {
+		}
+		// close twice is harmless
+		it.close();
+	}
+
+	/**
+	 * Unit test for BTreeFile.indexIterator()
+	 */
+	@Test public void indexIterator() throws Exception {
+		BTreeFile twoLeafPageFile = BTreeUtility.createBTreeFile(2, 520,
+				null, null, 0);
+		Field f =  new IntField(5);
+
+		// greater than
+		IndexPredicate ipred = new IndexPredicate(Op.GREATER_THAN, f);
+		DbFileIterator it = twoLeafPageFile.indexIterator(tid, ipred);
+		it.open();
+		int count = 0;
+		while(it.hasNext()) {
+			Tuple t = it.next();
+			assertTrue(t.getField(0).compare(Op.GREATER_THAN, f));
+			count++;
+		}
+		assertEquals(515, count);
+		it.close();
+
+		// less than or equal to
+		ipred = new IndexPredicate(Op.LESS_THAN_OR_EQ, f);
+		it = twoLeafPageFile.indexIterator(tid, ipred);
+		it.open();
+		count = 0;
+		while(it.hasNext()) {
+			Tuple t = it.next();
+			assertTrue(t.getField(0).compare(Op.LESS_THAN_OR_EQ, f));
+			count++;
+		}
+		assertEquals(5, count);
+		it.close();
+
+		// equal to
+		ipred = new IndexPredicate(Op.EQUALS, f);
+		it = twoLeafPageFile.indexIterator(tid, ipred);
+		it.open();
+		count = 0;
+		while(it.hasNext()) {
+			Tuple t = it.next();
+			assertTrue(t.getField(0).compare(Op.EQUALS, f));
+			count++;
+		}
+		assertEquals(1, count);
+		it.close();
+
+		// now insert a record and ensure EQUALS returns both records
+		twoLeafPageFile.insertTuple(tid, BTreeUtility.getBTreeTuple(5, 2));
+		ipred = new IndexPredicate(Op.EQUALS, f);
+		it = twoLeafPageFile.indexIterator(tid, ipred);
+		it.open();
+		count = 0;
+		while(it.hasNext()) {
+			Tuple t = it.next();
+			assertTrue(t.getField(0).compare(Op.EQUALS, f));
+			count++;
+		}
+		assertEquals(2, count);
+		it.close();
+
+		// search for a non-existent record
+		f = new IntField(1000);
+		ipred = new IndexPredicate(Op.GREATER_THAN, f);
+		it = twoLeafPageFile.indexIterator(tid, ipred);
+		it.open();
+		assertFalse(it.hasNext());
+		it.close();
+
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeFileReadTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/BTreeHeaderPageTest.java lab3/test/simpledb/BTreeHeaderPageTest.java
--- lab2/test/simpledb/BTreeHeaderPageTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeHeaderPageTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,188 @@
+package simpledb;
+
+import simpledb.TestUtil.SkeletonFile;
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.systemtest.SystemTestUtil;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeHeaderPageTest extends SimpleDbTestBase {
+	private BTreePageId pid;
+
+	public static final byte[] EXAMPLE_DATA;
+	static {
+		EXAMPLE_DATA = BTreeHeaderPage.createEmptyPageData();
+	}
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before public void addTable() throws Exception {
+		this.pid = new BTreePageId(-1, -1, BTreePageId.HEADER);
+		Database.getCatalog().addTable(new SkeletonFile(-1, Utility.getTupleDesc(2)), SystemTestUtil.getUUID());
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.getId()
+	 */
+	@Test public void getId() throws Exception {
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		assertEquals(pid, page.getId());
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.getPrevPageId()
+	 */
+	@Test public void getPrevPageId() throws Exception {
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		assertTrue(page.getPrevPageId() == null);
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.getNextPageId()
+	 */
+	@Test public void getNextPageId() throws Exception {
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		assertTrue(page.getNextPageId() == null);
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.setPrevPageId()
+	 */
+	@Test public void setPrevPageId() throws Exception {
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 1, BTreePageId.HEADER);
+		page.setPrevPageId(id);
+		assertEquals(id, page.getPrevPageId());
+
+		id = new BTreePageId(pid.getTableId(), 1, BTreePageId.INTERNAL);
+		try {
+			page.setPrevPageId(id);
+			throw new Exception("should not be able to set prevPageId to internal node; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.setNextPageId()
+	 */
+	@Test public void setNextPageId() throws Exception {
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 1, BTreePageId.HEADER);
+		page.setNextPageId(id);
+		assertEquals(id, page.getNextPageId());
+
+		id = new BTreePageId(pid.getTableId() + 1, 1, BTreePageId.HEADER);
+		try {
+			page.setNextPageId(id);
+			throw new Exception("should not be able to set nextPageId to a page from a different table; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.numSlots()
+	 */
+	@Test public void numSlots() throws Exception {
+		assertEquals(32704, BTreeHeaderPage.getNumSlots());
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.getEmptySlot()
+	 */
+	@Test public void getEmptySlot() throws Exception {
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		assertEquals(0, page.getEmptySlot());
+		page.init();
+		assertEquals(-1, page.getEmptySlot());
+		page.markSlotUsed(50, false);
+		assertEquals(50, page.getEmptySlot());
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.isSlotUsed() and BTreeHeaderPage.markSlotUsed()
+	 */
+	@Test public void getSlot() throws Exception {
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		page.init();
+		for (int i = 0; i < 20; ++i) {
+			page.markSlotUsed(i, false);
+		}
+
+		for (int i = 0; i < 20; i += 2) {
+			page.markSlotUsed(i, true);
+		}
+
+		for (int i = 0; i < 20; ++i) {
+			if(i % 2 == 0)
+				assertTrue(page.isSlotUsed(i));
+			else
+				assertFalse(page.isSlotUsed(i));
+		}
+
+		for (int i = 20; i < 32704; ++i)
+			assertTrue(page.isSlotUsed(i));
+
+		assertEquals(1, page.getEmptySlot());
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.getPageData()
+	 */
+	@Test public void getPageData() throws Exception {
+		BTreeHeaderPage page0 = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		page0.init();
+		for (int i = 0; i < 20; ++i) {
+			page0.markSlotUsed(i, false);
+		}
+
+		for (int i = 0; i < 20; i += 2) {
+			page0.markSlotUsed(i, true);
+		}
+
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, page0.getPageData());
+
+		for (int i = 0; i < 20; ++i) {
+			if(i % 2 == 0)
+				assertTrue(page.isSlotUsed(i));
+			else
+				assertFalse(page.isSlotUsed(i));
+		}
+
+		for (int i = 20; i < 32704; ++i)
+			assertTrue(page.isSlotUsed(i));
+
+		assertEquals(1, page.getEmptySlot());
+	}
+
+	/**
+	 * Unit test for BTreeHeaderPage.isDirty()
+	 */
+	@Test public void testDirty() throws Exception {
+		TransactionId tid = new TransactionId();
+		BTreeHeaderPage page = new BTreeHeaderPage(pid, EXAMPLE_DATA);
+		page.markDirty(true, tid);
+		TransactionId dirtier = page.isDirty();
+		assertEquals(true, dirtier != null);
+		assertEquals(true, dirtier == tid);
+
+		page.markDirty(false, tid);
+		dirtier = page.isDirty();
+		assertEquals(false, dirtier != null);
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeHeaderPageTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/BTreeInternalPageTest.java lab3/test/simpledb/BTreeInternalPageTest.java
--- lab2/test/simpledb/BTreeInternalPageTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeInternalPageTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,322 @@
+package simpledb;
+
+import simpledb.BTreeFileEncoder.EntryComparator;
+import simpledb.BTreeFileEncoder.ReverseEntryComparator;
+import simpledb.TestUtil.SkeletonFile;
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.systemtest.SystemTestUtil;
+
+//import java.io.File;
+import java.io.IOException;
+import java.util.*;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeInternalPageTest extends SimpleDbTestBase {
+	private BTreePageId pid;
+
+	// these entries have been carefully chosen to be valid entries when
+	// inserted in order. Be careful if you change them!
+	public static final int[][] EXAMPLE_VALUES = new int[][] {
+		{ 2, 6350, 4 },
+		{ 4, 9086, 5 },
+		{ 5, 17197, 7 },
+		{ 7, 22064, 9 },
+		{ 9, 22189, 10 },
+		{ 10, 28617, 11 },
+		{ 11, 31933, 13 },
+		{ 13, 33549, 14 },
+		{ 14, 34784, 15 },
+		{ 15, 42878, 17 },
+		{ 17, 45569, 19 },
+		{ 19, 56462, 20 },
+		{ 20, 62778, 21 },
+		{ 15, 42812, 16 },
+		{ 2, 3596, 3 },
+		{ 6, 17876, 7 },
+		{ 1, 1468, 2 },
+		{ 11, 29402, 12 },
+		{ 18, 51440, 19 },
+		{ 7, 19209, 8 }
+	};
+
+	public static final byte[] EXAMPLE_DATA;
+	static {
+		// Build the input table
+		ArrayList<BTreeEntry> entries = new ArrayList<BTreeEntry>();
+		for (int[] entry : EXAMPLE_VALUES) {
+			BTreePageId leftChild = new BTreePageId(-1, entry[0], BTreePageId.LEAF);
+			BTreePageId rightChild = new BTreePageId(-1, entry[2], BTreePageId.LEAF);
+			BTreeEntry e = new BTreeEntry(new IntField(entry[1]), leftChild, rightChild);
+			entries.add(e);
+		}
+
+		// Convert it to a BTreeInternalPage
+		try {
+			EXAMPLE_DATA = BTreeFileEncoder.convertToInternalPage(entries, 
+					BufferPool.getPageSize(), Type.INT_TYPE, BTreePageId.LEAF);
+		} catch (IOException e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before public void addTable() throws Exception {
+		this.pid = new BTreePageId(-1, -1, BTreePageId.INTERNAL);
+		Database.getCatalog().addTable(new SkeletonFile(-1, Utility.getTupleDesc(2)), SystemTestUtil.getUUID());
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.getId()
+	 */
+	@Test public void getId() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		assertEquals(pid, page.getId());
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.getParentId()
+	 */
+	@Test public void getParentId() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		assertEquals(new BTreePageId(pid.getTableId(), 0, BTreePageId.ROOT_PTR), page.getParentId());
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.getParentId()
+	 */
+	@Test public void setParentId() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 1, BTreePageId.INTERNAL);
+		page.setParentId(id);
+		assertEquals(id, page.getParentId());
+
+		id = new BTreePageId(pid.getTableId(), 1, BTreePageId.LEAF);
+		try {
+			page.setParentId(id);
+			throw new Exception("should not be able to set parentId to leaf node; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+
+		id = new BTreePageId(pid.getTableId() + 1, 1, BTreePageId.INTERNAL);
+		try {
+			page.setParentId(id);
+			throw new Exception("should not be able to set parentId to a page from a different table; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.iterator()
+	 */
+	@Test public void testIterator() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		Iterator<BTreeEntry> it = page.iterator();
+
+		ArrayList<BTreeEntry> entries = new ArrayList<BTreeEntry>();
+		for (int[] entry : EXAMPLE_VALUES) {
+			BTreePageId leftChild = new BTreePageId(-1, entry[0], BTreePageId.LEAF);
+			BTreePageId rightChild = new BTreePageId(-1, entry[2], BTreePageId.LEAF);
+			BTreeEntry e = new BTreeEntry(new IntField(entry[1]), leftChild, rightChild);
+			entries.add(e);
+		}
+		Collections.sort(entries, new EntryComparator());
+
+		int row = 0;
+		while (it.hasNext()) {
+			BTreeEntry e = it.next();
+
+			assertEquals(entries.get(row).getKey(), e.getKey());
+			row++;
+		}
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.reverseIterator()
+	 */
+	@Test public void testReverseIterator() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		Iterator<BTreeEntry> it = page.reverseIterator();
+
+		ArrayList<BTreeEntry> entries = new ArrayList<BTreeEntry>();
+		for (int[] entry : EXAMPLE_VALUES) {
+			BTreePageId leftChild = new BTreePageId(-1, entry[0], BTreePageId.LEAF);
+			BTreePageId rightChild = new BTreePageId(-1, entry[2], BTreePageId.LEAF);
+			BTreeEntry e = new BTreeEntry(new IntField(entry[1]), leftChild, rightChild);
+			entries.add(e);
+		}
+		Collections.sort(entries, new ReverseEntryComparator());
+
+		int row = 0;
+		while (it.hasNext()) {
+			BTreeEntry e = it.next();
+
+			assertEquals(entries.get(row).getKey(), e.getKey());
+			row++;
+		}
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.getNumEmptySlots()
+	 */
+	@Test public void getNumEmptySlots() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		assertEquals(483, page.getNumEmptySlots());
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.isSlotUsed()
+	 */
+	@Test public void getSlot() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+
+		// assuming the first slot is used for the extra child pointer
+		for (int i = 0; i < 21; ++i)
+			assertTrue(page.isSlotUsed(i));
+
+		for (int i = 21; i < 504; ++i)
+			assertFalse(page.isSlotUsed(i));
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.isDirty()
+	 */
+	@Test public void testDirty() throws Exception {
+		TransactionId tid = new TransactionId();
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		page.markDirty(true, tid);
+		TransactionId dirtier = page.isDirty();
+		assertEquals(true, dirtier != null);
+		assertEquals(true, dirtier == tid);
+
+		page.markDirty(false, tid);
+		dirtier = page.isDirty();
+		assertEquals(false, dirtier != null);
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.addEntry()
+	 */
+	@Test public void addEntry() throws Exception {
+		// create a blank page
+		byte[] data = BTreeInternalPage.createEmptyPageData();
+		BTreeInternalPage page = new BTreeInternalPage(pid, data, 0);
+
+		// insert entries into the page
+		ArrayList<BTreeEntry> entries = new ArrayList<BTreeEntry>();
+		for (int[] entry : EXAMPLE_VALUES) {
+			BTreePageId leftChild = new BTreePageId(pid.getTableId(), entry[0], BTreePageId.LEAF);
+			BTreePageId rightChild = new BTreePageId(pid.getTableId(), entry[2], BTreePageId.LEAF);
+			BTreeEntry e = new BTreeEntry(new IntField(entry[1]), leftChild, rightChild);
+			entries.add(e);
+			page.insertEntry(e);
+		}
+
+		// check that the entries are ordered by the key and
+		// all child pointers are present
+		Collections.sort(entries, new EntryComparator());
+		Iterator<BTreeEntry> it0 = page.iterator();
+		int childPtr = 1;
+		for(BTreeEntry e : entries) {
+			BTreeEntry next = it0.next();
+			assertTrue(e.getKey().equals(next.getKey()));
+			assertTrue(next.getLeftChild().pageNumber() == childPtr);
+			assertTrue(next.getRightChild().pageNumber() == ++childPtr);
+		}
+
+		// now insert entries until the page fills up
+		int free = page.getNumEmptySlots();
+
+		// NOTE(ghuo): this nested loop existence check is slow, but it
+		// shouldn't make a difference for n = 503 slots.
+
+		for (int i = 0; i < free; ++i) {
+			BTreeEntry addition = BTreeUtility.getBTreeEntry(i+21, 70000+i, pid.getTableId());
+			page.insertEntry(addition);
+			assertEquals(free-i-1, page.getNumEmptySlots());
+
+			// loop through the iterator to ensure that the entry actually exists
+			// on the page
+			Iterator<BTreeEntry> it = page.iterator();
+			boolean found = false;
+			while (it.hasNext()) {
+				BTreeEntry e = it.next();
+				if (e.getKey().equals(addition.getKey()) && e.getLeftChild().equals(addition.getLeftChild()) &&
+						e.getRightChild().equals(addition.getRightChild())) {
+					found = true;
+
+					// verify that the RecordId is sane
+					assertTrue(page.getId().equals(e.getRecordId().getPageId()));
+					break;
+				}
+			}
+			assertTrue(found);
+		}
+
+		// now, the page should be full.
+		try {
+			page.insertEntry(BTreeUtility.getBTreeEntry(0, 5, pid.getTableId()));
+			throw new Exception("page should be full; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.deleteEntry() with false entries
+	 */
+	@Test(expected=DbException.class)
+	public void deleteNonexistentEntry() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		page.deleteKeyAndRightChild(BTreeUtility.getBTreeEntry(2));
+	}
+
+	/**
+	 * Unit test for BTreeInternalPage.deleteEntry()
+	 */
+	@Test public void deleteEntry() throws Exception {
+		BTreeInternalPage page = new BTreeInternalPage(pid, EXAMPLE_DATA, 0);
+		int free = page.getNumEmptySlots();
+
+		// first, build a list of the entries on the page.
+		Iterator<BTreeEntry> it = page.iterator();
+		LinkedList<BTreeEntry> entries = new LinkedList<BTreeEntry>();
+		while (it.hasNext())
+			entries.add(it.next());
+		BTreeEntry first = entries.getFirst();
+
+		// now, delete them one-by-one from both the front and the end.
+		int deleted = 0;
+		while (entries.size() > 0) {
+			page.deleteKeyAndRightChild(entries.removeFirst());
+			page.deleteKeyAndRightChild(entries.removeLast());
+			deleted += 2;
+			assertEquals(free + deleted, page.getNumEmptySlots());
+		}
+
+		// now, the page should be empty.
+		try {
+			page.deleteKeyAndRightChild(first);
+			throw new Exception("page should be empty; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeInternalPageTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/BTreeLeafPageTest.java lab3/test/simpledb/BTreeLeafPageTest.java
--- lab2/test/simpledb/BTreeLeafPageTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeLeafPageTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,345 @@
+package simpledb;
+
+import simpledb.BTreeFileEncoder.TupleComparator;
+import simpledb.TestUtil.SkeletonFile;
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.systemtest.SystemTestUtil;
+
+//import java.io.File;
+import java.io.IOException;
+import java.util.*;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeLeafPageTest extends SimpleDbTestBase {
+	private BTreePageId pid;
+
+	public static final int[][] EXAMPLE_VALUES = new int[][] {
+		{ 31933, 862 },
+		{ 29402, 56883 },
+		{ 1468, 5825 },
+		{ 17876, 52278 },
+		{ 6350, 36090 },
+		{ 34784, 43771 },
+		{ 28617, 56874 },
+		{ 19209, 23253 },
+		{ 56462, 24979 },
+		{ 51440, 56685 },
+		{ 3596, 62307 },
+		{ 45569, 2719 },
+		{ 22064, 43575 },
+		{ 42812, 44947 },
+		{ 22189, 19724 },
+		{ 33549, 36554 },
+		{ 9086, 53184 },
+		{ 42878, 33394 },
+		{ 62778, 21122 },
+		{ 17197, 16388 }
+	};
+
+	public static final byte[] EXAMPLE_DATA;
+	static {
+		// Build the input table
+		ArrayList<Tuple> tuples = new ArrayList<Tuple>();
+		for (int[] tuple : EXAMPLE_VALUES) {
+			Tuple tup = new Tuple(Utility.getTupleDesc(2));
+			for (int i = 0; i < tuple.length; i++) {
+				tup.setField(i, new IntField(tuple[i]));
+			}
+			tuples.add(tup);
+		}
+
+		// Convert it to a BTreeLeafPage
+		try {
+			EXAMPLE_DATA = BTreeFileEncoder.convertToLeafPage(tuples, 
+					BufferPool.getPageSize(), 2, new Type[]{Type.INT_TYPE, Type.INT_TYPE}, 0);
+		} catch (IOException e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before public void addTable() throws Exception {
+		this.pid = new BTreePageId(-1, -1, BTreePageId.LEAF);
+		Database.getCatalog().addTable(new SkeletonFile(-1, Utility.getTupleDesc(2)), SystemTestUtil.getUUID());
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.getId()
+	 */
+	@Test public void getId() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		assertEquals(pid, page.getId());
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.getParentId()
+	 */
+	@Test public void getParentId() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		assertEquals(new BTreePageId(pid.getTableId(), 0, BTreePageId.ROOT_PTR), page.getParentId());
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.getLeftSiblingId()
+	 */
+	@Test public void getLeftSiblingId() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		assertTrue(page.getLeftSiblingId() == null);
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.getRightSiblingId()
+	 */
+	@Test public void getRightSiblingId() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		assertTrue(page.getRightSiblingId() == null);
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.setParentId()
+	 */
+	@Test public void setParentId() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 1, BTreePageId.INTERNAL);
+		page.setParentId(id);
+		assertEquals(id, page.getParentId());
+
+		id = new BTreePageId(pid.getTableId(), 1, BTreePageId.LEAF);
+		try {
+			page.setParentId(id);
+			throw new Exception("should not be able to set parentId to leaf node; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.setLeftSiblingId()
+	 */
+	@Test public void setLeftSiblingId() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 1, BTreePageId.LEAF);
+		page.setLeftSiblingId(id);
+		assertEquals(id, page.getLeftSiblingId());
+
+		id = new BTreePageId(pid.getTableId(), 1, BTreePageId.INTERNAL);
+		try {
+			page.setLeftSiblingId(id);
+			throw new Exception("should not be able to set leftSiblingId to internal node; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.setRightSiblingId()
+	 */
+	@Test public void setRightSiblingId() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 1, BTreePageId.LEAF);
+		page.setRightSiblingId(id);
+		assertEquals(id, page.getRightSiblingId());
+
+		id = new BTreePageId(pid.getTableId() + 1, 1, BTreePageId.LEAF);
+		try {
+			page.setRightSiblingId(id);
+			throw new Exception("should not be able to set rightSiblingId to a page from a different table; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.iterator()
+	 */
+	@Test public void testIterator() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		Iterator<Tuple> it = page.iterator();
+
+		ArrayList<Tuple> tuples = new ArrayList<Tuple>();
+		for (int[] tuple : EXAMPLE_VALUES) {
+			Tuple tup = new Tuple(Utility.getTupleDesc(2));
+			for (int i = 0; i < tuple.length; i++) {
+				tup.setField(i, new IntField(tuple[i]));
+			}
+			tuples.add(tup);
+		}
+		Collections.sort(tuples, new TupleComparator(0));
+
+		int row = 0;
+		while (it.hasNext()) {
+			Tuple tup = it.next();
+
+			assertEquals(tuples.get(row).getField(0), tup.getField(0));
+			assertEquals(tuples.get(row).getField(1), tup.getField(1));
+			row++;
+		}
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.getNumEmptySlots()
+	 */
+	@Test public void getNumEmptySlots() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		assertEquals(482, page.getNumEmptySlots());
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.isSlotUsed()
+	 */
+	@Test public void getSlot() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+
+		for (int i = 0; i < 20; ++i)
+			assertTrue(page.isSlotUsed(i));
+
+		for (int i = 20; i < 502; ++i)
+			assertFalse(page.isSlotUsed(i));
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.isDirty()
+	 */
+	@Test public void testDirty() throws Exception {
+		TransactionId tid = new TransactionId();
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		page.markDirty(true, tid);
+		TransactionId dirtier = page.isDirty();
+		assertEquals(true, dirtier != null);
+		assertEquals(true, dirtier == tid);
+
+		page.markDirty(false, tid);
+		dirtier = page.isDirty();
+		assertEquals(false, dirtier != null);
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.addTuple()
+	 */
+	@Test public void addTuple() throws Exception {
+		// create two blank pages -- one keyed on the first field, 
+		// the second keyed on the second field
+		byte[] data = BTreeLeafPage.createEmptyPageData();
+		BTreeLeafPage page0 = new BTreeLeafPage(pid, data, 0);
+		BTreeLeafPage page1 = new BTreeLeafPage(pid, data, 1);
+
+		// insert tuples into both pages
+		ArrayList<Tuple> tuples = new ArrayList<Tuple>();
+		for (int[] tuple : EXAMPLE_VALUES) {
+			Tuple tup = new Tuple(Utility.getTupleDesc(2));
+			for (int i = 0; i < tuple.length; i++) {
+				tup.setField(i, new IntField(tuple[i]));
+			}
+			tuples.add(tup);
+			page0.insertTuple(tup);
+			page1.insertTuple(tup);
+		}
+
+		// check that the tuples are ordered by field 0 in page0
+		Collections.sort(tuples, new TupleComparator(0));
+		Iterator<Tuple> it0 = page0.iterator();
+		for(Tuple tup : tuples) {
+			assertTrue(tup.equals(it0.next()));
+		}
+
+		// check that the tuples are ordered by field 1 in page1
+		Collections.sort(tuples, new TupleComparator(1));
+		Iterator<Tuple> it1 = page1.iterator();
+		for(Tuple tup : tuples) {
+			assertTrue(tup.equals(it1.next()));
+		}
+
+		// now insert tuples until the page fills up
+		int free = page0.getNumEmptySlots();
+
+		// NOTE(ghuo): this nested loop existence check is slow, but it
+		// shouldn't make a difference for n = 502 slots.
+
+		for (int i = 0; i < free; ++i) {
+			Tuple addition = BTreeUtility.getBTreeTuple(i, 2);
+			page0.insertTuple(addition);
+			assertEquals(free-i-1, page0.getNumEmptySlots());
+
+			// loop through the iterator to ensure that the tuple actually exists
+			// on the page
+			Iterator<Tuple> it = page0.iterator();
+			boolean found = false;
+			while (it.hasNext()) {
+				Tuple tup = it.next();
+				if (TestUtil.compareTuples(addition, tup)) {
+					found = true;
+
+					// verify that the RecordId is sane
+					assertTrue(page0.getId().equals(tup.getRecordId().getPageId()));
+					break;
+				}
+			}
+			assertTrue(found);
+		}
+
+		// now, the page should be full.
+		try {
+			page0.insertTuple(BTreeUtility.getBTreeTuple(0, 2));
+			throw new Exception("page should be full; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.deleteTuple() with false tuples
+	 */
+	@Test(expected=DbException.class)
+	public void deleteNonexistentTuple() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		page.deleteTuple(BTreeUtility.getBTreeTuple(2, 2));
+	}
+
+	/**
+	 * Unit test for BTreeLeafPage.deleteTuple()
+	 */
+	@Test public void deleteTuple() throws Exception {
+		BTreeLeafPage page = new BTreeLeafPage(pid, EXAMPLE_DATA, 0);
+		int free = page.getNumEmptySlots();
+
+		// first, build a list of the tuples on the page.
+		Iterator<Tuple> it = page.iterator();
+		LinkedList<Tuple> tuples = new LinkedList<Tuple>();
+		while (it.hasNext())
+			tuples.add(it.next());
+		Tuple first = tuples.getFirst();
+
+		// now, delete them one-by-one from both the front and the end.
+		int deleted = 0;
+		while (tuples.size() > 0) {
+			page.deleteTuple(tuples.removeFirst());
+			page.deleteTuple(tuples.removeLast());
+			deleted += 2;
+			assertEquals(free + deleted, page.getNumEmptySlots());
+		}
+
+		// now, the page should be empty.
+		try {
+			page.deleteTuple(first);
+			throw new Exception("page should be empty; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeLeafPageTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/BTreeNextKeyLockingTest.java lab3/test/simpledb/BTreeNextKeyLockingTest.java
--- lab2/test/simpledb/BTreeNextKeyLockingTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeNextKeyLockingTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,245 @@
+package simpledb;
+
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.BTreeUtility.BTreeWriter;
+import simpledb.Predicate.Op;
+
+import java.util.*;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.*;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeNextKeyLockingTest extends SimpleDbTestBase {
+	private TransactionId tid;
+	
+	private static final int POLL_INTERVAL = 100;
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before
+	public void setUp() throws Exception {
+		tid = new TransactionId();
+	}
+
+	@After
+	public void tearDown() throws Exception {
+		Database.getBufferPool().transactionComplete(tid);
+	}
+
+	@Test
+	public void nextKeyLockingTestLessThan() throws Exception {
+		
+		// This should create a B+ tree with 100 leaf pages
+		BTreeFile bigFile = BTreeUtility.createRandomBTreeFile(2, 50200,
+				null, null, 0);
+
+		// get a key from the middle of the root page
+		BTreePageId rootPtrPid = new BTreePageId(bigFile.getId(), 0, BTreePageId.ROOT_PTR);
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(tid, rootPtrPid, Permissions.READ_ONLY);
+		BTreePageId rootId = rootPtr.getRootId();
+		assertEquals(rootId.pgcateg(), BTreePageId.INTERNAL);
+		BTreeInternalPage root = (BTreeInternalPage) Database.getBufferPool().getPage(tid, rootId, Permissions.READ_ONLY);
+		int keyIndex = 50; // this should be right in the middle since there are 100 leaf pages
+		Iterator<BTreeEntry> it = root.iterator();
+		Field key = null;
+		int count = 0;
+		while(it.hasNext()) {
+			BTreeEntry e = it.next();
+			if(count == keyIndex) {
+				key = e.getKey();
+				break;
+			}
+			count++;
+		}
+		assertTrue(key != null);
+
+		// now find all tuples containing that key and delete them, as well as the next key
+		IndexPredicate ipred = new IndexPredicate(Op.EQUALS, key);
+		DbFileIterator fit = bigFile.indexIterator(tid, ipred);
+		fit.open();
+		while(fit.hasNext()) {
+			Database.getBufferPool().deleteTuple(tid, fit.next());
+		}
+		fit.close();
+
+		count = 0;
+		while(count == 0) {
+			key = new IntField(((IntField) key).getValue() + 1);
+			ipred = new IndexPredicate(Op.EQUALS, key);
+			fit = bigFile.indexIterator(tid, ipred);
+			fit.open();
+			while(fit.hasNext()) {
+				Database.getBufferPool().deleteTuple(tid, fit.next());
+				count++;
+			}
+			fit.close();
+		}
+
+		Database.getBufferPool().transactionComplete(tid);
+		tid = new TransactionId();
+
+		// search for tuples less than or equal to the key
+		ipred = new IndexPredicate(Op.LESS_THAN_OR_EQ, key);
+		fit = bigFile.indexIterator(tid, ipred);
+		fit.open();
+		int keyCountBefore = 0;
+		while(fit.hasNext()) {
+			fit.next();
+			keyCountBefore++;
+		}
+		fit.close();
+
+		// In a different thread, try to insert tuples containing the key
+		TransactionId tid1 = new TransactionId();
+		BTreeWriter bw1 = new BTreeWriter(tid1, bigFile, ((IntField) key).getValue(), 1);
+		bw1.start();
+
+		// allow thread to start
+		Thread.sleep(POLL_INTERVAL);
+
+		// search for tuples less than or equal to the key
+		ipred = new IndexPredicate(Op.LESS_THAN_OR_EQ, key);
+		fit = bigFile.indexIterator(tid, ipred);
+		fit.open();
+		int keyCountAfter = 0;
+		while(fit.hasNext()) {
+			fit.next();
+			keyCountAfter++;
+		}
+		fit.close();
+
+		// make sure our indexIterator() is working
+		assertTrue(keyCountBefore > 0);
+
+		// check that we don't have any phantoms
+		assertEquals(keyCountBefore, keyCountAfter);
+		assertFalse(bw1.succeeded());
+
+		// now let the inserts happen
+		Database.getBufferPool().transactionComplete(tid);
+
+		while(!bw1.succeeded()) {
+			Thread.sleep(POLL_INTERVAL);
+			if(bw1.succeeded()) {
+				Database.getBufferPool().transactionComplete(tid1);
+			}
+		}
+
+		// clean up
+		bw1 = null;
+	}
+
+	@Test
+	public void nextKeyLockingTestGreaterThan() throws Exception {
+		// This should create a B+ tree with 100 leaf pages
+		BTreeFile bigFile = BTreeUtility.createRandomBTreeFile(2, 50200,
+				null, null, 0);
+
+		// get a key from the middle of the root page
+		BTreePageId rootPtrPid = new BTreePageId(bigFile.getId(), 0, BTreePageId.ROOT_PTR);
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(tid, rootPtrPid, Permissions.READ_ONLY);
+		BTreePageId rootId = rootPtr.getRootId();
+		assertEquals(rootId.pgcateg(), BTreePageId.INTERNAL);
+		BTreeInternalPage root = (BTreeInternalPage) Database.getBufferPool().getPage(tid, rootId, Permissions.READ_ONLY);
+		int keyIndex = 50; // this should be right in the middle since there are 100 leaf pages
+		Iterator<BTreeEntry> it = root.iterator();
+		Field key = null;
+		int count = 0;
+		while(it.hasNext()) {
+			BTreeEntry e = it.next();
+			if(count == keyIndex) {
+				key = e.getKey();
+				break;
+			}
+			count++;
+		}
+		assertTrue(key != null);
+
+		// now find all tuples containing that key and delete them, as well as the previous key
+		IndexPredicate ipred = new IndexPredicate(Op.EQUALS, key);
+		DbFileIterator fit = bigFile.indexIterator(tid, ipred);
+		fit.open();
+		while(fit.hasNext()) {
+			Database.getBufferPool().deleteTuple(tid, fit.next());
+		}
+		fit.close();
+
+		count = 0;
+		while(count == 0) {
+			key = new IntField(((IntField) key).getValue() - 1);
+			ipred = new IndexPredicate(Op.EQUALS, key);
+			fit = bigFile.indexIterator(tid, ipred);
+			fit.open();
+			while(fit.hasNext()) {
+				Database.getBufferPool().deleteTuple(tid, fit.next());
+				count++;
+			}
+			fit.close();
+		}
+
+		Database.getBufferPool().transactionComplete(tid);
+		tid = new TransactionId();
+
+		// search for tuples greater than or equal to the key
+		ipred = new IndexPredicate(Op.GREATER_THAN_OR_EQ, key);
+		fit = bigFile.indexIterator(tid, ipred);
+		fit.open();
+		int keyCountBefore = 0;
+		while(fit.hasNext()) {
+			fit.next();
+			keyCountBefore++;
+		}
+		fit.close();
+
+		// In a different thread, try to insert tuples containing the key
+		TransactionId tid1 = new TransactionId();
+		BTreeWriter bw1 = new BTreeWriter(tid1, bigFile, ((IntField) key).getValue(), 1);
+		bw1.start();
+
+		// allow thread to start
+		Thread.sleep(POLL_INTERVAL);
+
+		// search for tuples greater than or equal to the key
+		ipred = new IndexPredicate(Op.GREATER_THAN_OR_EQ, key);
+		fit = bigFile.indexIterator(tid, ipred);
+		fit.open();
+		int keyCountAfter = 0;
+		while(fit.hasNext()) {
+			fit.next();
+			keyCountAfter++;
+		}
+		fit.close();
+
+		// make sure our indexIterator() is working
+		assertTrue(keyCountBefore > 0);
+
+		// check that we don't have any phantoms
+		assertEquals(keyCountBefore, keyCountAfter);
+		assertFalse(bw1.succeeded());
+
+		// now let the inserts happen
+		Database.getBufferPool().transactionComplete(tid);
+
+		while(!bw1.succeeded()) {
+			Thread.sleep(POLL_INTERVAL);
+			if(bw1.succeeded()) {
+				Database.getBufferPool().transactionComplete(tid1);
+			}
+		}
+
+		// clean up
+		bw1 = null;
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeNextKeyLockingTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/BTreePageIdTest.java lab3/test/simpledb/BTreePageIdTest.java
--- lab2/test/simpledb/BTreePageIdTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreePageIdTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,108 @@
+package simpledb;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import junit.framework.JUnit4TestAdapter;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import simpledb.systemtest.SimpleDbTestBase;
+
+public class BTreePageIdTest extends SimpleDbTestBase {
+
+	private BTreePageId rootPtrId;
+	private BTreePageId internalId;
+	private BTreePageId leafId;
+	private BTreePageId headerId;
+
+	@Before public void createPid() {
+		rootPtrId = new BTreePageId(1, 0, BTreePageId.ROOT_PTR);
+		internalId = new BTreePageId(1, 1, BTreePageId.INTERNAL);
+		leafId = new BTreePageId(1, 2, BTreePageId.LEAF);
+		headerId = new BTreePageId(1, 3, BTreePageId.HEADER);
+	}
+
+	/**
+	 * Unit test for BTreePageId.getTableId()
+	 */
+	@Test public void getTableId() {
+		assertEquals(1, rootPtrId.getTableId());
+		assertEquals(1, internalId.getTableId());
+		assertEquals(1, leafId.getTableId());
+		assertEquals(1, headerId.getTableId());
+	}
+
+	/**
+	 * Unit test for BTreePageId.pageno()
+	 */
+	@Test public void pageno() {
+		assertEquals(0, rootPtrId.pageNumber());
+		assertEquals(1, internalId.pageNumber());
+		assertEquals(2, leafId.pageNumber());
+		assertEquals(3, headerId.pageNumber());
+	}
+
+	/**
+	 * Unit test for BTreePageId.hashCode()
+	 */
+	@Test public void testHashCode() {
+		int code1, code2, code3, code4;
+
+		// NOTE(ghuo): the hashCode could be anything. test determinism,
+		// at least.
+		code1 = rootPtrId.hashCode();
+		assertEquals(code1, rootPtrId.hashCode());
+		assertEquals(code1, rootPtrId.hashCode());
+
+		code2 = internalId.hashCode();
+		assertEquals(code2, internalId.hashCode());
+		assertEquals(code2, internalId.hashCode());
+
+		code3 = leafId.hashCode();
+		assertEquals(code3, leafId.hashCode());
+		assertEquals(code3, leafId.hashCode());
+
+		code4 = headerId.hashCode();
+		assertEquals(code4, headerId.hashCode());
+		assertEquals(code4, headerId.hashCode());
+	}
+
+	/**
+	 * Unit test for BTreePageId.equals()
+	 */
+	@Test public void equals() {
+		BTreePageId pid1 = new BTreePageId(1, 1, BTreePageId.LEAF);
+		BTreePageId pid1Copy = new BTreePageId(1, 1, BTreePageId.LEAF);
+		BTreePageId pid2 = new BTreePageId(2, 2, BTreePageId.LEAF);
+		BTreePageId pid3 = new BTreePageId(1, 1, BTreePageId.INTERNAL);
+
+		// .equals() with null should return false
+		assertFalse(pid1.equals(null));
+
+		// .equals() with the wrong type should return false
+		assertFalse(pid1.equals(new Object()));
+
+		assertTrue(pid1.equals(pid1));
+		assertTrue(pid1.equals(pid1Copy));
+		assertTrue(pid1Copy.equals(pid1));
+		assertTrue(pid2.equals(pid2));
+		assertTrue(pid3.equals(pid3));
+
+		assertFalse(pid1.equals(pid2));
+		assertFalse(pid1Copy.equals(pid2));
+		assertFalse(pid2.equals(pid1));
+		assertFalse(pid2.equals(pid1Copy));
+		assertFalse(pid1.equals(pid3));
+		assertFalse(pid3.equals(pid1));
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreePageIdTest.class);
+	}
+}
+
diff -Naur lab2/test/simpledb/BTreeRootPtrPageTest.java lab3/test/simpledb/BTreeRootPtrPageTest.java
--- lab2/test/simpledb/BTreeRootPtrPageTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/BTreeRootPtrPageTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,140 @@
+package simpledb;
+
+import simpledb.TestUtil.SkeletonFile;
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.systemtest.SystemTestUtil;
+
+//import java.io.File;
+import java.io.IOException;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeRootPtrPageTest extends SimpleDbTestBase {
+	private BTreePageId pid;
+
+	public static final byte[] EXAMPLE_DATA;
+	static {
+		// Identify the root page and page category
+		int root = 1;
+		int rootCategory = BTreePageId.LEAF;
+		int header = 2;
+
+		// Convert it to a BTreeRootPtrPage
+		try {
+			EXAMPLE_DATA = BTreeFileEncoder.convertToRootPtrPage(root, rootCategory, header);
+		} catch (IOException e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before public void addTable() throws Exception {
+		this.pid = new BTreePageId(-1, 0, BTreePageId.ROOT_PTR);
+		Database.getCatalog().addTable(new SkeletonFile(-1, Utility.getTupleDesc(2)), SystemTestUtil.getUUID());
+	}
+
+	/**
+	 * Unit test for BTreeRootPtrPage.getId()
+	 */
+	@Test public void getId() throws Exception {
+		BTreeRootPtrPage page = new BTreeRootPtrPage(pid, EXAMPLE_DATA);
+		assertEquals(pid, page.getId());
+	}
+
+	/**
+	 * Unit test for BTreeRootPtrPage.getRootId()
+	 */
+	@Test public void getRootId() throws Exception {
+		BTreeRootPtrPage page = new BTreeRootPtrPage(pid, EXAMPLE_DATA);
+		assertEquals(new BTreePageId(pid.getTableId(), 1, BTreePageId.LEAF), page.getRootId());
+	}
+
+	/**
+	 * Unit test for BTreeRootPtrPage.setRootId()
+	 */
+	@Test public void setRootId() throws Exception {
+		BTreeRootPtrPage page = new BTreeRootPtrPage(pid, EXAMPLE_DATA);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 1, BTreePageId.INTERNAL);
+		page.setRootId(id);
+		assertEquals(id, page.getRootId());
+
+		id = new BTreePageId(pid.getTableId(), 1, BTreePageId.ROOT_PTR);
+		try {
+			page.setRootId(id);
+			throw new Exception("should not be able to set rootId to RootPtr node; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+
+		id = new BTreePageId(pid.getTableId() + 1, 1, BTreePageId.INTERNAL);
+		try {
+			page.setRootId(id);
+			throw new Exception("should not be able to set rootId to a page from a different table; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeRootPtrPage.getHeaderId()
+	 */
+	@Test public void getHeaderId() throws Exception {
+		BTreeRootPtrPage page = new BTreeRootPtrPage(pid, EXAMPLE_DATA);
+		assertEquals(new BTreePageId(pid.getTableId(), 2, BTreePageId.HEADER), page.getHeaderId());
+	}
+
+	/**
+	 * Unit test for BTreeRootPtrPage.setHeaderId()
+	 */
+	@Test public void setHeaderId() throws Exception {
+		BTreeRootPtrPage page = new BTreeRootPtrPage(pid, EXAMPLE_DATA);
+		BTreePageId id = new BTreePageId(pid.getTableId(), 3, BTreePageId.HEADER);
+		page.setHeaderId(id);
+		assertEquals(id, page.getHeaderId());
+
+		id = new BTreePageId(pid.getTableId(), 2, BTreePageId.ROOT_PTR);
+		try {
+			page.setHeaderId(id);
+			throw new Exception("should not be able to set headerId to RootPtr node; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+
+		id = new BTreePageId(pid.getTableId() + 1, 1, BTreePageId.HEADER);
+		try {
+			page.setHeaderId(id);
+			throw new Exception("should not be able to set rootId to a page from a different table; expected DbException");
+		} catch (DbException e) {
+			// explicitly ignored
+		}
+	}
+
+	/**
+	 * Unit test for BTreeRootPtrPage.isDirty()
+	 */
+	@Test public void testDirty() throws Exception {
+		TransactionId tid = new TransactionId();
+		BTreeRootPtrPage page = new BTreeRootPtrPage(pid, EXAMPLE_DATA);
+		page.markDirty(true, tid);
+		TransactionId dirtier = page.isDirty();
+		assertEquals(true, dirtier != null);
+		assertEquals(true, dirtier == tid);
+
+		page.markDirty(false, tid);
+		dirtier = page.isDirty();
+		assertEquals(false, dirtier != null);
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeRootPtrPageTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/systemtest/BTreeFileDeleteTest.java lab3/test/simpledb/systemtest/BTreeFileDeleteTest.java
--- lab2/test/simpledb/systemtest/BTreeFileDeleteTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/systemtest/BTreeFileDeleteTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,343 @@
+package simpledb.systemtest;
+
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.Predicate.Op;
+import simpledb.*;
+
+import java.util.*;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.*;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeFileDeleteTest extends SimpleDbTestBase {
+	private TransactionId tid;
+
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before
+	public void setUp() throws Exception {
+		tid = new TransactionId();
+	}
+
+	@After
+	public void tearDown() throws Exception {
+		Database.getBufferPool().transactionComplete(tid);
+
+		// set the page size back to the default
+		BufferPool.resetPageSize();
+		Database.reset();
+
+	}
+
+	@Test
+	public void testRedistributeLeafPages() throws Exception {
+		// This should create a B+ tree with two partially full leaf pages
+		BTreeFile twoLeafPageFile = BTreeUtility.createRandomBTreeFile(2, 600,
+				null, null, 0);
+
+		// Delete some tuples from the first page until it gets to minimum occupancy
+		DbFileIterator it = twoLeafPageFile.iterator(tid);
+		it.open();
+		int count = 0;
+		while(it.hasNext() && count < 49) {
+			Tuple t = it.next();
+			BTreePageId pid = (BTreePageId) t.getRecordId().getPageId();
+			BTreeLeafPage p = (BTreeLeafPage) Database.getBufferPool().getPage(
+					tid, pid, Permissions.READ_ONLY);
+			assertEquals(202 + count, p.getNumEmptySlots());
+			twoLeafPageFile.deleteTuple(tid, t);
+			count++;
+		}
+
+		// deleting a tuple now should bring the page below minimum occupancy and cause 
+		// the tuples to be redistributed
+		Tuple t = it.next();
+		it.close();
+		BTreePageId pid = (BTreePageId) t.getRecordId().getPageId();
+		BTreeLeafPage p = (BTreeLeafPage) Database.getBufferPool().getPage(
+				tid, pid, Permissions.READ_ONLY);
+		assertEquals(251, p.getNumEmptySlots());
+		twoLeafPageFile.deleteTuple(tid, t);
+		assertTrue(p.getNumEmptySlots() <= 251);
+
+		BTreePageId rightSiblingId = p.getRightSiblingId();
+		BTreeLeafPage rightSibling = (BTreeLeafPage) Database.getBufferPool().getPage(
+				tid, rightSiblingId, Permissions.READ_ONLY);
+		assertTrue(rightSibling.getNumEmptySlots() > 202);
+	} 
+
+	@Test
+	public void testMergeLeafPages() throws Exception {
+		// This should create a B+ tree with one full page and two half-full leaf pages
+		BTreeFile threeLeafPageFile = BTreeUtility.createRandomBTreeFile(2, 1005,
+				null, null, 0);
+
+		// there should be one internal node and 3 leaf nodes
+		assertEquals(4, threeLeafPageFile.numPages());
+
+		// delete the last two tuples
+		DbFileIterator it = threeLeafPageFile.iterator(tid);
+		it.open();
+		Tuple secondToLast = null;
+		Tuple last = null;
+		while(it.hasNext()) {
+			secondToLast = last;
+			last = it.next();
+		}
+		it.close();
+		threeLeafPageFile.deleteTuple(tid, secondToLast);
+		threeLeafPageFile.deleteTuple(tid, last);
+
+		// confirm that the last two pages have merged successfully
+		BTreePageId rootPtrId = BTreeRootPtrPage.getId(threeLeafPageFile.getId());
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(
+				tid, rootPtrId, Permissions.READ_ONLY);
+		BTreeInternalPage root = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, rootPtr.getRootId(), Permissions.READ_ONLY);
+		assertEquals(502, root.getNumEmptySlots());
+		BTreeEntry e = root.iterator().next();
+		BTreeLeafPage leftChild = (BTreeLeafPage) Database.getBufferPool().getPage(
+				tid, e.getLeftChild(), Permissions.READ_ONLY);
+		BTreeLeafPage rightChild = (BTreeLeafPage) Database.getBufferPool().getPage(
+				tid, e.getRightChild(), Permissions.READ_ONLY);
+		assertEquals(0, leftChild.getNumEmptySlots());
+		assertEquals(1, rightChild.getNumEmptySlots());
+		assertTrue(e.getKey().equals(rightChild.iterator().next().getField(0)));
+
+	}
+
+	@Test
+	public void testDeleteRootPage() throws Exception {
+		// This should create a B+ tree with two half-full leaf pages
+		BTreeFile twoLeafPageFile = BTreeUtility.createRandomBTreeFile(2, 503,
+				null, null, 0);
+
+		// there should be one internal node and 2 leaf nodes
+		assertEquals(3, twoLeafPageFile.numPages());
+
+		// delete the first two tuples
+		DbFileIterator it = twoLeafPageFile.iterator(tid);
+		it.open();
+		Tuple first = it.next();
+		Tuple second = it.next();
+		it.close();
+		twoLeafPageFile.deleteTuple(tid, first);
+		twoLeafPageFile.deleteTuple(tid, second);
+
+		// confirm that the last two pages have merged successfully and replaced the root
+		BTreePageId rootPtrId = BTreeRootPtrPage.getId(twoLeafPageFile.getId());
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(
+				tid, rootPtrId, Permissions.READ_ONLY);
+		assertTrue(rootPtr.getRootId().pgcateg() == BTreePageId.LEAF);
+		BTreeLeafPage root = (BTreeLeafPage) Database.getBufferPool().getPage(
+				tid, rootPtr.getRootId(), Permissions.READ_ONLY);
+		assertEquals(1, root.getNumEmptySlots());
+		assertTrue(root.getParentId().equals(rootPtrId));
+	}
+
+	@Test
+	public void testReuseDeletedPages() throws Exception {
+		// this should create a B+ tree with 3 leaf nodes
+		BTreeFile threeLeafPageFile = BTreeUtility.createRandomBTreeFile(2, 1005,
+				null, null, 0);
+
+		// 3 leaf pages, 1 internal page
+		assertEquals(4, threeLeafPageFile.numPages());
+
+		// delete enough tuples to ensure one page gets deleted
+		DbFileIterator it = threeLeafPageFile.iterator(tid);
+		it.open();
+		for(int i = 0; i < 502; ++i) {
+			Database.getBufferPool().deleteTuple(tid, it.next());
+			it.rewind();
+		}
+		it.close();
+
+		// now there should be 2 leaf pages, 1 internal page, 1 unused leaf page, 1 header page
+		assertEquals(5, threeLeafPageFile.numPages());
+
+		// insert enough tuples to ensure one of the leaf pages splits
+		for(int i = 0; i < 502; ++i) {
+			Database.getBufferPool().insertTuple(tid, threeLeafPageFile.getId(), 
+					BTreeUtility.getBTreeTuple(i, 2));
+		}
+
+		// now there should be 3 leaf pages, 1 internal page, and 1 header page
+		assertEquals(5, threeLeafPageFile.numPages());
+	}
+
+	@Test
+	public void testRedistributeInternalPages() throws Exception {
+		// This should create a B+ tree with two nodes in the second tier
+		// and 602 nodes in the third tier
+		BTreeFile bf = BTreeUtility.createRandomBTreeFile(2, 302204,
+				null, null, 0);
+
+		Database.resetBufferPool(500); // we need more pages for this test
+
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(
+				tid, BTreeRootPtrPage.getId(bf.getId()), Permissions.READ_ONLY);
+		BTreeInternalPage root = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, rootPtr.getRootId(), Permissions.READ_ONLY);
+		assertEquals(502, root.getNumEmptySlots());
+
+		BTreeEntry rootEntry = root.iterator().next();
+		BTreeInternalPage leftChild = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, rootEntry.getLeftChild(), Permissions.READ_ONLY);
+		BTreeInternalPage rightChild = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, rootEntry.getRightChild(), Permissions.READ_ONLY);
+
+		// delete from the right child to test redistribution from the left
+		Iterator<BTreeEntry> it = rightChild.iterator();
+		int count = 0;
+		// bring the right internal page to minimum occupancy
+		while(it.hasNext() && count < 49 * 502 + 1) {
+			BTreeLeafPage leaf = (BTreeLeafPage) Database.getBufferPool().getPage(tid, 
+					it.next().getLeftChild(), Permissions.READ_ONLY);
+			Tuple t = leaf.iterator().next();
+			Database.getBufferPool().deleteTuple(tid, t);
+			it = rightChild.iterator();
+			count++;
+		}
+
+		// deleting a page of tuples should bring the internal page below minimum 
+		// occupancy and cause the entries to be redistributed
+		assertEquals(252, rightChild.getNumEmptySlots());
+		count = 0;
+		while(it.hasNext() && count < 502) {
+			BTreeLeafPage leaf = (BTreeLeafPage) Database.getBufferPool().getPage(tid, 
+					it.next().getLeftChild(), Permissions.READ_ONLY);
+			Tuple t = leaf.iterator().next();
+			Database.getBufferPool().deleteTuple(tid, t);
+			it = rightChild.iterator();
+			count++;
+		}
+		assertTrue(leftChild.getNumEmptySlots() > 203);
+		assertTrue(rightChild.getNumEmptySlots() <= 252);
+
+		// sanity check that the entries make sense
+		BTreeEntry lastLeftEntry = null;
+		it = leftChild.iterator();
+		while(it.hasNext()) {
+			lastLeftEntry = it.next();
+		}
+		rootEntry = root.iterator().next();
+		BTreeEntry firstRightEntry = rightChild.iterator().next();
+		assertTrue(lastLeftEntry.getKey().compare(Op.LESS_THAN_OR_EQ, rootEntry.getKey()));
+		assertTrue(rootEntry.getKey().compare(Op.LESS_THAN_OR_EQ, firstRightEntry.getKey()));
+	}
+
+	@Test
+	public void testDeleteInternalPages() throws Exception {
+    	// For this test we will decrease the size of the Buffer Pool pages
+    	BufferPool.setPageSize(1024);
+		
+		// This should create a B+ tree with three nodes in the second tier
+		// and 252 nodes in the third tier
+    	// (124 entries per internal/leaf page, 125 children per internal page ->
+    	// 251*124 + 1 = 31125)
+		BTreeFile bigFile = BTreeUtility.createRandomBTreeFile(2, 31125,
+				null, null, 0);
+
+		Database.resetBufferPool(500); // we need more pages for this test
+
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(
+				tid, BTreeRootPtrPage.getId(bigFile.getId()), Permissions.READ_ONLY);
+		BTreeInternalPage root = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, rootPtr.getRootId(), Permissions.READ_ONLY);
+		assertEquals(122, root.getNumEmptySlots());
+
+		BTreeEntry e = root.iterator().next();
+		BTreeInternalPage leftChild = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, e.getLeftChild(), Permissions.READ_ONLY);
+		BTreeInternalPage rightChild = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, e.getRightChild(), Permissions.READ_ONLY);
+
+		// Delete tuples causing leaf pages to merge until the first internal page 
+		// gets to minimum occupancy
+		DbFileIterator it = bigFile.iterator(tid);
+		it.open();
+		int count = 0;
+		Database.getBufferPool().deleteTuple(tid, it.next());
+		it.rewind();
+		while(count < 62) {
+			assertEquals(count, leftChild.getNumEmptySlots());
+			for(int i = 0; i < 124; ++i) {
+				Database.getBufferPool().deleteTuple(tid, it.next());
+				it.rewind();
+			}
+			count++;
+		}
+
+		// deleting a page of tuples should bring the internal page below minimum 
+		// occupancy and cause the entries to be redistributed
+		assertEquals(62, leftChild.getNumEmptySlots());
+		for(int i = 0; i < 124; ++i) {
+			Database.getBufferPool().deleteTuple(tid, it.next());
+			it.rewind();
+		}
+		assertEquals(62, leftChild.getNumEmptySlots());
+		assertEquals(62, rightChild.getNumEmptySlots());
+
+		// deleting another page of tuples should bring the page below minimum occupancy 
+		// again but this time cause it to merge with its right sibling 
+		for(int i = 0; i < 124; ++i) {
+			Database.getBufferPool().deleteTuple(tid, it.next());
+			it.rewind();
+		}
+
+		// confirm that the pages have merged
+		assertEquals(123, root.getNumEmptySlots());
+		e = root.iterator().next();
+		leftChild = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, e.getLeftChild(), Permissions.READ_ONLY);
+		rightChild = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, e.getRightChild(), Permissions.READ_ONLY);
+		assertEquals(0, leftChild.getNumEmptySlots());
+		assertTrue(e.getKey().compare(Op.LESS_THAN_OR_EQ, rightChild.iterator().next().getKey()));
+
+		// Delete tuples causing leaf pages to merge until the first internal page 
+		// gets below minimum occupancy and causes the entries to be redistributed
+		count = 0;
+		while(count < 62) {
+			assertEquals(count, leftChild.getNumEmptySlots());
+			for(int i = 0; i < 124; ++i) {
+				Database.getBufferPool().deleteTuple(tid, it.next());
+				it.rewind();
+			}
+			count++;
+		}
+
+		// deleting another page of tuples should bring the page below minimum occupancy 
+		// and cause it to merge with the right sibling to replace the root
+		for(int i = 0; i < 124; ++i) {
+			Database.getBufferPool().deleteTuple(tid, it.next());
+			it.rewind();
+		}
+
+		// confirm that the last two internal pages have merged successfully and 
+		// replaced the root
+		BTreePageId rootPtrId = BTreeRootPtrPage.getId(bigFile.getId());
+		rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(
+				tid, rootPtrId, Permissions.READ_ONLY);
+		assertTrue(rootPtr.getRootId().pgcateg() == BTreePageId.INTERNAL);
+		root = (BTreeInternalPage) Database.getBufferPool().getPage(
+				tid, rootPtr.getRootId(), Permissions.READ_ONLY);
+		assertEquals(0, root.getNumEmptySlots());
+		assertTrue(root.getParentId().equals(rootPtrId));
+
+		it.close();
+	}    
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeFileDeleteTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/systemtest/BTreeFileInsertTest.java lab3/test/simpledb/systemtest/BTreeFileInsertTest.java
--- lab2/test/simpledb/systemtest/BTreeFileInsertTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/systemtest/BTreeFileInsertTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,280 @@
+package simpledb.systemtest;
+
+import simpledb.systemtest.SimpleDbTestBase;
+import simpledb.Predicate.Op;
+import simpledb.*;
+
+import java.io.File;
+import java.util.*;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import static org.junit.Assert.*;
+import junit.framework.JUnit4TestAdapter;
+
+public class BTreeFileInsertTest extends SimpleDbTestBase {
+	private TransactionId tid;
+	
+	/**
+	 * Set up initial resources for each unit test.
+	 */
+	@Before
+	public void setUp() throws Exception {
+		tid = new TransactionId();
+	}
+
+	@After
+	public void tearDown() throws Exception {
+		Database.getBufferPool().transactionComplete(tid);
+		
+		// set the page size back to the default
+		BufferPool.resetPageSize();
+		Database.reset();
+	}
+
+	@Test public void addTuple() throws Exception {
+		// create an empty B+ tree file keyed on the second field of a 2-field tuple
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 1);
+
+		Tuple tup = null;
+		// we should be able to add 502 tuples on one page
+		for (int i = 0; i < 502; ++i) {
+			tup = BTreeUtility.getBTreeTuple(i, 2);
+			empty.insertTuple(tid, tup);
+			assertEquals(1, empty.numPages());
+		}
+
+		// the next 251 tuples should live on page 2 since they are greater than
+		// all existing tuples in the file
+		for (int i = 502; i < 753; ++i) {
+			tup = BTreeUtility.getBTreeTuple(i, 2);
+			empty.insertTuple(tid, tup);
+			assertEquals(3, empty.numPages());
+		}
+
+		// one more insert greater than 502 should cause page 2 to split
+		tup = BTreeUtility.getBTreeTuple(753, 2);
+		empty.insertTuple(tid, tup);
+		assertEquals(4, empty.numPages());
+
+		// now make sure the records are sorted on the key field
+		DbFileIterator it = empty.iterator(tid);
+		it.open();
+		int prev = -1;
+		while(it.hasNext()) {
+			Tuple t = it.next();
+			int value = ((IntField) t.getField(0)).getValue();
+			assertTrue(value >= prev);
+			prev = value;
+		} 
+	}
+
+	@Test public void addDuplicateTuples() throws Exception {
+		// create an empty B+ tree file keyed on the second field of a 2-field tuple
+		File emptyFile = File.createTempFile("empty", ".dat");
+		emptyFile.deleteOnExit();
+		Database.reset();
+		BTreeFile empty = BTreeUtility.createEmptyBTreeFile(emptyFile.getAbsolutePath(), 2, 1);
+
+		Tuple tup = null;
+		// add a bunch of identical tuples
+		for (int i = 0; i < 5; ++i) {
+			for(int j = 0; j < 600; ++j) {
+				tup = BTreeUtility.getBTreeTuple(i, 2);
+				empty.insertTuple(tid, tup);
+			}
+		}
+
+		// now search for some ranges and make sure we find all the tuples
+		IndexPredicate ipred = new IndexPredicate(Op.EQUALS, new IntField(3));
+		DbFileIterator it = empty.indexIterator(tid, ipred);
+		it.open();
+		int count = 0;
+		while(it.hasNext()) {
+			it.next();
+			count++;
+		} 
+		assertEquals(600, count);
+
+		ipred = new IndexPredicate(Op.GREATER_THAN_OR_EQ, new IntField(2));
+		it = empty.indexIterator(tid, ipred);
+		it.open();
+		count = 0;
+		while(it.hasNext()) {
+			it.next();
+			count++;
+		} 
+		assertEquals(1800, count);
+
+		ipred = new IndexPredicate(Op.LESS_THAN, new IntField(2));
+		it = empty.indexIterator(tid, ipred);
+		it.open();
+		count = 0;
+		while(it.hasNext()) {
+			it.next();
+			count++;
+		} 
+		assertEquals(1200, count);
+	}
+
+	@Test
+	public void testSplitLeafPage() throws Exception {
+		// This should create a B+ tree with one full page
+		BTreeFile onePageFile = BTreeUtility.createRandomBTreeFile(2, 502,
+				null, null, 0);
+
+		// there should be 1 leaf page
+		assertEquals(1, onePageFile.numPages());
+
+		// now insert a tuple
+		Database.getBufferPool().insertTuple(tid, onePageFile.getId(), BTreeUtility.getBTreeTuple(5000, 2));
+
+		// there should now be 2 leaf pages + 1 internal node
+		assertEquals(3, onePageFile.numPages());
+
+		// the root node should be an internal node and have 2 children (1 entry)
+		BTreePageId rootPtrPid = new BTreePageId(onePageFile.getId(), 0, BTreePageId.ROOT_PTR);
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(tid, rootPtrPid, Permissions.READ_ONLY);
+		BTreePageId rootId = rootPtr.getRootId();
+		assertEquals(rootId.pgcateg(), BTreePageId.INTERNAL);
+		BTreeInternalPage root = (BTreeInternalPage) Database.getBufferPool().getPage(tid, rootId, Permissions.READ_ONLY);
+		assertEquals(502, root.getNumEmptySlots());
+
+		// each child should have half of the records
+		Iterator<BTreeEntry> it = root.iterator();
+		assertTrue(it.hasNext());
+		BTreeEntry e = it.next();
+		BTreeLeafPage leftChild = (BTreeLeafPage) Database.getBufferPool().getPage(tid, e.getLeftChild(), Permissions.READ_ONLY);
+		BTreeLeafPage rightChild = (BTreeLeafPage) Database.getBufferPool().getPage(tid, e.getRightChild(), Permissions.READ_ONLY);
+		assertTrue(leftChild.getNumEmptySlots() <= 251);
+		assertTrue(rightChild.getNumEmptySlots() <= 251);
+
+	}
+
+	@Test
+	public void testSplitRootPage() throws Exception {
+		// This should create a packed B+ tree with no empty slots
+		// There are 503 keys per internal page (504 children) and 502 tuples per leaf page
+		// 504 * 502 = 253008
+		BTreeFile bigFile = BTreeUtility.createRandomBTreeFile(2, 253008,
+				null, null, 0);
+
+		// we will need more room in the buffer pool for this test
+		Database.resetBufferPool(500);		
+
+		// there should be 504 leaf pages + 1 internal node
+		assertEquals(505, bigFile.numPages());
+
+		// now insert a tuple
+		Database.getBufferPool().insertTuple(tid, bigFile.getId(), BTreeUtility.getBTreeTuple(10, 2));
+
+		// there should now be 505 leaf pages + 3 internal nodes
+		assertEquals(508, bigFile.numPages());
+
+		// the root node should be an internal node and have 2 children (1 entry)
+		BTreePageId rootPtrPid = new BTreePageId(bigFile.getId(), 0, BTreePageId.ROOT_PTR);
+		BTreeRootPtrPage rootPtr = (BTreeRootPtrPage) Database.getBufferPool().getPage(tid, rootPtrPid, Permissions.READ_ONLY);
+		BTreePageId rootId = rootPtr.getRootId();
+		assertEquals(rootId.pgcateg(), BTreePageId.INTERNAL);
+		BTreeInternalPage root = (BTreeInternalPage) Database.getBufferPool().getPage(tid, rootId, Permissions.READ_ONLY);
+		assertEquals(502, root.getNumEmptySlots());
+
+		// each child should have half of the entries
+		Iterator<BTreeEntry> it = root.iterator();
+		assertTrue(it.hasNext());
+		BTreeEntry e = it.next();
+		BTreeInternalPage leftChild = (BTreeInternalPage) Database.getBufferPool().getPage(tid, e.getLeftChild(), Permissions.READ_ONLY);
+		BTreeInternalPage rightChild = (BTreeInternalPage) Database.getBufferPool().getPage(tid, e.getRightChild(), Permissions.READ_ONLY);
+		assertTrue(leftChild.getNumEmptySlots() <= 252);
+		assertTrue(rightChild.getNumEmptySlots() <= 252);
+
+		// now insert some random tuples and make sure we can find them
+		Random rand = new Random();
+		for(int i = 0; i < 100; i++) {
+			int item = rand.nextInt(BTreeUtility.MAX_RAND_VALUE);
+			Tuple t = BTreeUtility.getBTreeTuple(item, 2);
+			Database.getBufferPool().insertTuple(tid, bigFile.getId(), t);
+
+			IndexPredicate ipred = new IndexPredicate(Op.EQUALS, t.getField(0));
+			DbFileIterator fit = bigFile.indexIterator(tid, ipred);
+			fit.open();
+			boolean found = false;
+			while(fit.hasNext()) {
+				if(fit.next().equals(t)) {
+					found = true;
+					break;
+				}
+			}
+			fit.close();
+			assertTrue(found);
+		}
+	}
+
+	@Test
+	public void testSplitInternalPage() throws Exception {
+		// For this test we will decrease the size of the Buffer Pool pages
+    	BufferPool.setPageSize(1024);
+
+		// This should create a B+ tree with a packed second tier of internal pages
+		// and packed third tier of leaf pages
+    	// (124 entries per internal/leaf page, 125 children per internal page ->
+    	// 125*2*124 = 31000)
+		BTreeFile bigFile = BTreeUtility.createRandomBTreeFile(2, 31000,
+				null, null, 0);
+		
+		// we will need more room in the buffer pool for this test
+		Database.resetBufferPool(1000);
+
+		// there should be 250 leaf pages + 3 internal nodes
+		assertEquals(253, bigFile.numPages());
+
+		// now insert some random tuples and make sure we can find them
+		Random rand = new Random();
+		for(int i = 0; i < 100; i++) {
+			int item = rand.nextInt(BTreeUtility.MAX_RAND_VALUE);
+			Tuple t = BTreeUtility.getBTreeTuple(item, 2);
+			Database.getBufferPool().insertTuple(tid, bigFile.getId(), t);
+
+			IndexPredicate ipred = new IndexPredicate(Op.EQUALS, t.getField(0));
+			DbFileIterator fit = bigFile.indexIterator(tid, ipred);
+			fit.open();
+			boolean found = false;
+			while(fit.hasNext()) {
+				if(fit.next().equals(t)) {
+					found = true;
+					break;
+				}
+			}
+			fit.close();
+			assertTrue(found);
+		}
+
+		// now make sure we have 31100 records and they are all in sorted order
+		DbFileIterator fit = bigFile.iterator(tid);
+		int count = 0;
+		Tuple prev = null;
+		fit.open();
+		while(fit.hasNext()) {
+			Tuple tup = fit.next();
+			if(prev != null)
+				assertTrue(tup.getField(0).compare(Op.GREATER_THAN_OR_EQ, prev.getField(0)));
+			prev = tup;
+			count++;
+		}
+		fit.close();
+		assertEquals(31100, count);	
+		
+	}
+
+	/**
+	 * JUnit suite target
+	 */
+	public static junit.framework.Test suite() {
+		return new JUnit4TestAdapter(BTreeFileInsertTest.class);
+	}
+}
diff -Naur lab2/test/simpledb/systemtest/BTreeScanTest.java lab3/test/simpledb/systemtest/BTreeScanTest.java
--- lab2/test/simpledb/systemtest/BTreeScanTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/systemtest/BTreeScanTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,289 @@
+package simpledb.systemtest;
+
+import simpledb.systemtest.SystemTestUtil;
+
+import static org.junit.Assert.*;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.NoSuchElementException;
+import java.util.Random;
+import java.util.Iterator;
+
+import org.junit.Test;
+import org.junit.Before;
+
+import simpledb.*;
+import simpledb.Predicate.Op;
+
+/**
+ * Dumps the contents of a table.
+ * args[1] is the number of columns.  E.g., if it's 5, then BTreeScanTest will end
+ * up dumping the contents of f4.0.txt.
+ */
+public class BTreeScanTest extends SimpleDbTestBase {
+    private final static Random r = new Random();
+    
+    /** Tests the scan operator for a table with the specified dimensions. */
+    private void validateScan(int[] columnSizes, int[] rowSizes)
+            throws IOException, DbException, TransactionAbortedException {
+    	TransactionId tid = new TransactionId();
+    	for (int columns : columnSizes) {
+    		int keyField = r.nextInt(columns);
+            for (int rows : rowSizes) {
+                ArrayList<ArrayList<Integer>> tuples = new ArrayList<ArrayList<Integer>>();
+                BTreeFile f = BTreeUtility.createRandomBTreeFile(columns, rows, null, tuples, keyField);
+                BTreeScan scan = new BTreeScan(tid, f.getId(), "table", null);
+                SystemTestUtil.matchTuples(scan, tuples);
+                Database.resetBufferPool(BufferPool.DEFAULT_PAGES);
+            }
+        }
+    	Database.getBufferPool().transactionComplete(tid);
+    }
+    
+    // comparator to sort Tuples by key field
+    private static class TupleComparator implements Comparator<ArrayList<Integer>> {
+        private int keyField;
+        
+        public TupleComparator(int keyField) {
+        	this.keyField = keyField;
+        }
+        
+    	public int compare(ArrayList<Integer> t1, ArrayList<Integer> t2) {
+            int cmp = 0;
+            if(t1.get(keyField) < t2.get(keyField)) {
+            	cmp = -1;
+            }
+            else if(t1.get(keyField) > t2.get(keyField)) {
+            	cmp = 1;
+            }
+            return cmp;
+        }
+    }
+    
+    /** Counts the number of readPage operations. */
+    class InstrumentedBTreeFile extends BTreeFile {
+        public InstrumentedBTreeFile(File f, int keyField, TupleDesc td) {
+            super(f, keyField, td);
+        }
+
+        @Override
+        public Page readPage(PageId pid) throws NoSuchElementException {
+            readCount += 1;
+            return super.readPage(pid);
+        }
+
+        public int readCount = 0;
+    }
+    
+    /** Scan 1-4 columns. */
+    @Test public void testSmall() throws IOException, DbException, TransactionAbortedException {
+        int[] columnSizes = new int[]{1, 2, 3, 4};
+        int[] rowSizes =
+                new int[]{0, 1, 2, 511, 512, 513, 1023, 1024, 1025, 4096 + r.nextInt(4096)};
+        validateScan(columnSizes, rowSizes);
+    }
+
+    /** Test that rewinding a BTreeScan iterator works. */
+    @Test public void testRewind() throws IOException, DbException, TransactionAbortedException {
+        ArrayList<ArrayList<Integer>> tuples = new ArrayList<ArrayList<Integer>>();
+        int keyField = r.nextInt(2);
+        BTreeFile f = BTreeUtility.createRandomBTreeFile(2, 1000, null, tuples, keyField);
+        Collections.sort(tuples, new TupleComparator(keyField));
+        
+        TransactionId tid = new TransactionId();
+        BTreeScan scan = new BTreeScan(tid, f.getId(), "table", null);
+        scan.open();
+        for (int i = 0; i < 100; ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuples.get(i), SystemTestUtil.tupleToList(t));
+        }
+
+        scan.rewind();
+        for (int i = 0; i < 100; ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuples.get(i), SystemTestUtil.tupleToList(t));
+        }
+        scan.close();
+        Database.getBufferPool().transactionComplete(tid);
+    }
+    
+    /** Test that rewinding a BTreeScan iterator works with predicates. */
+    @Test public void testRewindPredicates() throws IOException, DbException, TransactionAbortedException {
+    	// Create the table
+        ArrayList<ArrayList<Integer>> tuples = new ArrayList<ArrayList<Integer>>();
+        int keyField = r.nextInt(3);
+        BTreeFile f = BTreeUtility.createRandomBTreeFile(3, 1000, null, tuples, keyField);
+        Collections.sort(tuples, new TupleComparator(keyField));
+                
+        // EQUALS
+        TransactionId tid = new TransactionId();
+        ArrayList<ArrayList<Integer>> tuplesFiltered = new ArrayList<ArrayList<Integer>>();
+        IndexPredicate ipred = new IndexPredicate(Op.EQUALS, new IntField(r.nextInt(BTreeUtility.MAX_RAND_VALUE)));
+        Iterator<ArrayList<Integer>> it = tuples.iterator();
+        while(it.hasNext()) {
+        	ArrayList<Integer> tup = it.next();
+        	if(tup.get(keyField) == ((IntField) ipred.getField()).getValue()) {
+        		tuplesFiltered.add(tup);
+        	}
+        }
+        
+        BTreeScan scan = new BTreeScan(tid, f.getId(), "table", ipred);
+        scan.open();
+        for (int i = 0; i < tuplesFiltered.size(); ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuplesFiltered.get(i), SystemTestUtil.tupleToList(t));
+        }
+
+        scan.rewind();
+        for (int i = 0; i < tuplesFiltered.size(); ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuplesFiltered.get(i), SystemTestUtil.tupleToList(t));
+        }
+        scan.close();
+        
+        // LESS_THAN
+        tuplesFiltered.clear();
+        ipred = new IndexPredicate(Op.LESS_THAN, new IntField(r.nextInt(BTreeUtility.MAX_RAND_VALUE)));
+        it = tuples.iterator();
+        while(it.hasNext()) {
+        	ArrayList<Integer> tup = it.next();
+        	if(tup.get(keyField) < ((IntField) ipred.getField()).getValue()) {
+        		tuplesFiltered.add(tup);
+        	}
+        }
+        
+        scan = new BTreeScan(tid, f.getId(), "table", ipred);
+        scan.open();
+        for (int i = 0; i < tuplesFiltered.size(); ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuplesFiltered.get(i), SystemTestUtil.tupleToList(t));
+        }
+
+        scan.rewind();
+        for (int i = 0; i < tuplesFiltered.size(); ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuplesFiltered.get(i), SystemTestUtil.tupleToList(t));
+        }
+        scan.close();
+        
+        // GREATER_THAN
+        tuplesFiltered.clear();
+        ipred = new IndexPredicate(Op.GREATER_THAN_OR_EQ, new IntField(r.nextInt(BTreeUtility.MAX_RAND_VALUE)));
+        it = tuples.iterator();
+        while(it.hasNext()) {
+        	ArrayList<Integer> tup = it.next();
+        	if(tup.get(keyField) >= ((IntField) ipred.getField()).getValue()) {
+        		tuplesFiltered.add(tup);
+        	}
+        }
+        
+        scan = new BTreeScan(tid, f.getId(), "table", ipred);
+        scan.open();
+        for (int i = 0; i < tuplesFiltered.size(); ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuplesFiltered.get(i), SystemTestUtil.tupleToList(t));
+        }
+
+        scan.rewind();
+        for (int i = 0; i < tuplesFiltered.size(); ++i) {
+            assertTrue(scan.hasNext());
+            Tuple t = scan.next();
+            assertEquals(tuplesFiltered.get(i), SystemTestUtil.tupleToList(t));
+        }
+        scan.close();
+        Database.getBufferPool().transactionComplete(tid);
+    }
+    
+    /** Test that scanning the BTree for predicates does not read all the pages */
+    @Test public void testReadPage() throws Exception {
+    	// Create the table
+        final int LEAF_PAGES = 30;
+    	
+    	ArrayList<ArrayList<Integer>> tuples = new ArrayList<ArrayList<Integer>>();
+        int keyField = 0;
+        BTreeFile f = BTreeUtility.createBTreeFile(2, LEAF_PAGES*502, null, tuples, keyField);
+        Collections.sort(tuples, new TupleComparator(keyField));
+        TupleDesc td = Utility.getTupleDesc(2);
+        InstrumentedBTreeFile table = new InstrumentedBTreeFile(f.getFile(), keyField, td);
+        Database.getCatalog().addTable(table, SystemTestUtil.getUUID());
+        
+        // EQUALS
+        TransactionId tid = new TransactionId();
+        ArrayList<ArrayList<Integer>> tuplesFiltered = new ArrayList<ArrayList<Integer>>();
+        IndexPredicate ipred = new IndexPredicate(Op.EQUALS, new IntField(r.nextInt(LEAF_PAGES*502)));
+        Iterator<ArrayList<Integer>> it = tuples.iterator();
+        while(it.hasNext()) {
+        	ArrayList<Integer> tup = it.next();
+        	if(tup.get(keyField) == ((IntField) ipred.getField()).getValue()) {
+        		tuplesFiltered.add(tup);
+        	}
+        }
+        
+        Database.resetBufferPool(BufferPool.DEFAULT_PAGES);
+        table.readCount = 0;
+        BTreeScan scan = new BTreeScan(tid, f.getId(), "table", ipred);
+        SystemTestUtil.matchTuples(scan, tuplesFiltered);
+        // root pointer page + root + leaf page (possibly 2 leaf pages)
+        assertTrue(table.readCount == 3 || table.readCount == 4);
+        
+        // LESS_THAN
+        tuplesFiltered.clear();
+        ipred = new IndexPredicate(Op.LESS_THAN, new IntField(r.nextInt(LEAF_PAGES*502)));
+        it = tuples.iterator();
+        while(it.hasNext()) {
+        	ArrayList<Integer> tup = it.next();
+        	if(tup.get(keyField) < ((IntField) ipred.getField()).getValue()) {
+        		tuplesFiltered.add(tup);
+        	}
+        }
+        
+        Database.resetBufferPool(BufferPool.DEFAULT_PAGES);
+        table.readCount = 0;
+        scan = new BTreeScan(tid, f.getId(), "table", ipred);
+        SystemTestUtil.matchTuples(scan, tuplesFiltered);
+        // root pointer page + root + leaf pages
+        int leafPageCount = tuplesFiltered.size()/502;
+        if(leafPageCount < LEAF_PAGES)
+        	leafPageCount++; // +1 for next key locking
+        assertEquals(leafPageCount + 2, table.readCount);
+        
+        // GREATER_THAN
+        tuplesFiltered.clear();
+        ipred = new IndexPredicate(Op.GREATER_THAN_OR_EQ, new IntField(r.nextInt(LEAF_PAGES*502)));
+        it = tuples.iterator();
+        while(it.hasNext()) {
+        	ArrayList<Integer> tup = it.next();
+        	if(tup.get(keyField) >= ((IntField) ipred.getField()).getValue()) {
+        		tuplesFiltered.add(tup);
+        	}
+        }
+        
+        Database.resetBufferPool(BufferPool.DEFAULT_PAGES);
+        table.readCount = 0;
+        scan = new BTreeScan(tid, f.getId(), "table", ipred);
+        SystemTestUtil.matchTuples(scan, tuplesFiltered);
+        // root pointer page + root + leaf pages
+        leafPageCount = tuplesFiltered.size()/502;
+        if(leafPageCount < LEAF_PAGES)
+        	leafPageCount++; // +1 for next key locking
+        assertEquals(leafPageCount + 2, table.readCount);
+        
+        Database.getBufferPool().transactionComplete(tid);
+    }
+
+    /** Make test compatible with older version of ant. */
+    public static junit.framework.Test suite() {
+        return new junit.framework.JUnit4TestAdapter(BTreeScanTest.class);
+    }
+}
diff -Naur lab2/test/simpledb/systemtest/BTreeTest.java lab3/test/simpledb/systemtest/BTreeTest.java
--- lab2/test/simpledb/systemtest/BTreeTest.java	1969-12-31 18:00:00.000000000 -0600
+++ lab3/test/simpledb/systemtest/BTreeTest.java	2016-01-11 16:13:26.000000000 -0600
@@ -0,0 +1,227 @@
+package simpledb.systemtest;
+
+import simpledb.systemtest.SystemTestUtil;
+import static org.junit.Assert.*;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.NoSuchElementException;
+import java.util.Random;
+import java.util.Iterator;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.ArrayBlockingQueue;
+
+import org.junit.After;
+import org.junit.Test;
+import org.junit.Before;
+
+import simpledb.*;
+import simpledb.BTreeUtility.*;
+import simpledb.Predicate.Op;
+
+/**
+ * System test for the BTree
+ */
+public class BTreeTest extends SimpleDbTestBase {
+    private final static Random r = new Random();
+    
+    private static final int POLL_INTERVAL = 100;
+    
+    /**
+	 * Helper method to clean up the syntax of starting a BTreeInserter thread.
+	 * The parameters pass through to the BTreeInserter constructor.
+	 */
+	public BTreeInserter startInserter(BTreeFile bf, int[] tupdata, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+
+		BTreeInserter bi = new BTreeInserter(bf, tupdata, insertedTuples);
+		bi.start();
+		return bi;
+	}
+    
+	/**
+	 * Helper method to clean up the syntax of starting a BTreeDeleter thread.
+	 * The parameters pass through to the BTreeDeleter constructor.
+	 */
+	public BTreeDeleter startDeleter(BTreeFile bf, BlockingQueue<ArrayList<Integer>> insertedTuples) {
+
+		BTreeDeleter bd = new BTreeDeleter(bf, insertedTuples);
+		bd.start();
+		return bd;
+	}
+	
+	private void waitForInserterThreads(ArrayList<BTreeInserter> insertThreads) 
+			throws Exception {
+		Thread.sleep(POLL_INTERVAL);
+		for(BTreeInserter thread : insertThreads) {
+			while(!thread.succeeded() && thread.getError() == null) {
+				Thread.sleep(POLL_INTERVAL);
+			}
+		}
+	}
+	
+	private void waitForDeleterThreads(ArrayList<BTreeDeleter> deleteThreads) 
+			throws Exception {
+		Thread.sleep(POLL_INTERVAL);
+		for(BTreeDeleter thread : deleteThreads) {
+			while(!thread.succeeded() && thread.getError() == null) {
+				Thread.sleep(POLL_INTERVAL);
+			}
+		}
+	}
+	
+	private int[] getRandomTupleData() {
+		int item1 = r.nextInt(BTreeUtility.MAX_RAND_VALUE);
+		int item2 = r.nextInt(BTreeUtility.MAX_RAND_VALUE);
+		return new int[]{item1, item2};
+	}
+	
+	@After
+	public void tearDown() throws Exception {
+		// set the page size back to the default
+		BufferPool.resetPageSize();
+		Database.reset();
+	}
+	
+    /** Test that doing lots of inserts and deletes in multiple threads works */
+    @Test public void testBigFile() throws Exception {
+    	// For this test we will decrease the size of the Buffer Pool pages
+    	BufferPool.setPageSize(1024);
+    	
+    	// This should create a B+ tree with a packed second tier of internal pages
+		// and packed third tier of leaf pages
+    	System.out.println("Creating large random B+ tree...");
+    	ArrayList<ArrayList<Integer>> tuples = new ArrayList<ArrayList<Integer>>();
+		BTreeFile bf = BTreeUtility.createRandomBTreeFile(2, 31000,
+				null, tuples, 0);
+		
+		// we will need more room in the buffer pool for this test
+		Database.resetBufferPool(500);
+    	
+    	ArrayBlockingQueue<ArrayList<Integer>> insertedTuples = new ArrayBlockingQueue<ArrayList<Integer>>(100000);
+		insertedTuples.addAll(tuples);
+		assertEquals(31000, insertedTuples.size());
+		int size = insertedTuples.size();
+		
+		// now insert some random tuples
+		System.out.println("Inserting tuples...");
+    	ArrayList<BTreeInserter> insertThreads = new ArrayList<BTreeInserter>();
+		for(int i = 0; i < 200; i++) {
+			BTreeInserter bi = startInserter(bf, getRandomTupleData(), insertedTuples);
+			insertThreads.add(bi);
+			// The first few inserts will cause pages to split so give them a little
+			// more time to avoid too many deadlock situations
+			Thread.sleep(r.nextInt(POLL_INTERVAL));
+		}
+		
+		for(int i = 0; i < 800; i++) {
+			BTreeInserter bi = startInserter(bf, getRandomTupleData(), insertedTuples);
+			insertThreads.add(bi);
+		}
+		
+		// wait for all threads to finish
+		waitForInserterThreads(insertThreads);	
+		assertTrue(insertedTuples.size() > size);
+		
+		// now insert and delete tuples at the same time
+		System.out.println("Inserting and deleting tuples...");
+    	ArrayList<BTreeDeleter> deleteThreads = new ArrayList<BTreeDeleter>();
+		for(BTreeInserter thread : insertThreads) {
+			thread.rerun(bf, getRandomTupleData(), insertedTuples);
+    		BTreeDeleter bd = startDeleter(bf, insertedTuples);
+    		deleteThreads.add(bd);
+		}
+		
+		// wait for all threads to finish
+		waitForInserterThreads(insertThreads);
+		waitForDeleterThreads(deleteThreads);
+		int numPages = bf.numPages();
+		size = insertedTuples.size();
+		
+		// now delete a bunch of tuples
+		System.out.println("Deleting tuples...");
+		for(int i = 0; i < 10; i++) {
+	    	for(BTreeDeleter thread : deleteThreads) {
+				thread.rerun(bf, insertedTuples);
+			}
+			
+			// wait for all threads to finish
+	    	waitForDeleterThreads(deleteThreads);
+		}
+		assertTrue(insertedTuples.size() < size);
+		size = insertedTuples.size();
+		
+		// now insert a bunch of random tuples again
+		System.out.println("Inserting tuples...");
+		for(int i = 0; i < 10; i++) {
+	    	for(BTreeInserter thread : insertThreads) {
+				thread.rerun(bf, getRandomTupleData(), insertedTuples);
+			}
+		
+			// wait for all threads to finish
+	    	waitForInserterThreads(insertThreads);
+		}
+		assertTrue(insertedTuples.size() > size);
+		size = insertedTuples.size();
+		// we should be reusing the deleted pages
+		assertTrue(bf.numPages() < numPages + 20);
+		
+		// kill all the threads
+		insertThreads = null;
+		deleteThreads = null;
+		
+		ArrayList<ArrayList<Integer>> tuplesList = new ArrayList<ArrayList<Integer>>();
+		tuplesList.addAll(insertedTuples);
+		TransactionId tid = new TransactionId();
+		
+		// First look for random tuples and make sure we can find them
+		System.out.println("Searching for tuples...");
+		for(int i = 0; i < 10000; i++) {
+			int rand = r.nextInt(insertedTuples.size());
+			ArrayList<Integer> tuple = tuplesList.get(rand);
+			IntField randKey = new IntField(tuple.get(bf.keyField()));
+			IndexPredicate ipred = new IndexPredicate(Op.EQUALS, randKey);
+			DbFileIterator it = bf.indexIterator(tid, ipred);
+			it.open();
+			boolean found = false;
+			while(it.hasNext()) {
+				Tuple t = it.next();
+				if(tuple.equals(SystemTestUtil.tupleToList(t))) {
+					found = true;
+					break;
+				}
+			}
+			assertTrue(found);
+			it.close();
+		}
+		
+		// now make sure all the tuples are in order and we have the right number
+		System.out.println("Performing sanity checks...");
+    	DbFileIterator it = bf.iterator(tid);
+		Field prev = null;
+		it.open();
+		int count = 0;
+		while(it.hasNext()) {
+			Tuple t = it.next();
+			if(prev != null) {
+				assertTrue(t.getField(bf.keyField()).compare(Op.GREATER_THAN_OR_EQ, prev));
+			}
+			prev = t.getField(bf.keyField());
+			count++;
+		}
+		it.close();
+		assertEquals(count, tuplesList.size());
+		Database.getBufferPool().transactionComplete(tid);
+		
+		// set the page size back
+		BufferPool.resetPageSize();
+		
+    }
+
+    /** Make test compatible with older version of ant. */
+    public static junit.framework.Test suite() {
+        return new junit.framework.JUnit4TestAdapter(BTreeTest.class);
+    }
+}